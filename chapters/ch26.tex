

\chapter{Модели ошибок измерения}
%%%% Comments %%%%

\section{Введение}
Проблемы, связанные с ошибками измерений в эконометрике встречаются повсеместно. В микроэконометрике основным источником  ошибок измерения являются неправильные ответы на вопросы анкет, неправильное кодирование правильных ответов и использование правильно измеренных переменных в качестве прокси для теоретически подходящей, но ненаблюдаемой переменной (например, использование наблюдаемого дохода как прокси для <<нормального дохода>>.  Вопросы, связанные с конфиденциальной информацией, могут привести к неполным или неверным ответам. Иными словами, ошибки измерений порождаются ненаблюдаемыми \emph{(или латентными)} переменными, когда они заменяются прокси-переменными.

Приведём несколько примеров. Рассмотрим задачу тестирования наличия дискриминации по половому признаку в рамках исследования доходов. Очевидный подход --- построить регрессию переменной доходов на категориальную переменную пола индивида, учитывая квалификацию, возраст, опыт работы и т.д. Однако наиболее подходящей переменной может быть индивидуальная производительность труда на рабочем месте, которая не может быть измерена напрямую и вместо которой может быть использована прокси. Таким образом, влияние ошибки измерений на выводы относительно гендерной дискриминации, является важной проблемой. Исследования индивидуального спроса на товары и услуги используют такие понятия, как <<экономические издержки>> \emph{(economic cost)} и <<полная цена услуги>> \emph{(full price of a service)}. Тем не менее, такие переменные редко напрямую могут быть посчитаны по доступным данным, так что для оценивания моделей должны быть сконструированы их заменители.  Неизбежно появляются ошибки измерения.

В этой книге нет фактически ни одной модели, защищённой от проблем ошибок измерений. Бинарные  эндогенные и экзогенные переменные являются потенциально источником ошибок классификации; данные по переходам из одного состояния в другое и дискретные данные, взятые из ретроспективных обследований подвержены ошибкам памяти; данные по относительно однозначным переменным, таким как почасовая заработная плата и расходы домохозяйств, могут искажаться из-за преднамеренного завышения или неверно сообщенной информации. В отличие от агрегированных данных, когда агрегирование может нивелировать некоторые ошибки измерений, данные на уровне отдельных индивидов эти ошибки сохраняют.

В первой части этой Главы изучаются последствия ошибок измерений и стратегии оценивания для ликвидации этих последствий. Рассматриваются как линейные, так и нелинейные модели. Хотя более реалистичным было бы решать проблему ошибок измерений, принимая во внимание, что она возникает одновременно с рядом других, более удобно для представления предположить, что это единственная проблема, которая стоит перед эконометристом.

Вообще говоря, последствия ошибок измерения заключаются в неправильной идентификации интересующих параметров. Решение такой задачи сложное. Можно просто не включать действительно подходящую переменную, можно заменить её на прокси для истинного значения. Существуют, по крайней мере, две причины, по которым не стоит впадать в крайности. Первая заключается в том, что невключение в модель основной интересующей переменной ведёт к серьёзному смещению, что является замещением одной проблемы другой при той же невозможности идентификации параметров. Вторая причина такова: в линейной регрессии использование прокси вместо латентной переменной даёт меньшее асимптотическое смещение, чем невключение переменной в модель, если ошибки наблюдения случайны и независимы от истинных регрессоров (МакКоллум, 1972). Игнорирование переменной даёт оценки низкого качества.  Тем не менее, использование прокси не решает проблему несмещенности, хотя и приводит к меньшему смещению.

Основная идея, лежащая в основе решения задачи борьбы с ошибками измерений, --- чтобы восстановить параметр при латентной переменной и  идентифицировать саму модель, необходимо располагать большей информацией в виде дополнительных предположений об ошибках измерений или получить дополнительные данные и использовать эту информацию после введения правдоподобных допущений. Такой подход является довольно известным. Тем не менее, когда дополнительная информация недоступна, эконометрические модели представляют собой хорошую альтернативу.

Ошибки измерений вызывают очень серьёзные последствия, так как во многих случаях они ведут к тому, что параметры регрессии не могут быть идентифицированы. Например, Кард (2001) проанализировал эмпирические исследования коэффициента при переменной образования в регрессии доходов и обнаружил, что, как правило, результаты смещены в сторону занижения на 25--35\%.  Конкретные масштабы последствий ошибок измерений зависят от функциональной формы модели, от того, какую форму принимают ошибки (аддитивную или мультипликативную) и от структуры анализируемых данных. Решение проблемы, возникшей по причине ошибок измерений, обычно требует введения в модель дополнительной информации, либо в форме данных, либо в форме предположений.

Удобно построить рассмотрение ошибок измерений, разбив его на части: случаи линейных моделей, нелинейных моделей и специальные случаи. Разделы 26.2 и 26.3 посвящены линейной регрессии. В Разделе 26.4 речь идёт о нелинейной регрессии. В Разделе 26.5 приводятся несколько примеров использования метода Монте-Карло.  Необходимые в анализе линейных регрессий идеи применимы и в случае нелинейных моделей. В любом случае более ясные результаты обычно доступны в моделях специального вида.

\section{Ошибки измерений в линейной регрессии}

Ошибки измерений регрессоров или {\bf ошибки в переменных}  --- важная тема, так как это причина несостоятельности МНК-оценок, даже если ошибки измерений имеют нулевое математическое ожидание. Принято говорить, что ошибки измерений регрессоров ведут к смещению оценок, но мы пользуемся более сильным термином --- несостоятельность --- то есть смещение сохраняется даже при стремлении размера выборки к бесконечности.

Спектр моделей ошибок измерений широк, они описывают ситуации, когда ошибкам измерений подвержены объясняющие переменные --- регрессоры, зависимые переменные или и те, и другие. В работе Хаусмана (2001) эти случаи названы <<проблемы справа>> и <<проблемы слева>>. В случае ошибки в регрессорах, когда мы имеем классическую модель ошибки переменной,  интерес представляет взаимосвязь зависимой переменной $y$ и объясняющих переменных $(\mathbf{W}, \mathbf{X^*})$, где $\mathbf{W}$ измерена без ошибок, а $\mathbf{X^*}$ --- ненаблюдаемая, но прокси для неё, переменная $\mathbf{X}$, доступна. Вопрос исследования ставится тогда следующим образом: является ли оценка взаимосвязи $\mathbf{y}$ и $(\mathbf{W}, \mathbf{X})$ достаточным основанием для заключений относительно $\mathbf{X^*}$.


В статистической литературе  принято разделять  функциональный и структурный подходы к моделированию ошибок измерения. Если $\mathbf{X^*}$ отражает истинные ненаблюдаемые регрессоры, то, согласно функциональному подходу, они буду представлены как неизвестные фиксированные константы. В структурном подходе они будут считаться случайными. Кэррол, Рупперт и Стефански (1995) далее выделяют \emph{функциональное моделирование}, в котором относительно регрессоров $\mathbf{X}$ сделаны лишь минимальные предположения, вне зависимости от того, фиксированные они или случайные, и \emph{структурное моделирование}, которое предполагает параметрические предположения о распределении $\mathbf{X}$. Функциональные модели ошибок измерений являются примерами моделей с бесконечным количеством мешающих параметров, что порождает известные сложности в применении метода максимального правдоподобия (которые обсуждались в Главе, посвященной анализу панельных данных). Этому моменту нечасто уделяется внимание в эконометрической литературе.

Масштабы несостоятельности на практике могут быть существенны. В исследованиях детерминант доходов индивидов тема проблемы ошибок измерений, как и методов её выявления, является очень популярной

\subsection{Классическая модель ошибок измерений} 

Стандартная модель ошибок измерений имеет непрерывную зависимую переменную $y$, которая является линейной функцией от $K$ истинных регрессоров $\mathbf{x^*}$. Аддитивная ошибка измерений $y$ не порождает никаких проблем, если она не коррелирована с регрессорами, так как она может быть просто объединена с ошибкой регрессии. Если бы $\mathbf{x^*}$ наблюдались, то параметры могут быть состоятельно оценены с помощью МНК-регрессии $y$ на $\mathbf{x^*}$,
\[
y_i=\mathbf{x^*}_i'+u_i,
\]
Где $u_i$ --- независимые одинаково распределённые случайные величины с параметрами $[0,\sigma^2]$. Вместо этого мы наблюдаем $\mathbf{x}\neq \mathbf{x^*}$ и строим регрессию $y$ на $\mathbf{x}$, а не на $\mathbf{x^*}$. Взаимосвязь между истинными и реально наблюдаемыми регрессорами задаётся как

\begin{equation}
\mathbf{x}_i=\mathbf{x}_i^*+\mathbf{v}_i, i=1,\ldots,N,
\end{equation}

где аддитивно заданная ошибка измерений предполагается распределённой следующим образом:
\begin{equation}
\mathbf{v}_i \sim [\mathbf{0},\mathbf{\Sigma_{vv}}].
\end{equation}

Для ненаблюдаемых истинных регрессоров предполагается нулевое математическое ожидание, то есть мы трактуем их как отклонения от среднего с ковариационной матрицей 
\begin{equation}
\Var\mathbf{([x^*_i]}=\mathbf{\Sigma_{x^*x^*}}.
\end{equation}
Отметим, что $\mathbf{x}$ есть несмещённая оценка $\mathbf{x^*}$, так как математическое ожидание ошибки измерений $\mathbf{v}$ предполагается равным нулю. Ошибка измерений, согласно предпосылкам модели, независима от $\mathbf{x^*}$ и ошибки регрессии $u$,
\begin{equation}
\Expect(\mathbf{v_i}|\mathbf{x^*_i})=\Expect[\mathbf{v_i}|u_i]=0.
\end{equation}

\subsection{Несостоятельность оценок метода наименьших квадратов}  

Чтобы рассмотреть последствия ошибок измерений, удобно представить процесс порождающий данные для классической модели ошибок измерений в матричном виде как 
\begin{align}
\mathbf{y}&=\mathbf{X^*}\beta+\mathbf{u}, \\
\mathbf{X}&=\mathbf{X^*}+\mathbf{V}, \notag
\end{align}
где $u$, ошибка регрессии, удовлетворяет условиям $\Expect(\mathbf{u}|\mathbf{X^*})=\mathbf{0}$ и $\Expect(\mathbf{uu'}|\mathbf{X^*})=\sigma^2\mathbf{I}_N$. Подставляя второе выражение в первое, получаем
\begin{equation}
\mathbf{y}=\mathbf{X}\beta+(\mathbf{u}-\mathbf{V}\beta).
\end{equation}
МНК-регрессия $\mathbf{y}$ на $\mathbf{X}$ ведёт к получению несостоятельных оценок $\mathbf{\beta}$, так как ошибка $(\mathbf{u}-\mathbf{V\beta})$ коррелирована с регрессором $\mathbf{X}$ через ошибку измерений $\mathbf{V}$.
Формально мы имеем
\begin{align*}
\plim N^{-1}\mathbf{X'}(\mathbf{u}-\mathbf{V\beta})&=\plim N^{-1}(\mathbf{X^*}+\mathbf{V})'(\mathbf{u}-\mathbf{V\beta}) \\
&=-\mathbf{\Sigma_{vv}}\mathbf{\beta} \\
&\neq\mathbf{0},
\end{align*}
где мы воспользовались тем, что $N^{-1}\mathbf{V'V}=N^{-1}\sum\limits_i\mathbf{v}_i\mathbf{v}'_i$ и $\mathbf{v}_i$ независимы и одинаково распределены с параметрами $[\mathbf{0}, \mathbf{\Sigma_{vv}}]$. Это и есть основной источник несостоятельности. Теперь 
\begin{align*}
\plim N^{-1}\mathbf{X'X}&=\plim N^{-1}(\mathbf{X^*+V})'(\mathbf{X^*+V}) \\
&=\mathbf{\Sigma_{x^*x^*}}+\mathbf{\Sigma_{vv}},
\end{align*}
где мы воспользовались тем, что $\mathbf{x_i^*}$ --- независимые одинаково распределённые случайные величины с нулевым средним и ковариационной матрицей $\Var\mathbf{[x^*_i]}=\mathbf{\Sigma_{x^*x^*}}$. Также
\begin{align*}
\plim N^{-1}\mathbf{X'y}&=\plim N^{-1}(\mathbf{X^*+V})'(\mathbf{X^*\beta+u}) \\
&=\mathbf{\Sigma_{x^*x^*}}+\mathbf{\Sigma_{vv}},
\end{align*}
так что, согласно теореме Слуцкого (Приложение А, Теорема А.3.), мы получаем
\begin{align}
\plim \mathbf{\widehat {\beta}}&={\plim N^{-1}\mathbf{X'X}}^{-1}\plim N^{-1}\mathbf{X'y} \\
&={\mathbf{\Sigma_{xx}}}^{-1}(\mathbf{\Sigma_{xx}}-\mathbf{\Sigma_{vv}})\mathbf{\beta} \notag \\
&=\mathbf{\beta}-{(\mathbf{\Sigma_{x^*x^*}}+\mathbf{\Sigma_{vv}})}^{-1}\mathbf{\Sigma_{vv}}\mathbf{\beta}. \notag 
\end{align}

Очевидно, что несостоятельность МНК появляется из-за ошибок измерений и предположения $\mathbf{\Sigma_{vv}}\neq\mathbf{0}$.

Для последующего изложения отметим, что, если мы имеем состоятельную оценку ковариационной матрицы $\mathbf{\Sigma_{vv}}$, обозначенной как $\mathbf{S_{vv}}$, и если $(\mathbf{X'X}-\mathbf{S_{vv}})$ положительно определена, то можно вычислить оценку скорректированным МНК $\mathbf{\widehat {\beta_a}}={(\mathbf{X'X}-\mathbf{S_{vv}})}^{-1}\mathbf{X'y}$. Эта формула может быть использована для изучения влияния дисперсии ошибки измерений на оценки метода наименьших квадратов.

\subsection{Ошибки измерений и скалярный регрессор}

Частный случай этой модели, который обычно рассматривается в учебниках, подразумевает наличие одного истинного или ненаблюдаемого регрессора $x^*$ с дисперсией $\sigma^2_x$, наблюдаемой переменной $x$, ошибки измерений $v$ с нулевым средним и дисперсией $\sigma^2_v$. Таким образом, мы имеем уравнение регрессии $y=\beta x^*+u$, где $\Expect[u|x^*]=0$, $\Var[u|x^*]=\sigma^2_u$,  и $\Cov[v,u]=0$, но в регрессии вместо $x^*$ используется наблюдаемая величина $x$. 
В этом случае (26.7) может быть представлено как
\begin{align}
\plim\widehat {\beta}&=\frac{\sigma^2_{x^*}}{\sigma^2_{x^*}+\sigma^2_v}\beta \\
&=\frac{1}{1+\sigma^2_v / \sigma^2_{x^*}}\beta \notag \\
&=\beta[1-s/(1+s)], \notag 
\end{align}

где $s=\sigma^2_v / \sigma^2_{x^*}$, что носит название отношения {\bf шум-сигнал}, а компонента ${(1+s)}^{-1}$ называется {\bf отношением стабильности}. Оценка коэффициента $\widehat {\beta}$ асимптотически смещена к нулю, при этом смещение зависит  от отношения шум-сигнал. Эта величина ещё носит название {\bf смещения затухания} \emph{(attenuation bias)}. Такая терминология интуитивно понятна, т.к. оценки предельного воздействия изменения $\mathbf{x^*}$ на изменение $y$, полученные исследователем, затухают, уменьшаются из-за появления ошибки наблюдений регрессора $x^*$. 
  
Отметим также, что
\[
\Var[y|x]=\sigma^2_u+\frac{{\beta}^2\sigma^2_v\sigma^2_{x^*}}{\sigma^2_{x^*}+\sigma^2_v}\geqslant \sigma^2_u.
\]
Из этого следует, что ошибка измерений не только занижает оценки коэффициентов, но и увеличивает дисперсию ошибки регрессии. И уменьшение дисперсии ошибок измерений определённо приведёт к снижению дисперсии ошибок регрессии.

Если бы в описанное выше уравнение регрессии был включен свободный член, смещенной была бы его МНК-оценка $\bar{y} - \widehat{\beta}\bar{x}$,  где $(\bar y, \bar x)$ --- выборочные средние значения, которые всё ещё представляют собой несмещенные оценки средних значений всей генеральной совокупности. Крэгг (1994) предложил термин {\bf <<смещение заражения>>} \emph{(contamination bias)} для описания влияния ошибок измерения на другие параметры в регрессионном уравнении.

В качестве примера рассмотрим регрессию логарифма почасовой заработной платы на количество лет образования. Предположим, что продолжительность образования $x^*$ измерена с ошибкой, также предположим, что стандартное отклонение истинной величины продолжительности образования равно 2, а стандартное отклонение ошибок измерений равно 1, так что $\sigma^2_{x^*}=4$, $\sigma^2_v=1$, и $\sigma^2_x=5$. Тогда $\plim\widehat{\beta}=0.8 \times \beta$. МНК-оценка коэффициента наклона 0.04 тогда означает, что один дополнительный год обучения в школе соответствует 5\%-ому увеличению заработной платы, а не 4\%-ому.

\subsection{Обобщения} 

При обобщении этого простого, но изящного результата, исследователи часто задаются вопросом, является ли затухание общей чертой всех моделей ошибок измерения и что если затуханию подвергаются все параметры? Хотя результат не обязательно распространять на более общие модели, он может послужить хорошей отправной точкой. Хаусман (Hausman, 2001) назвал смещение затухания, вызванное ошибками измерения, <<железным законом эконометрики>>. 

Если ошибки измерений предполагается некоррелированной с истинной ненаблюдаемой переменной, такие ошибки называются <<классическими>>. Несмотря на удобство, эта предпосылка иногда не выполняется. На самом деле, в некоторых случаях она и не может выполняться. Например, если $x$ является бинарной переменной, ошибки измерений будут ошибками классификации. Если в результате неправильной классификации 0 будет измерен как 1 и наоборот, то ошибки измерений должны будут коррелировать с истинными значениями.

Когда в модель включается больше одного регрессор, обозначим $\mathbf{X^*}=[\mathbf{x^* Z}]$. Как и в предыдущем случае, мы предполагаем, что только один регрессор наблюдается с ошибкой измерения, то есть $x=x^*+v$. Тогда выражение для оценки коэффициента при $x$ методом наименьших квадратов будет следующим:
\begin{equation}
\plim\widehat{\beta}_{x|\mathbf{Z}}=\beta \left[ 1-\frac{\sigma^2_v}{\sigma^2_{x^*}(1-R^2_{x^*,\mathbf{Z}})+\sigma^2_v}\right],
\end{equation}
где $R^2_{x^*,\mathbf{Z}}$ представляет собой $R^2$ во вспомогательной регрессии $\mathbf{x^*}$ на $\mathbf{Z}$. Формула (26.9) представляет собой другой вариант формулы (26.8), только здесь мы вместо дисперсии $x^*$ мы считаем дисперсию после исключения влияния $\mathbf{Z}$ на $\mathbf{x^*}$. И снова  МНК-оценки смещены к нулю, хотя и меньше, чем в случае одного регрессора. Коэффициенты при регрессорах, измеренных без ошибок, также несостоятельны, при этом направление смещения зависит от $\mathbf{\Sigma_{x^*x^*}}$ (Леви, 1973). Этот эффект может быть снова назван смещением заражения. Смещение затухания в рассмотренном случае сильно зависит от предпосылки об аддитивности ошибок измерений. 

Когда более чем один регрессор измерен с ошибками, априори определить направление смещения не получается, хотя в любой рассматриваемой задаче оно может быть выведено, исходя из знания о $\mathbf{\Sigma_{x^*x^*}}$ и $\mathbf{\Sigma_{vv}}$. В большинстве работ предполагается, что ошибки измерения существуют только для одного регрессора, в этом случае оценка смещена к нулю. Интуиция, основанная на рассмотренных выше примерах, позволяет заключить, что если ошибки измерений разных регрессоров независимы, тогда каждая из них будет способствовать затуханию своего коэффициента регрессии, и к росту условной дисперсии. Крэгг (1994) анализировал множественную регрессионную модель с ошибками измерений и изучал взаимосвязь между смещениями разных регрессоров.

\subsection{Ошибки измерений в линейных моделях панельных данных}
 
Эффект от ошибок измерений в регрессорах становится более сложным в случае панельных данных.

Рассмотрим сквозную модель для панельных данных $y_{it}=\beta x^*_{it}+u_{it}$, где мы наблюдаем $x_{it}=x^*_{it}+v_{it}$, при этом для упрощения рассмотрим скалярный регрессор. Полученные ранее результаты по-прежнему верны, если мы рассматриваем пространственный срез данных. Тем не менее, если мы оцениваем модель, используя наблюдения за несколько лет, нам необходимо скорректировать  предыдущие результаты, так как регрессор $x^*_{it}$ будет скорее всего положительно коррелирован, нежели  будет иметь независимые наблюдения по $t$ для определённого $i$. Например, если мы строим регрессию в первых разностях
\begin{align*}
\Delta y_{it}&=\beta \Delta x^*_{it}+ \Delta u_{it} \\
&= \beta \Delta x_{it}+\Delta u_{it}-\beta \Delta v_{it}
\end{align*}
(см. Главу 21.6) и определив параметр $\rho = Cor[x^*_{it}, x^*_{i,t-1}]$, получим
\begin{align*}
\plim\widehat{\beta}&=\beta + \left( \plim \frac{1}{N} \sum \limits^{N}_{i=1}(\Delta x_{it})^2 \right)^{-1} \left( \plim \frac{1}{N} \sum \limits^{N}_{i=1}(\Delta x_{it} \Delta u_{it}-\beta \Delta x_{it} \Delta v_{it}) \right) \\
&= \beta - \frac{2\beta \sigma^2_v}{2(1-\rho)\sigma^2_{x^*}+2\sigma^2_v} \\
&=\beta-\frac{\beta \sigma^2_v}{(1-\rho)\sigma^2_{x^*}+\sigma^2_v},
\end{align*}
используя равенства$\Var[\Delta v_{it}]=2\Var[v_{it}]$ и $\Var[\Delta x^*_{it}]=2(1-\rho)\Var[x^*_{it}]$.

Масштаб несостоятельности увеличивается по сравнению с пространственной выборкой, если $\rho>0$. Более того, при $\rho\rightarrow 1$, что вероятно в случае панельных данных, несостоятельность становится очень сильной. Она может быть снижена путём взятия разностей, которые отстоят друг от друга по времени на $m>1$ шагов, так как $\Corr[x^*_{it}, x^*_{i,t-m}]$ будет убывать с ростом $m$.

\section{Стратегии идентификации} 

Принято считать, что модели с ошибками измерения не могут быть идентифицированы без введения дополнительных предпосылок. Это утверждение может быть интерпретировано в контексте частного  случая парной регрессии следующим образом. Одно  значение оценки параметра $\widehat{\beta}$, или точнее, его предела по вероятности, будет соответствовать бесконечному количестве комбинаций параметра $\beta$ и отношения шум-сигнал $s$. А при введении дополнительных предпосылок в модель можно будет исключить некоторые комбинации упомянутых параметров, потенциально соответствующие имеющимся данным. Если дополнительные ограничения позволяют получить единственное решение, модель считается точно идентифицированной. Если введённых ограничений больше, чем достаточно, чтобы однозначно идентифицировать параметры, модель будет переидентифицированной.

Общая стратегия идентификации моделей ошибок измерений заключается в получении границ на значения, а не точечных оценок интересующих параметров, если нет дополнительной априорной информации о данных. Если доступны дополнительные данные или информация об ошибках измерений, то осуществимыми становятся и другие стратегии идентификации, такие как метод инструментальных переменных или метод моментов. 
Наличие дополнительной информации об ошибках измерения --- это широкое понятие, которое включает одну из самых старых стратегий идентификации --- использование инструментальных переменных, которые выступают связующим звеном между истинными ненаблюдаемыми переменными и соответствующие им переменными. Например, использование дополнительной информации может привести к состоятельной оценке коэффициента затухания, $\frac{\sigma^2_{x^*}}{\sigma^2_{x^*}+\sigma^2_{v}}$, приводя к возможности скорректировать оценки на это смещение. Наконец, дублированные данные или контрольные данные могут быть доступны, и использованы как информация о моментах ошибок измерений. Эти возможности будут подробнее разобраны далее.

\subsection{Ограничения на параметры регрессии}
 
Обратимся снова к множественной регрессии из Главы 26.2. Рассмотренная в том случае модель требует положительной полуопределённости матриц $\mathbf{\Sigma_{x^*x^*}}$, $\mathbf{\Sigma_{vv}}$ и $\sigma^2$. Вместе с условиями ортогональности они могут быть использованы для построения ограничений на интервал, в котором должны лежать коэффициенты. Клеппер и Лимер (1984), а также Вансбик и Мейер (2000) рассматривали эту проблему в общей её постановке. Наиболее доступный частный случай граничного  подхода –-- построение обратной регрессии, описанное далее.

\subsection*{Обратная регрессия} 

В простой парной регрессии с переменными $(x, y)$ {\bf прямой} называют регрессию $y$ на $x$, тогда как {\bf обратной} --– регрессию $x$ на $y$. В общем случае множественной регрессии с $K$ независимыми переменными существует единственная прямая регрессия и $K$ обратных. Каждая обратная регрессия содержит в левой части экзогенную переменную, измеренную с ошибками, а в правой части --- другие экзогенные переменные и $y$. В случае парной регрессии с ошибками измерений легко показать, что оценки коэффициентов наклона в прямой и обратной постановке определяют верхнюю и нижнюю границы для истинного значения коэффициента. Этот результат может быть использован при анализе эффектов ошибок измерения. Лимер (1978) приводит отличное обсуждение логики  обратной регрессии.
 
Для начала приведём обоснование использования обратной регрессии в приложении к простой парной регрессии с ошибками измерения:
\begin{align}
y&=\beta x^*+u, \\
x&=x^*+v, \notag
\end{align}
где $u$ --– ошибка регрессии  и $v$ --– ошибка измерений, которая представляет собой отклонение наблюдаемых значений $x$ от истинных значений переменной $x^*$, которая включена в регрессию. Будем предполагать, что $u \sim \cN [0,\sigma^2_u]$ и $v \sim \cN [0,\sigma^2_v]$.

В соответствии со структурным подходом Солари (1969) и Лимера (1978), рассмотрим $x^*$ как  неизвестный параметр в функции правдоподобия. Общая функция правдоподобия для имеющихся данных $(\mathbf{y}, \mathbf{x})$ выглядит как
\begin{align}
L(\mathbf{x^*}, \beta, \sigma^2_v)\propto ( \sigma^2_u)^{N/2} \exp \left[ -\frac{1}{2\sigma^2_u}(\mathbf{y-\beta x})'(\mathbf{y-\beta x}) \right] \notag \\
\times ( \sigma^2_v)^{N/2} \exp \left[ -\frac{1}{2\sigma^2_v}(\mathbf{x^*-\beta x})'(\mathbf{x^*-\beta x}) \right].
\end{align}
Эта функция не определена в точках, удовлетворяющим условиям $\sigma^2_u=0$ и $\mathbf{x^*}=\mathbf{x}$, или условиям $\sigma^2_v=0$ и $\mathbf{y}=\mathbf{\beta x^*}$. Если мы просто минимизируем  функцию правдоподобия там где она определена с учетом ограничений, мы получим два скалярных параметра регрессии, $\widehat{\beta}_D=\mathbf{y'x/x'x}$ для прямой регрессии и $\widehat{\beta}_R=\mathbf{y'x/y'y}$ для обратной. Интуитивно, если $\mathbf{x}$ измерен без ошибок, то $\mathbf{y}$ случаен, а $\mathbf{x}$ --- нет, тогда прямая регрессия имеет осмысленную интерпретацию в терминах условных ожиданий. Если же  $\mathbf{x}$ --- стохастический (измерен с ошибкой), то условное ожидание $\Expect[\mathbf{x|y}]$ имеет смысл, так как система из двух уравнений сводится к уравнению $x=(1/\beta)y-u/\beta+v$. Таким образом, обратная регрессия даёт МНК-оценку $\widehat{1/\beta}$. Напрямую можно проверить, что
\begin{align}
r^2_{xy} \widehat{\beta}_R&=\widehat{\beta}_D, \\
\widehat{\beta}_D &< \beta < \widehat{\beta}_R, \notag
\end{align}
где $r^2_{xy}$ --- квадрат выборочной корреляции между $x$ и $y$; границы свидетельствуют о том, что $\widehat{\beta}_D$ --- заниженная оценка $\beta$ и $\widehat{\beta}_R$ --- завышенная оценка. Отметим, что этот интервал может быть очень широким для микроэкономических данных, где почти всегда $r^2_{xy}<0.5$ и даже величина $r^2_{xy}<0.1$ довольно распространена.

Лимер (1978) предложил модель, в которой $(y, x*)$ имеют двумерное нормальное распределение со средним $(\beta \bar{x}^*, \bar{x}^*)$ и ковариационной матрицей 
\begin{equation}
\mathbf{\Sigma}=
\begin{bmatrix}
\sigma^2_u+\beta^2\sigma^2_{x^*} & \beta\sigma^2_{x^*} \\ \beta\sigma^2_{x^*} & \sigma^2_{x^*}+\sigma^2_v
\end{bmatrix} .
\end{equation}
Он показал (Лимер, 1978, стр. 239--240), что для этой модели функция правдоподобия достигает максимума при любом значении $\widehat{\beta}_D$ из промежутка от оценки из прямой регрессии $\beta$ до оценки из обратной регрессии $\widehat{\beta}_R$.

Из упомянутого анализа следует, что хотя $\beta$ и не идентифицируется, можно всё же получить состоятельные границы для искомого значения. Здесь успешно применяется {\bf метод идентификации границ коэффициентов}. Этот результат может быть легко распространён на случай множественной регрессии, а которой только один регрессор измерен с ошибками (Боллингер, 2003). Клеппер и Лимер (1984) рассмотрели обобщение случая множественной регрессии с $K$ независимыми переменными, предположив, что все они могут иметь ошибки измерений. В этом случае будет одна прямая регрессия и $K$ обратных. После оценивания каждая обратная регрессия перенормируется чтобы коэффициент при $y$ в левой части оказался равным единице. Пусть $\mathbf{\widehat{\beta}_{D}}$ --- вектор оценок из прямой регрессии и $\mathbf{\widehat{\beta}_{R,j}}$ --- вектор оценок из $j$-ой обратной регрессии. Согласно результатам Клеппера и Лимера (1984), если коэффициенты из прямой и обратных регрессий лежат в одном ортанте, то множество возможных значений $\mathbf{\beta}$ --- это выпуклая оболочка множества коэффициентов для прямой и обратной регрессии; т.е. $\mathbf{\beta} \in \{ \mathbf{\widehat{\beta}|\widehat{\beta}=\lambda_D \widehat{\beta}_D}+\lambda_1 \widehat{\beta}_{R,1}+ \dots \lambda_k \widehat{\beta}_{R,K} \}$, где $\lambda$ --- неотрицательные веса, в сумме дающие единицу. Наименьший коэффициент из прямой и обратных регрессий является нижней границей интервала, а наибольшие --- верхней границей. Таких границ не существует, если значения коэффициента меняют знак.

В дополнение к работе Клеппера и Лимера (1984) можно упомянуть несколько работ, в которых этот подход применятся на практике. Грин (1983) и Голдбергер (1984) использовали метод обратных регрессий для измерения масштабов дискриминации в контексте размера заработной платы. Боллингер (2003) измерял разницу в доходах белого и черного населения на основе модели зарплаты и человеческого капитала. Боллингер (1996) обратился к методу границ при построении  регрессии на категориальную дамми-переменную, при этом имели место ошибки классификации.

\subsection{Идентификация с помощью инструментальных переменных} 

Одним решением проблемы идентификации можно назвать введение одного или более моментных ограничений, которые позволяют идентифицировать модель. Моментное ограничение, как правило, состоит в том, что существует некоторая инструментальная переменная коррелированная или имеет причинно-следственную связь с ошибочно измеренной переменной. Более того, она не коррелирует и не имеет причинно-следственных связей с зависимой переменной модели. Добавляя это ограничение в исходную модель, мы теоретически получаем решение проблемы идентификации.

Исторически, оценивание методом инструментальных переменных было предложено как возможный путь  решения проблемы ошибок измерения в линейных моделях (Райерсол, 1941; Дарбин, 1954). Подход с использованием инструментальных переменных также обоснован, когда одна или более переменная в правой части уравнения является эндогенной, а значит коррелированной с ошибкой регрессии. Модель линейных одновременных уравнений и линейная модель ошибок измерений сходны по структуре, и, таким образом, использование оценок метода инструментальных переменных в случае возникновения ошибок измерений вполне естественно.

Снова рассмотрим  линейную модель с инструментальными переменными из Разделов 4.8 и 6.4, где $\mathbf{y=X\beta+u}$ и $\Expect[\mathbf{u|X}] \neq \mathbf{0}$. Мы можем использовать двухшаговую МНК оценку, если доступен набор валидных инструментов $\mathbf{Z}$, таких что $\dim[\mathbf{Z}] \geqslant \dim[\mathbf{X}]$.

С помощью теста Хаусмана на эндогенность в регрессорах можно проверить наличие ошибок измерений, см. Раздел 8.3. Возможны несколько вариантов теста, один из которых подробнее рассмотрен в Разделе 8.4.

Основная проблема применения оценок метода инструментальных переменных заключается в сложности нахождения валидных инструментов на практике. Хорошие инструменты удовлетворяют двум требованиям: некоррелированность с ошибкой регрессии (для состоятельности) и высокая корреляция с заменяемыми переменными (для эффективности). Такие инструменты не так просто найти. Хотя в идеале можно создать валидные инструменты проанализировав  взаимосвязи регрессоров и ошибки модели, как правило, обычно на практике используются ad-hoc методы. В отличие от подхода, подразумевающего полное описание системы, ad-hoc метод проще и требуется для него меньше. Отметим, что требования к валидности инструментов не порождают никакой процедуры выбора инструментов. Технические требования могут быть удовлетворены, если переменная не имеет причинно-следственной связи с изучаемым явлением. Нужно найти переменную, сильно коррелированную с регрессором(-ами) и некоррелированную с ошибкой регрессии. Несколько интересных примеров применения этой идеи можно встретить в литературе; см., например, работу Ангриста (1990). Даже если такая переменная найдена, её использование может давать  спорные и противоречивые результаты.

В качестве примера предположим, что у нас имеется несколько возможных инструментов для пространственной регрессии доходов на образование. Во-первых, если доступны данные о родных братья или сёстрах, то их уровень образования может быть использован как инструмент, так как уровни образования братьев и сестёр предполагаются коррелированными. Состоятельность оценок метода инструментальных переменных тогда основывается на некоррелированности ошибки измерений $v$ и любой ошибкой измерений уровня образования родных братьев и сестёр. Во-вторых, также могут быть использованы такие переменные, связанные с уровнем образования, как уровень образования родителей или их доход. Использование более широкого множества инструментальных переменных может быть связано с риском использования слабо коррелирующих с $x$ переменных, что ведёт к неточности и возможно плохим оценкам на малых выборках. В-третьих, более, чем один вопрос об уровне образования может быть задан респонденту в рамках опроса, или же информация об образовании может быть доступна из опросов прошлых лет, если речь идёт об исследовании данных панельной структуры. Такие инструменты, скорее всего, будут сильно коррелировать с $x$, но в этом случае сложно поверить в выполнение предпосылки о некоррелированности между ошибками измерений в $x$ и $z$.
 
Лаги переменных часто используются как инструменты, но и они будут иметь ошибки измерений, так что использование метода инструментальных переменных оправдано только в случае, если отсутствует автокорреляция между ошибками измерений.

Последствия от ошибок измерений могут иметь больший размах в случае анализа панельных данных. Так как в этом случае измерения $x^*_{it}$ берутся за несколько периодов, то оценивание методом инструментальных переменных может быть использовано для получения состоятельных оценок параметров в предположении о некоррелированности ошибок измерений во времени. См. Хсяо (1986, стр. 63-65).

\subsection{Идентификация с помощью дополнительных моментных ограничений} 

Предположения о распределении ошибок регрессии и ошибок измерения $(u, v)$ могут обеспечить возможность идентификации модели. Есть один важный случай, в котором использование информации или допущений относительно распределения ненаблюдаемого истинного значения измеряемой переменной помогает при идентификации. Предположения о нормальности совместного закона распределения $(y, x, x^*)$ вместе с предположением о то, что ошибки регрессии и ошибки измерений являются независимыми одинаково распределёнными нормальными случайными величинами  $v\sim \mathcal{N}[0, \, \sigma^2_v]$ и   $u\sim \mathcal{N}[0, \, \sigma^2_u]$, недостаточно для идентифицируемости модели ошибок измерения. Тем не менее, предпосылка о том, что первые четыре момента $(x^*, u, v)$ существуют и третий момента каждой величины и перекрёстные моменты третьего порядка --- ненулевые,  достаточна для идентификации, что будет продемонстрировано ниже. Данная предпосылка говорит о ненормальности совместного распределения.

Снова построим модель вида (26.10)
\begin{align*}
y&=\beta x^* + u, \\
x&=x^*+v,
\end{align*}
с приведенной формой  $y=\beta x+ \epsilon$, где $\epsilon = u- \beta v$, и которая оценивается с помощью инструментальных переменных. Однако теперь мы добавляем новую информацию: распределение $x^*$ ненормально в том смысле, что асимметрия и эксцесс отличны от нормального Крэгг (1997); Даженэ and Даженэ, (1997); Вансбик и Мейер (2000). Эти предпосылки приводят к следующим шести условиям:
\begin{align*}
&\Expect [(xy)x]=\beta \Expect [x^{*3}], &\ &\Expect [(xy)u]=0, \\
&\Expect [(x^2)x]=\Expect [x^{*3}]+\Expect [v^3],&\ &\Expect [(x^2)u]=-\beta \Expect [v^3], \\
&\Expect [(y^2)x]=\beta^2 \Expect [x^{*3}],&\ &\Expect [(y^2)u]=-\beta \Expect [\epsilon^3],
\end{align*}
Первая строчка означает, что искусственно созданная переменная $x_i y_i$ будет являться валидным инструментом, если $\Expect[x^{*3}_i] \neq 0$.  Из второй строчки видно, что $x^2_i$ будет валидным инструментом, если  $\Expect[x^{*3}_i] \neq 0$, но  $\Expect[v^3_i] = 0$, то есть, если $x^*$ не распределён нормально, но $v$ имеет симметричное распределение. Действительно, чем больше коэффициент асимметрии, тем лучше инструмент. Тем не менее, так как переменная $x^*$ --- ненаблюдаемая, то любые заключения относительно неё должны базироваться на $x$. В последней строчке содержится утверждение, что $y_i^2$ будет валидным инструментом, если третий момент $x^*$ не будет равным нулю при том, что третий момент $\epsilon$ будет нулевым.

При использовании этих моментных условий метод инструментальных переменных может применяться для получения состоятельных оценок параметров модели. Этот пример показывает, как дополнительные предположения о моментах распределения могут помочь для создания хороших инструментов даже в условиях, когда кроме $(y_i, x_i)$ нет доступных данных.

\subsection{Дублированные данные} 

Альтернативное решение возможно, если может быть оценена дисперсия ошибок измерений. В этом случае идея состоит в том, что мы можем скорректировать матрицу выборочных вторых моментов регрессоров $\mathbf{X'X}$ на величину, зависящую от дисперсии и ковариаций ошибок измерений. Обратим внимание, что мы не пытаемся скорректировать сами наблюдения. Вместо этого корректируются выборочные моменты, так как оценка  является функцией от выборочный моментов. Основная идея также обобщается до более сложных моделей.

Когда ковариационная матрица ошибок измерений $\mathbf{\Sigma_{vv}}$ известна, состоятельная оценка коэффициента $\mathbf{\beta}$ может быть получена с помощью формулы
\begin{equation}
\mathbf{\tilde{\beta}}=(\mathbf{X'X}-N \mathbf{\Sigma_{vv}})^{-1} \mathbf{X'y},
\end{equation}
где $N$ –-- размер выборки. Эта оценка состоятельна в силу того, что
\begin{align*}
\mathbf{\tilde{\beta}}&=\plim(N^{-1}\mathbf{X'X}-N \mathbf{\Sigma_{vv}})^{-1} \plim N^{-1} \mathbf{X'y}  \\
&= (\mathbf{\Sigma_{x^*x^*}} + \mathbf{\Sigma_{vv}} - \mathbf{\Sigma_{vv}})^{-1} \mathbf{\Sigma_{x^*x^*} \beta} \\
&= \mathbf{\beta},
\end{align*}
где предел $\plim N^{-1} \mathbf{X'y}=\mathbf{\Sigma_{x^*x^*} \beta}$ получен с использованием равенства $\mathbf{X}=\mathbf{X^*}+\mathbf{V}$ и $\mathbf{y}=\mathbf{X} \beta + (\mathbf{u}-\mathbf{V \beta})$. Для подробного описания способов оценивания $\mathbf{\Sigma}_{vv}$ в практических приложениях можно обратиться к работе Крашинского (2004).

{\bf Дублирование (повторение, реплицирование) данных} –-- это ситуация, в которой доступна несмещенная оценка ненаблюдаемой переменной $\mathbf{X^*}$. Предположим, что ошибка измерений аддитивна и имеется наблюдаемая величина $\mathbf{X}$:
\[
\mathbf{X}=\mathbf{X^*}+\mathbf{V}.
\]
Если $\mathbf{X}$ является несмещенной оценкой $\mathbf{X^*}$, то $\Expect[\mathbf{V|X^*}]=\mathbf{0}$. Если данные дублированы, то это означает, что мы имеем, по крайней мере, два доступных наблюдения $\mathbf{X}$. Также это означает, что с использованием повторных измерений $\mathbf{X}$ мы может получить оценки моментов $\mathbf{V}$, предполагая, что ошибки повторных измерений  не коррелированы.

Предположим, что в нашем распоряжении две скалярных величины (реплики) $X(1)$ и $X(2)$, такие что $X_{(j)}=X^*+V_{(j)}, \, j=1, \, 2$. Тогда $\Var[V_{(j)}]=\Expect[X^2_{(j)}]-\Expect[X_{(1)}X_{(2)}]$, которая может быть оценена, исходя из выборочного среднего, как $N^{-1} \Sigma_i [X^2_{(j),i}-X_{(1),i}X_{(2),i}]$. В этом случае параметры регрессии могут быть оценены  по формуле (26.14). 

В качестве примера предположим, что мы хотим предсказать средний  балл (GPA) за первый год обучения в колледже, используя результаты за экзамен SAT в старших классах (тест на проверку академических способностей). Известно, что наблюдаемые баллы за SAT для одного и того же человека различаются в разных попытках сдачи экзамена. Положим, что $x^*$ отражает истинный балл за SAT, а $x_1$ и $x_2$ отражают наблюдаемые результаты двух разных экзаменов. Тогда $x_1=x^*+v_1$, $x_2=x^*+v_2$, и предполагается, что $v_1$ и $v_2$ независимы и имеют одинаковую дисперсию $\sigma^2_v$. Из этого следует, что $\Cov[x_1, x_2]=\sigma^2_{x^*}$, $\Var[x_1]=\Var[x_2]=\sigma^2_{x^*}+\sigma^2_v$ и $\Corr^2[x_1,x_2]=\sigma^2_{x^*} / (\sigma^2_{x^*}+\sigma^2_v)$. Согласно исследованиям, тест имеет надёжность 0.9, что означает, что корреляция между результатами двух сдач теста равна 0.9 и квадрат корреляции равен 0.81. Таким образом, $\sigma^2_{x^*} / (\sigma^2_{x^*}+\sigma^2_v)=0.81$. Из (26.8) следует, что $\plim \widehat{\beta}=0.81 \times \beta$, то есть, учет ошибок измерений балла за SAT помогает лучше предсказать результаты первого года обучения (GPA), чем МНК.

\subsection{Верифицирующие данные} 
Иногда верифицирующая выборка формируется для дополнительной проверки правильности исходных ответов. Хотя {\bf верифицирующая выборка} (validation sample) и принадлежит исследуемой совокупности, она может быть получена из другого независимого источника. Например, пациенты могут заполнять анкету об оказанных им медицинских услугах, и те, кто оказывают эти услуги, могут ответить на вопросы в качестве верифицирующей информации. Другой пример касается работников, которые могут предоставить информацию о чем-то, тогда как верифицирована она может быть на основе информации, полученной от работодателей. Один из лучших примеров в экономике –-- верификация на базе Панельного исследования динамики доходов (Panel Study of Income Dynamics, PSID) Баунда и др. (1994).

Пусть $\mathbf{X}$ –-- матрица регрессоров, измеренных с ошибками, размерности $N \times K$  и пусть $X_v$ –-- матрица контрольных измерений размерности $M \times K$. Мы можем использовать верифицирующие данные, построив регрессию $X_v$ на $\mathbf{X}$ и сгенерировав <<предсказанные>> значения $\mathbf{X[X'X]}^{-1} \mathbf{X'X}_v$, которые послужат заменой искаженной матрице $\mathbf{X}$. Для нелинейных моделей используется более сложный подход, см. Ли и Сепански (1995).

Использование сгенерированных регрессоров в интересующей исследователя регрессии  может быть полезной стратегией, если предсказания взяты из хорошо подогнанной регрессии. Сгенерированные регрессоры являются оценками истинных значений и, таким образом, связаны с неопределённостью оценивания. Эта неопределённость должна быть учтена при оценивании дисперсии оценок коэффициентов. Соответствующая теория описана в Разделе 6.8.

\section{Ошибки измерений в нелинейных моделях} 

Нелинейные модели, что должно быть достаточно понятно, включают в себя огромный спектр моделей. Получение общих результатов, таких как смещение затухания, для широкого класса моделей, представляет собой непростую задачу. Довольно часто общие результаты получают при упрощающих  предположениях, в то время как особые результаты можно получить для частных случаев. Таким образом, неудивительно, что развитие темы нелинейных моделей в литературе порождает много процедур и подходов, специфических и применимых к определённого рода моделям. Например, в случае моделей бинарного выбора с ошибками измерений в левой части естественно обращать внимание на проблему неверной классификации; в случае счетных моделей  с ошибками измерений в левой части также естественно концентрироваться на проблеме занижения и завышения показателей. Мотивированный такими сложностями, Хсяо (1992) предложил переключить внимание от поиска решений для общего вида моделей на более специальные типы задач. Однако в поиске специфических результатов есть опасность узости и потери части общих результатов. Таким образом, мы начинаем рассмотрение с некоторых общих результатов.

\subsection{Идентификация с помощью инструментальных переменных} 

Общая техника для линейных моделей ошибок переменных --– метод инструментальных переменных. Для нелинейной по независимым переменным регрессионной модели было показано Амэмией (1985), что оценка метода инструментальных переменных в общем случае несостоятельна, кроме случая, когда выполнена предпосылка о сжимающейся (shrinking) ковариационной матрице.

Простое представление описанной выше идеи основано на регрессионном уравнении
\begin{equation}
y=\beta_0 +\beta_1 f(x^*)+ \epsilon,
\end{equation}
где $f(x^*)$ --- гладкая, дифференцируемая ограниченная функция скалярного регрессора $x^*$, измеренного без ошибок. Наблюдаемая переменная определяется как $x=x^*+v$, где $v$ --– ошибка измерений. Заменяя переменную $x^*$ и используя разложение в ряд Тейлора функции $f(x-v)$ в окрестности точки $x$, получаем
\begin{equation}
y=\beta_0 +\beta_1 f(x)+ \epsilon - \beta_1 f^{(1)}(x)v + \beta_1 \sum \limits^{\infty}_{j=2} f^{(j)}(x)(-v)^j/j!,
\end{equation}
где $f^{(j)}(\cdot)$ --- производная $j$-ого порядка функции $f(\cdot)$. В случае квадратичной функции $f(x)=x^2+\gamma x$, имеем $f^{(1)}(x)=2x+ \gamma$, $f^{(1)}(x)=2$ и $f^{(j)}(x)=0, \, j>2$. Тогда
\begin{align}
y&=\beta_0 + \beta_1 (x^2+ \gamma x) + \epsilon - \beta_1 (2x+ \gamma)v + \beta_1 2v^1 /2 \notag \\
&= \beta_0 + \beta_1 x^2 + \beta_1 \gamma x + (\epsilon- \beta_1 xv - \beta_1 \gamma v + \beta_1 v^2),
\end{align}
Следовательно, валидные инструменты должны  коррелировать с $x^2$ и $x$, но не коррелировать с $u=(\epsilon- \beta_1 xv - \beta_1 \gamma v + \beta_1 v^2)$. Понятно, что недостаточно, чтобы $v$ и $\epsilon$ по отдельности не коррелировали с инструментами. Это означает, что инструментальная переменная для $f(x)$ должна удовлетворять более жестким требованиям, чем в линейном случае.

В более общем случае, используя аппроксимацию Тейлора, Амэмия показал, что инструментальные переменные не дают состоятельных оценок в нелинейных моделях ошибок переменных, так как остаточный член включает в себя как ошибку измерений, так и наблюдаемую зараженную ошибками переменную. Таким образом, невозможно найти инструментальную переменную, которая бы сильно коррелировала с наблюдаемой переменной и не коррелировала с остаточным членом. Более того, с практической точки зрения, непросто найти подтверждение валидности инструмента при оценивании из-за ограниченности информации о латентной переменной $(x^*)$ и ошибках измерений.
 
\subsection{Идентификация с помощью дублированных данных} 

Имея в виду сложности применения метода инструментальных переменных, приведём ещё два существующих альтернативных подхода.

Первый подразумевает введение очень жестких предположений об условном распределении ненаблюдаемой переменной $x^*$ при фиксированном наблюдаемом $x$. Такие предположения, усиленные техническими условиями, позволяют идентифицировать параметры модели. Такой подход можно встретить у Амэмии (1985) и Хсяо (1989).

Второй подход предусматривает возможность получения большого количества измерений каждого ненаблюдаемого $x^*$, обозначенного как $x_{(j)}$. Тогда среднее по реплицированным измерениям для каждого $x^*$ служит заменой для ненаблюдаемого регрессора. Мы получаем состоятельные оценки нелинейной модели, так как ковариация ошибок измерений сокращается до нуля при увеличении числа реплик, см. работу Амэмия (1985). К сожалению, в эконометрике этот способ редко воплотим.

Так как не существует типичной структуры нелинейной модели ошибок измерения, которая может быть использована для идентификации и оценивания регрессионной модели, рассмотрим несколько специальных нелинейных регрессий.

Хаусман, Ньюи и Пауэлл (1995) анализировали полиномиальные кривые Энгла на основе данных Исследования потребительских расходов (Consumer Expenditure Survey). Их полиномиальная функция была линейна по параметрам. Они доказали, что, при условиях регулярности, и инструментальные переменные, и дополнительные измерения могут быть использованы для получения состоятельных и асимптотически нормальных оценок. Применительно к этому случаю, ближайшие квартальные данные использовались и как дублирующая информация и как инструментальные переменные. Далее они предположили, что нелинейная функция в общем может быть аппроксимирована полиномиальной функцией. Тем не менее, они признали, что инструментальные переменные не могут быть введены в этом случае, так что требуются дополнительные измерения истинных регрессоров.

Ли (2002) предложил общий двухшаговый подход к проблеме нелинейных моделей ошибок переменных, который основан на дублированных измерениях. В качестве первого шага, на базе эмпирических характеристических функций и обратного преобразования Фурье получают непараметрические оценки для условной функции плотности латентных переменных. После получения оценки плотности строятся полупараметрические оценки нелинейного метода наименьших квадратов с использованием критерия минимального расстояния. Он установил состоятельность этих оценок. Эти оценки также робастны в том смысле, что не требуют никакого знания о функциональной форме латентных переменных. Подход Ли может быть применён в ситуации любых нелинейных моделей ошибок переменных, если доступны дублированные измерения. Тем не менее, асимптотическое распределение оценки не установлено.

\subsection{Ошибки измерений в зависимых переменных} 
В линейной регрессионной модели ошибки измерений в зависимой переменной увеличивают стандартные ошибки параметров регрессии, но не ведут к несостоятельности оценок. В нелинейной модели возникают ещё ряд последствий.

В одном из классов моделей предполагается наличие неверной классификации наблюдений в моделях качественного выбора. Эта идея породила много работ, связанных с ошибкой из-за декларирования неверных данных.

\subsection*{Модели дискретного выбора} 

Потерба и Саммерс (1995) в своём исследовании влияния страхования от безработицы на длительность безработицы с использованием данных Текущего обследования населения (Current Population Survey, CPS) обобщили вероятностную модель, чтобы учесть неправильную классификацию индивидов при смене статуса на рынке труда. Конкретнее, они фокусировались на возможных ошибках отнесения к одному из трёх классов: занятные, безработные и не входящие в рабочую силу. Они анализировали множественную логит-модель с учетом некоторых особенностей данных: предполагалось, что все безработные индивиды правильно ответили на вопрос о статусе занятости в первый месяц исследования. Их результаты показали, что страхование от безработицы увеличивает длительность безработицы, и что учитывание неправильного отнесения в группы по статусу на рынке труда усиливает  влияние страхования безработицы на её длительность. Тем не менее, их модель основана на предпосылке о том, что вероятность предоставления неправильных ответов фиксирована и не коррелирует с индивидуальными характеристиками, которая, с чем согласны сами авторы, на практике маловероятно выполняется. Хотя авторы утверждают, что оценки параметров состоятельные, Хаусман, Абревая и Скотт-Мортон (1998) спорят с ними, утверждая, что стандартные ошибки несостоятельно оценены из-за игнорирования изменчивости вероятности ошибки и не блочно-диагональной формы информационной матрицы.

Хаусман и др. (1998) предложили параметрический метод оценивания модели бинарного выбора с ошибками классификации. Тем не менее, их параметрический метод требует знания закона распределения ошибок. Они указывают на то, что оценки параметром могут быть несостоятельными, если предпосылка о типе распределения не выполняется. Также они предлагают двухшаговый полупараметрический метод. Основное условие для идентификации в этой модели, которое, как они показали, слабее условия для параметрического метода, состоит в том, что ожидаемое значение наблюдаемой зависимой переменной есть возрастающая функция от некоторого индекса. В сравнении с подходом Потерба и Саммерса (1995), их подход робастен в том смысле, что вероятность неверной классификации является функцией от индивидуальных характеристик. Используя CPS и PSID, они показали, что имеет место серьезные ошибки классификации в переменной смены работы.

Кляйн и Шерман (1997) разработали {\bf орбит-модель} (с чертами модели упорядоченного выбора и тобит-модели) для оценки возможного спроса на новый видео продукт. Они выявили, что потенциальные потребители завышают спрос. Орбит-модель представляет собой двухшаговую процедуру с оцениванием параметров стандартной тобит-модели для реального будущего спроса на первом шаге и с оцениванием функции связи между текущим предполагаемым спросом и реальным будущим спросом. Далее они доказывают состоятельность и асимптотическую нормальность оценок орбит-модели. Несмотря на это, идентификация модели требует выполнения предпосылки о том, что предполагаемый нулевой спрос действительно будет нулевым в будущем. Это может быть достаточно сильным предположением.
 
Хсяо и Сан (1999) использовали данные обследования спроса на сложную электронику. Они показывали, что респонденты могут давать смещенную информацию относительно спроса. Они предложили модель случайных ответов и модель одностороннего смещения для преувеличений.  В их модели  различные параметрические вероятности соответствуют истинному и альтернативному выбору.  Логит или пробит функции используются для истинных выявленных предпочтений. Они определили, что <<имеет место значительное смещение в ответах, и на анализируемом рынке ставки и эластичности цен являются более скромными, чем оценки, полученные на основе  предположений о сообщении потребителями своих истинных предпочтений>>.

\subsection*{Регрессии дискретных переменных} 
В нелинейной регрессии счетных переменных Камерон и Триведи (1998) предложили подход для моделирования  случайного занижения значений. Их модель порождает обобщенную пуассоновскую и отрицательную биномиальную модели для счетных данных, путем рассмотрения индикатора записи события.  Говоря точнее, для каждого наступления события вводится бернуллиевская случайная величина, являющееся индикатором того, что событие будет зафиксировано. При положительной вероятности того, что событие не будет зафиксировано,  распределение записанных событий будет иметь меньшее среднее и дисперсию, чем распределение действительно наступавших событий. Далее они исследуют оценку модели, полученную методом максимального правдоподобия, квази-обобщенным методом псевдо-максимального правдоподобия и методом моментов. Основываясь на методе Монте-Карло, они определили, что использование метода максимального правдоподобия хорошо в случаях выборок, превосходящих 500 наблюдений.

Джордан и др. (1997) применили метод ошибок в переменных в модели пуассоновской регрессии. В исследовании смертности от рака желудка в пяти регионах Японии они отметили, что регрессор (например, уровень ликопена в плазме) неизвестен, а при его оценке возникают случайные ошибки. Принимая предпосылку о том, что ошибка измерений нормально распределена, они применяют байесовский подход и получают апостериорное распределение параметров, используя сэмплирование Гиббса. Результаты говорят о том, что скорректированная модель даёт более точные оценки параметров, даже когда выборка мала.

\subsection{Пуассоновская регрессия с ошибками измерений в независимых переменных} 
Теперь мы более детально рассмотрим один  пример нелинейной регрессионной модели с аддитивными ошибками измерений в независимых переменных. Этот пример иллюстрирует и последствия от такого рода ошибок измерений, и доступные стратегии оценивания.

Гуо и Ли (2002) показали, что ошибки измерений в регрессорах в общем случае ведут к завышенной дисперсии наблюдаемых данных. Они также показали с использованием Монте-Карло симуляций, что смещение возникает в случае, если завышенная дисперсия, вызванная ошибками измерений, неверно смоделирована как возникшая вследствие ненаблюдаемой неоднородности. Таким образом, из наличия завышенной дисперсии не обязательно следует вывод о ненаблюдаемой гетерогенности.

Стефански (1989) и Накамура (1990) предложили {\bf скорректированную скоринговую оценку} \emph{(corrected score estimator)}, которая является состоятельной в случае наличия ошибок измерений. В частности, Накамура (1990) нашел в явном виде скоринговую функцию  для случая, когда ошибки измерений распределены нормально и доступны дублированные наблюдения. Гуо и Ли (2002) обобщили результаты Накамуры (Nakamura, 1990).

\subsection*{Ошибки наблюдений и завышенная дисперсия} 
В этом Разделе мы рассмотрим пуассоновскую регрессионную модель, в которой дискретная случайная переменная $y$ распределена на закону Пуассона с параметром $\mu = \exp(\mathbf{x^{*\prime} \beta})$, где $\mathbf{\beta}$ --- вектор параметров размерности $K \times 1$. Как известно, в пуассоновской регрессионной модели  на дисперсию наложено требование:
\begin{equation}
\Expect[y| \mathbf{x^*}]=\Var[y \mid  \mathbf{x^*}].
\end{equation} 
Если ошибка измерений имеет аддитивную форму, то
\[
\mathbf{x}=\mathbf{x^*}+ \epsilon,
\]
где $\epsilon$ предполагается независимой от ненаблюдаемой латентной переменной $\mathbf{x^*}$, обладающей нулевым средним и ковариационной матрицей $\mathbf{\Sigma_{\epsilon}}$. Это замечание включает в рассмотрение и случай, когда все или некоторые объясняющие переменные измерены с ошибками.

Ошибки измерений увеличивают дисперсию, см работу Чешера (1991). Это применимо к пуассоновской регрессии в том смысле, что, хотя (26.18) выполняется при фиксированном $\mathbf{x^*}$, однако результат меняется, если фиксировать  $\mathbf{x}$. Вместо этого мы получаем $\Expect[y| \mathbf{x}]<\Var[y| \mathbf{x^*}]$, отчасти потому, что $\Expect[y| \mathbf{x^*}] \neq \Expect[y| \mathbf{x}]$  и $\Var[y| \mathbf{x^*} \neq \Var[y| \mathbf{x^*}]$.

Если $g(\mathbf{x^*|x})$ обозначает условную плотность $\mathbf{x^*}$ при заданном $\mathbf{x}$, тогда, как Гуо и Ли показали, 
\begin{align}
\Expect[y| \mathbf{x}] &= \int \Expect[y| \mathbf{x^*}]g(\mathbf{x^*|x})\, d\mathbf{x^*} \notag \\
&= \int \Expect[y^2| \mathbf{x^*}]g(\mathbf{x^*|x})\, d\mathbf{x^*} - \int (\Expect[y| \mathbf{x^*}])^2 g(\mathbf{x^*|x})\, d\mathbf{x^*},
\end{align}
И, используя (26.18), условная дисперсия $y$ при заданном $\mathbf{x}$ будет следующей:
\begin{equation}
\Var[y| \mathbf{x^*}]= \int \Expect[y^2| \mathbf{x^*}]g(\mathbf{x^*|x})\, d\mathbf{x^*} -  \left[ \int \Expect[y| \mathbf{x^*}]g(\mathbf{x^*|x})\, d\mathbf{x^*} \right]^2.
\end{equation}

Сравнение (26.19) и (26.20) показывает, что первая компонента в скобках в (26.19) совпадает с первой компонентой в (26.20). Используя этот факт, Гуо и Ли  показали, что
\begin{equation}
 \left[ \int \Expect[y| \mathbf{x^*}]g(\mathbf{x^*|x})\, d\mathbf{x^*} \right]^2 \leqslant \int (\Expect[y| \mathbf{x^*}])^2 g(\mathbf{x^*|x})\, d\mathbf{x^*},
\end{equation}
что может быть интерпретировано, как завышение дисперсии вследствие наличия ошибок измерений.

\subsection*{Оценивание модели ошибок в переменных} 
Когда $\mathbf{x}$ искажен ошибками измерений, оценивание методом максимального правдоподобия или нелинейным методом наименьших квадратов, основанными на наблюдениях $(y, \mathbf{x})$ не  дает состоятельных оценок. Замена  регрессора $\mathbf{x^*}$ на $x$ называется <<наивной>> моделью.

Есть две темы для размышлений. Во-первых, почему ММП даёт несостоятельные оценки, когда появляются ошибки измерений? Во-вторых, возможно ли вообще получить состоятельные оценки? Ответ на второй вопрос –-- <<да>>, если мы применяем {\bf метод скорректированной скоринговой функции} для обобщенных линейных моделей, согласно работам Стефански (1989) и Накамуры (1990). 

Идея, лежащая в основе метода скорректированной скоринговой функции заключается в том, что условное распределение скорректированной оценки коэффициента при фиксированной независимой переменной $\mathbf{x^*}$ и зависимой переменной $y$, центрировано относительно ММП-оценки, что обеспечивает состоятельность оценки истинного значения интересующего параметра.

\subsection*{Несостоятельные и состоятельные оценки} 
Пусть есть выборка $N$ наблюдений $(y_i, \mathbf{x}^*_i), \, i=1, \dots,N$ , которые имеют распределение Пуассона с вероятностью
\[
\Prob[Y_i=y_i|\mathbf{x}^*_i]=\frac{e^{-\mu_i(\mathbf{\beta_0})}\mu_i(\mathbf{\beta_0})^{y_i}}{y_i!},
\]
где $\mu_i(\beta_0)=\exp(\mathbf{x}^{*\prime}_i \mathbf{\beta_0})$. При заданных наблюдениях $(y_i, \mathbf{x}^*_i), \, i=1, \dots, N$ ММП-оценки коэффициентов $\mathbf{\widehat{\beta}}$ состоятельные, если предел по вероятности среднего значения логарифма функции правдоподобия
\begin{align}
\plim N^{-1}\ln L(\mathbf{\beta})&=N^{-1} \sum \limits_i \{ -e^{\mathbf{x}^{*\prime}_i \mathbf{\beta}} + y_i \mathbf{x}^{*\prime}_i \mathbf{\beta} - \ln y_i! \} \notag \\
&= \Expect_{y,\mathbf{x^*}}[-e^{\mathbf{x^{*\prime}} \mathbf{\beta}} + y \mathbf{x^{*\prime}} \mathbf{\beta} - \ln y! ]
\end{align}
достигает максимума при $\mathbf{\beta} = \mathbf{\beta_0}$.

Предположим, что мы наблюдаем $\mathbf{x}_i$ вместо $\mathbf{x}^*_i$, где $\mathbf{x}_i=\mathbf{x}^*_i+\mathbf{\epsilon}_i$ и $\epsilon_i \sim \mathcal{N}[\mathbf{0}, \, \mathbf{\Sigma_{\epsilon}}]$ независимы от $\mathbf{x}^*_i$. Тогда $y_i| \mathbf{x}_i$ не распределено по Пуассону. Если, несмотря на это, использовать {\bf  <<наивную>> модель Пуассона}, полученная оценка $\mathbf{\tilde{\beta}}$ максимизирует
\begin{equation}
Q(\mathbf{\beta})= N^{-1} \sum \limits_i \{ -e^{\mathbf{x}^{*\prime}_i \mathbf{\beta}} + y_i \mathbf{x}^{*\prime}_i \mathbf{\beta} - \ln y_i! \}.
\end{equation}
Этот логарифм неверно специфицированной функции правдоподобия сходится к функции
\begin{equation}
\plim Q(\mathbf{\beta})=\Expect_{y,\mathbf{x}^*}[-e^{\mathbf{x}^{*\prime} \mathbf{\beta}} + y \mathbf{x^{*\prime}} \mathbf{\beta} - \ln y! ] +  \Expect_{\mathbf{x^*}} [-e^{\mathbf{x^{*\prime}} \mathbf{\beta}}] (\Expect_{\epsilon}[e^{\mathbf{\epsilon}' \mathbf{\beta}}]-1),
\end{equation}
которая, в общем случае, не достигает максимума при $\mathbf{\beta}= \mathbf{\beta_0}$. Поэтому $\mathbf{\tilde{\beta}}$ не является состоятельной оценкой $\mathbf{\beta}_0$.

Подходящая модификация этой целевой функции обеспечивает состоятельные оценки. Из уравнений (26.22) и (26.24) следует, что
\[
\{ \plim Q(\mathbf{\beta})-\Expect_{\mathbf{x^*}} [-e^{\mathbf{x^*}' \mathbf{\beta}}](\Expect_{\epsilon}[e^{\mathbf{\epsilon}' \mathbf{\beta}}]-1) \} = \plim N^{-1}\ln L(\mathbf{\beta}).
\]
Поэтому можно максимизировать целевую функцию
\[
Q^+(\mathbf{\beta})=N^{-1} \sum \limits_i \{ -e^{\mathbf{x}^{*\prime}_i \mathbf{\beta}} + y_i \mathbf{x}^{*\prime}_i \mathbf{\beta} - \ln y_i! \} - \Expect_{\mathbf{x^*}} [-e^{\mathbf{x^{*\prime}} \mathbf{\beta}}](\Expect_{\epsilon}[e^{\mathbf{\epsilon}' \mathbf{\beta}}]-1),
\]
так как $Q^+(\mathbf{\beta})$ стремится к $-N^{-1} \sum \limits_i \ln L(\mathbf{\beta})$. Теперь, учитывая независимость $x^*$ и $\mathbf{\epsilon}$,
\[
\Expect_{\mathbf{x^*}}[ -e^{\mathbf{x^*}'_i \mathbf{\beta}}]\Expect_{\epsilon}[e^{\mathbf{\epsilon}' \mathbf{\beta}}] = \Expect_{\mathbf{x^*},\epsilon}[e^{(\mathbf{x^*}+\mathbf{\epsilon})' \mathbf{\beta}}]=-\Expect_{\mathbf{x}}[e^{\mathbf{x}'_i \mathbf{\beta}}],
\]
что состоятельно оценивается как $-N^{-1} \sum \limits_i -e^{\mathbf{x}_i' \mathbf{\beta}}$. После  упрощения следует, что максимизация $Q^+(\mathbf{\beta})$ эквивалентна максимизации
\begin{equation}
Q^{++}(\mathbf{\beta})=N^{-1} \sum \limits_i \{ y_i \mathbf{x}^*_i \mathbf{\beta} - \ln y! \} - \Expect_{\mathbf{x^*}} [e^{\mathbf{x^*}' \mathbf{\beta}}].
\end{equation}
Это даёт состоятельную оценку $\mathbf{\beta}_0$. Использование этого метода требует подходящей оценки $\Expect_{\mathbf{x}^*}[ e^{\mathbf{x}^{*\prime} \mathbf{\beta}}]$, которая возможна, если доступны дублированные данные. Если распределение объясняющих переменных специфицировано с помощью неизвестных параметров, то эти параметры могут быть оценены с помощью реплицированных измерений. Таким образом, можно получить оценку $\Expect_{\mathbf{x}^*}[ e^{\mathbf{x}^{*\prime} \mathbf{\beta}}]$.

Оценка $\mathbf{\beta_C}$, которая максимизирует (26.25) была названа {\bf скорректированной скоринговой оценкой} Гуо и Ли (2002), так как это корень уравнения  скорректированной скоринговой функции $\sum_i (y_i \mathbf{x}_i- \Expect_{\mathbf{x^*}}[\mathbf{x^*}e^{\mathbf{x^*}'\mathbf{\beta}}])=\mathbf{0}$. Гуо и Ли также показали асимптотическую нормальность этой оценки. Асимптотическая оценка ковариационной матрицы равна $\widehat{\Var}[\widehat{\mathbf{\beta}}]=N^{-1} \widehat{\mathbf{A}}^{-1}\widehat{\mathbf{B}}\widehat{\mathbf{A}}^{-1}$, где 
\begin{align*}
\widehat{\mathbf{A}}&=\Expect_{\mathbf{x^*}}[e^{\mathbf{x}^{*\prime} \widehat{\mathbf{\beta_C}}} \mathbf{x^*} \mathbf{x^*}'], \\
\widehat{\mathbf{B}}&=N^{-1} \sum \limits_i (y_i \mathbf{x}_i - \Expect_{\mathbf{x^*}}[e^{\mathbf{x}^{*\prime} \widehat{\mathbf{\beta_C}}} \mathbf{x^*}]) (y_i \mathbf{x}_i - \Expect_{\mathbf{x^*}}[e^{\mathbf{x}^{*\prime} \widehat{\mathbf{\beta_C}}} \mathbf{x^*}])'.
\end{align*}

Накамура (1990) ввёл сильную предпосылку о том, что ошибки измерений $\mathbf{\varepsilon}$ имеют нормальное распределение $\mathcal{N}[\mathbf{0}, \, \mathbf{\Omega}]$. Тогда
\[
\exp (\mathbf{x^*}' \mathbf{\beta}) = \Expect_{\mathbf{x|x^*}} \left[ \exp \left(\mathbf{x}' \mathbf{\beta} - (\mathbf{\beta' \Omega \beta} /2) \right) \right].
\]
Согласно закону повторных ожиданий,
\[
\Expect_{\mathbf{x^*}} [\exp (\mathbf{x^*}' \mathbf{\beta})] = \Expect_{\mathbf{x}} \left[ \exp \left(\mathbf{x}' \mathbf{\beta} - (\mathbf{\beta' \Omega \beta} /2) \right) \right],
\]
Что может быть состоятельно оценено, как $N^{-1} \sum \limits_i [ \exp (\mathbf{x}' \mathbf{\beta} - (\mathbf{\beta' \Omega \beta} /2) )]$. Следовательно, для $Q(\mathbf{\beta})$ в (26.23) предел по вероятности, приведённый в (26.24), сводится к
\[
\plim Q(\mathbf{\beta}) = N^{-1} \sum \limits_i \left[ y_i \mathbf{x}'_i \mathbf{\beta} - \ln y_! - \exp \left(\mathbf{x}' \mathbf{\beta} - (\mathbf{\beta' \Omega \beta} /2) \right) \right].
\]
Это логарифм {\bf скорректированной функции правдоподобия}, предложенный Накамурой (1990). Максимизация по $\mathbf{\beta}$ позволяет получить состоятельные оценки $\mathbf{\beta_0}$.

Подход Накамуры  напоминает один из способов оценивания линейной регрессии с ошибками измерений (см. (26.14)) при известной оценке ковариационной матрицы ошибок измерений. Как и в том случае, для максимизации скорректированной скоринговой функции Накамуры требуется знание о $\mathbf{\Omega}$, ковариационной матрице ошибок измерений. Она может быть получена из дублированных данных. Тем не менее, если регрессоры преимущественно дискретны, то предпосылка о нормальности ошибок измерений неправдоподобна. В таких случаях подход Гуо и Ли выглядит более привлекательным.

Для случая множественности регрессоров $\mathbf{x^*}$, вычисление $\Expect [\exp (\mathbf{x^*}' \mathbf{\beta})]$ непросто, даже если известно распределение $\mathbf{x^*}$, так как требуется работа с многомерными интегралами. Методы, основанные на симуляции Ли (2002) обеспечивают возможное разрешение этой проблемы.

Применение некоторых других нелинейных моделей ошибок в переменных также требует реплицированных наблюдений; см. например, работы Хсяо (1992) и Хаусмана, Ньюи и Пауэлла (1995). Панельные данные могут обеспечить дублированные наблюдения на уровне индивидов. Например, рассмотрим случай, когда имеется скалярный регрессор $x^*$, для которого имеются две реплики измерений $x$, так как $x_{ij} = x_i + \epsilon_{ij}$ для $i=1,\dots,N$ и $j=1, \, 2$. Тогда оценка $\sigma^2_{\epsilon}$, полученная методом моментов, будет равна $\widehat{\sigma}^2_{\epsilon} = \sum \limits_i (x^2_{i1}+x^2_{i2} - 2x_{i1}x_{i2})/2N$. Таким образом, и среднее значение, и дисперсия $\mathbf{x^*}$ могут быть оценены.
 
\section{Пример симуляции смещения затухания} 
Аналитические результаты для линейной модели приведены в Разделы 26.2, но результаты в нелинейных моделях получить намного сложнее. Здесь мы приведём два примера симуляции, один из которых --- для логит модели, другой --- для линейной в логарифмах модели, которые иллюстрируют смещение затухания в нелинейной регрессии с ошибками измерений в регрессорах.

В первом примере данные порождены логит-моделью, где
\begin{align*}
y^* &=\alpha^* + \beta^* + \epsilon, \\
x^* &\sim \mathcal{U}[0, \, 1], \, \epsilon \sim \text{logistic}, \\
y &= 
\begin{cases}
0, \text{если} y^* &\leqslant0 ,\\
1, \text{если} y^* &>0.
\end{cases}
\end{align*}
Усложнением является то, что $x*$ измерен с ошибками, так что
\begin{align*}
x &=x^*+v, \\
v &\sim \mathcal{N}[0, \, \sigma^2_v].
\end{align*}
Так как $x^* \sim \mathcal{U}[0, \, 1]$ , он имеет дисперсию $\sigma^2_{x^*}=1/12$, и отношение шум--сигнал равно $s=12\sigma^2_v$. Была оценена логит-регрессия $y$ на $x^*$.

Чтобы провести симуляцию, мы строим логит регрессию $y$ на $x$ для шести различных значений отношения шум--сигнал, включая 0, что будет являться базой для сравнения. Размер выборки --- 1000, количество проведённых симуляций --- 100. 

В Таблице 26.1 отражены средние значения $(\widehat{\alpha}, \, \widehat{\beta})$ при 100 симуляциях, где $\widehat{\alpha}$ и $\widehat{\beta}$ --- оценки свободного члена и коэффициента наклона из логит регрессии $y$ на $x$, а не правильной регрессии $y$ на $x^*$, для выборки из $N=1000$ наблюдений и шести различных значений $\sigma^2_v$, которые дают шесть различных значений отношения шум--сигнал $s$. Первая колонка со значением $s=0$ является базовой. Напомним, что для линейной МНК модели такой же постановки  мультипликативное смещение оценки коэффициента наклона равно $1/(1+s)$, или 0.96, 0.8, 0.5, 0.2 и 0.1 соответственно. В этом примере  направление смещений то же, но для случая логит-модели они сравнительно больше.


\begin{table}[h!]
\caption{\label{tab:26.1 } Смещение затухания в логит-модели с ошибками измерения}
\begin{center}
\begin{tabular}{lcccccc}
\hline
\hline
Отношение шум-сигнал & 0 & 0.04 & 0.25 & 1 & 4 & 9 \\
\hline
Среднее $\hat{\alpha}$ &   0.785 & 1.062 & 1.406 & 1.548 & 1.570 & 1.596  \\
Среднее $\hat{\beta}$ &    1.799 & 1.224 & 0.446 & 0.125 & 0.037 & 0.012 \\
\hline
\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[h!]
\caption{\label{tab:26.2 } Смещение затухания в нелинейной регресии с ошибками измерения}
\begin{center}
\begin{tabular}{lcccccc}
\hline
\hline
$\sigma^2_x/\sigma^2_{x^*}$ & 0.00025 & 0.0025 & 0.025 & 0.25 & 2.5 & 25 \\
\hline
Среднее $\hat{\beta}$ &   0.393 & 0.383 & 0.341 & 0.217 & 0.063 & 0.020  \\
\hline
\end{tabular}
\end{center}
\end{table}

Второй пример –-- парная линейная в логарифмах мультипликативная регрессионная модель с $\alpha=4$ и $\beta=0.4$ и аддитивными ошибками измерений обеих переменных. В этом случае постановка следующая:
\begin{align*}
y^* &= 4{x^*}^{0.4}u, \, u \sim \mathcal{N}[10, \, 0.0001], \\
x^* &= 100+ \mathcal{U}[0, \, 1], \\
y &= y^*+ \epsilon_y, \, \epsilon_y \sim \mathcal{N}[0, \, \sigma^2_y], \\
x &= x^*+ \epsilon_x, \, \epsilon_x \sim \mathcal{N}[0, \, \sigma^2_x].
\end{align*}
В симуляции используется выборка размером 1000, количество симуляций --- 100. Мы меняем значение дисперсии $x^*$ от эксперимента к эксперименту, получая в результате следующие значения $\sigma^2_{x} / \sigma^2_{x^*}$: 0.001, 0.01, 0.1, 1,5, 10, 50, 100, 1000 и 5000.

В верхней строке Таблицы 26.2 приведены средние значения оценок коэффициента наклона в разных экспериментах, в которых менялось значение отношения шум--сигнал. Снова видно, что имеет место смещение затухания.

Оба примера дают результаты, соответствующие <<железному закону эконометрики>>.

\section{Библиографические заметки} 

Работа Вансбика и Мейера (2000) является самой современной и полной написанной работой по ошибкам измерений с точки зрения эконометрики. В ней содержится глубокий анализ большего числа тем, рассмотренных в этой Главе с упором на линейные модели. Авторы также включили несколько глав, в которых ошибки измерения связаны с факторными моделями, моделями латентной переменной и моделями структурных уравнений. Говоря о результатах, авторы избегают фразы <<это может быть показано>>, чтобы подробно их изложить. Также с эконометрической позиции, Хаусман (2000) приводит обзор последних результатов, полученных в работах его коллег и его самого. Баунд, Браун и Матьовец (2001) исследовали вопросы ошибок измерений на рынке труда.

Проблема ошибок измерений хорошо представлена в статистической литературе. Полезна ссылка на работу Фуллера (1987), в частности, интересен его разбор подхода ортогональных регрессий, который применим в случае, если известно отношение шум-сигнал. Хотя наш анализ линейных моделей стандартен для эконометрической литературы, читателю также стоит ознакомиться с альтернативной моделью ошибок Берксона, в которой ненаблюдаемая истинная переменная предполагается константой, но несовершенство измерений является источником ошибок, а также с неоклассической моделью ошибок измерений, рассмотренной Ангристом и Крюгером (1999). Мадански (1959) приводит обзор более ранних результатов и подходов. Смотрите также работу Стефански (2000).

\begin{enumerate}
\item Модели панельных данных с ошибками измерений анализируются в работе Бьорна (1992).
\item Интересная тема обратной регрессии рассматривалась Голдбергером (1984) и Грином (1983) в их комментариях к работе Конвея и Робертса (1983). Лимер (1978) привёл глубокий анализ обратных регрессий с байесовских позиций. Хан и Хаусман (2002) использовали идею обратных регрессий для спецификации теста на валидность инструментов в рамках проблемы ошибок измерений. Эта задача связана с тем, что доступные инструменты могут быть слабыми, что проводит к плохим оценкам. Идея Хана-Хаусмана состоит в получении оценок инструментальных переменных в прямой регрессии, где возникают ошибки измерений в правой части уравнения. Обратная регрессия имеет те же ошибки, но в левой части. Эта регрессия также оценивается с помощью инструментальных переменных, причем тех же, что использовались в прямой регрессии.
\item Литература по теме ошибок измерений в нелинейных моделях более разнородна. Работа Амэмия (1985) особенно полезна эконометристам. Со статистической точки зрения, Кэррол и др. (1995) рассматривали нелинейные модели, в частности класс обобщенных линейных моделей, с аддитивными ошибками измерений в регрессорах, используя различные методы, включая ряд подходов, в которых могут применяться реплицированные данные, если они доступны. Ли, Триведи и Гуо (2003) развивали и использовали модель ошибок измерений, в которых с ошибками измерена счетная переменная.
\end{enumerate}


\section*{Упражнения} 
\begin{enumerate}
\item Пусть имеет место  смещение затухания \emph{(attenuation bias)} для параметра наклона парной модели ошибок переменных (Уравнение 26.9 в Разделе 26.2.3). Расширим эту модель, включив константу.
\begin{enumerate}
\item Найдите аналогичный результат  смещения из-за ошибки измерений для константы.
\item	Найдите аналогичный результат при идентификации границ для МНК-оценки свободного члена, сходного с Уравнением (26.12) в Разделе 26.3.1.
\end{enumerate}
\item (Адаптировано из работы Боллингера, 2003) Пусть есть линейная множественная регрессионная модель со скалярным регрессором $x$, который измерен с ошибками, и вектором регрессоров $z$, которые свободны от ошибок измерений.
\begin{enumerate}
\item Сохраняя предпосылки относительно ошибок измерений для парной модели ошибок переменных, обобщите результат смещения затухания и результат при идентификации границ на этот случай.
\item Проверьте, что новые результаты содержат в себе парную регрессию как частный случай.
\end{enumerate}
\item (Адаптировано из работы Вансбика и Мейера, 2000) Пусть есть квадратичная регрессионная модель $\mathbf{y}=\alpha + \beta\mathbf{x^*}+\gamma\mathbf{{x^*}^2}+\epsilon$, где регрессор $\mathbf{x^*}=\mathbf{x}+\mathbf{v}$ с $\mathbf{x}$ --– наблюдаемым и $\mathbf{v}$ --– ошибкой измерений. Предположим, что $(\mathbf
x^*, \, \epsilon, \, \mathbf{v})$ попарно не коррелированы и нормально распределены с нулевым средним.
\begin{enumerate}
\item	Сравните смещение МНК-оценок $\beta$ и $\gamma$.
\item	Идентифицируема ли модель? Сравните последний результат с результатом оценивания парной линейной модели ошибок переменных.
\end{enumerate}
\item В литературе, посвященной, мобильности, связывающей поколения \emph{(intergenerational mobility)}, используется следующая модель (Солон, 1992; Циммерман, 1992):
\begin{equation}
Y^{son}_i=\alpha + \beta Y^{father}_i + \epsilon^{son}_i,
\end{equation}
где $\epsilon_i$ независимы и нормальны $\mathcal{N}[0,\, \sigma^2]$. Здесь $Y$ --– мера перманентного статуса (например, перманентный доход) и $\beta$ измеряет степень возвращения к среднему экономическому статусу. Положим, что этот перманентный статус не наблюдается. Вместо него, текущий статус $Y_{it}$ наблюдается с $Y_{it}=Y_i+ \gamma X_{it}+ w_{it}$, так что $Y_{it}$  состоит из индивидуального фиксированного эффекта $Y_{i}$, называемого  перманентным статусом, систематических факторов $X_{it}$ и переходной ошибки $w_{it}$. Пусть $\widehat{\gamma}$ отражает посчитанный на основе МНК коэффициент и пусть
\[
Y_{it}-\widehat{\gamma}X_{it}= Y_i+ (\gamma - \widehat{\gamma})X_{it} + w_{it} = Y_i + v_{it}.
\]
\begin{enumerate}
\item Пусть $Y^{father}_i=T^{-1} \sum \limits^{T}_{t=1}Y^{father}_{it}$ отражает средний статус отца, который используется как независимая переменная, --- прокси для ненаблюдаемого перманентного статуса в (26.26). Пусть $\widehat{\beta}_{avg}$ обозначает соответствующий коэффициент регрессии. Покажите, что $\plim \widehat{\beta}_{avg}=\beta P_Y$, где $P_Y=n\sigma^2_Y/(\sigma^2_Y+T^{-1} \sigma^2_{\epsilon})$.
\item Предположим, что переходная составляющая доходов отца следует авторегрессионной схеме, $v^{father}_{it}=\rho v^{father}_{it}+\xi_{it}$, где $\xi \sim \text{iid} \mathcal{N}[0,\, \sigma^2_{\xi}]$, $i=1,\dots ,T$. Покажите, что теперь $\plim \widehat{\beta}_{avg}=\beta P^*_Y$, где $P_Y=n\sigma^2_Y/(\sigma^2_Y+T^{-1} V)$ и $V=\sigma^2_{\xi}[T(1-\rho^2)]^{-1}[(1+2\rho\{ T-(1-\rho^T)/(1-\rho) \} /T(1-\rho)]$.
\end{enumerate}
\end{enumerate} 

