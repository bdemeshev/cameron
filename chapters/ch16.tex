
\chapter {Тобит-модели и модели выбора}

\section{Введение}

В этой главе рассматриваются две связанные между собой темы: модели с частично наблюдаемой зависимой переменной и модели с полностью наблюдаемой зависимой переменной для совокупности отобранных данных. К выше обозначенным моделям относятся модели с ограниченной зависимой переменной, модели со скрытой переменной, обобщенные тобит-модели и модели отбора данных. 

Все эти модели имеют общую характеристику, а именно даже в самом простом случае, когда условное среднее генеральной совокупности линейно по параметрам, МНК-оценки несостоятельны, поскольку выборка не репрезентативна. Альтернативные способы оценки, в которых принимаются более сильные предпосылки, должны дать состоятельные оценки параметров.

К основным причинам неполноты данных относят усечение и цензурирование. При усечении как зависимая, так и независимая переменные частично наблюдаемы. Например, если в качестве зависимой переменной берется доход и в выборку входят индивиды только с низким уровнем доходов. В то же время, для цензурированых данных пропуски в данных могут быть только для зависимой переменной. Например, люди всех уровней дохода могут быть включены в выборку, но в целях конфиденциальности может быть установлено пороговое значение дохода, скажем 10 000 долл., выше которого, значение дохода принимается равным 10 000 долл. Усечение влечет за собой большую потерю информации, чем цензурирование. Ярким примером усечения и цензурирования является тобит-модель, названная в честь Тобина (1958). Тобин изучал линейные регрессионные модели, опираясь на предпосылку, что ошибки нормально распределены. Проблемы характерные для оценки усеченных и цензурированных моделей рассматрены в последующих главах, например, для цензурированных данных типа поток (глава 17). В целом, усечение и цензурирование -- это примеры пропущенных данных, см. главу 27.

Применения первых методов оценки требует строгих предпосылок о распределении. Малейшие отклонения от изначальных предпосылок, например, нарушение предпосылки о гомоскедастичности ошибок, могут привести к несостоятельным оценкам параметров. В этой главе рассматриваются полупараметрические регрессионные методы, а также примеры успешной реализации полупараметрических методов для оценки простых моделей с цензурированными и усеченными данными. Вместе с тем, в настоящее время, отсутствует общепринятый способ оценки для случаев, когда часть данных ненаблюдаема.

В разделе 16.2 дана общая теория цензурированных и усеченных нелинейных регрессий; подробное описание тобит-модели дано в разделе 16.3. Альтернативная модель оценки цензурированных данных -- двушаговая модель -- вводится в разделе 16.4. В разделе 16.5 дается характеристика модели отбора данных. В разделе 6.6. на примере оценки затрат на здравоохранение сравниваются двушаговая модель Хекмана и модели отбора данных. В разделе 16.7 рассматривается модель Роя. В разделе 16.8 рассматриваются полные структурные модели с угловыми решениями, полученные путем максимизации полезности или через решение системы одновременных уравнений для отобранных данных. В разделе 16.9 дается анализ семипараметрических методов.


\section{Эконометрические модели с цензурированными и усеченными данными}

Рассмотрим общие методы оценки полностью параметрических моделей с цензурированными или усеченными данными. Эти методы могут быть также использованы для оценки моделей, представленных в последующих главах, например, счетная модель и модель дюрации. Использование на практике тобит-модели для анализа цензурированных и усеченных данных продемонстрировано в разделах 16.2.1 и 16.3.

\subsection{Пример цензурированной и усеченной модели}

Пусть $y^{*}$ частично наблюдаемая переменная. При усечении снизу $y^{*}$ наблюдаемы, если $y^{*}$ вышае порогового значения. Допустим, что пороговое значение равно нулю. Тогда, $y=y^{*}$, если $y^{*}>0$. Поскольку в выборке отсутствуют отрицательные значения, среднее усеченных данных будет выше среднего $y^{*}$. Для цензурированных снизу данных $y^{*}$ ненаблюдаемо при $y^{*}<0$ и, если известно, что для всех значений выполняется неравенство $y^{*}<0$, значение $y^{*}$ приравнивается к нулю. В связи с этим, среднее цензурированных данных будет превышать среднее $y^{*}$. Очевидно, что среднее значение усеченных или цензурированных выборок не может использоваться без корректировки оценки среднего исходной модели.

В этой главе рассматриваются аналогичные вопросы оценки регрессионных моделей. В лучшем случае, усечение или цензурирование приведет к изменению константы, не оказывая влияния на коэффициент наклона. Например, если в исходной модели $E[y^{*}|x]=x'\beta$, для усеченой или цензурированой модели $E[y|x]$ нелинейно зависит от $x$ и $\beta$, следовательно, оценки МНК параметра $\beta$, а также оценка предельного эффекта последнего будут несостоятельны.

В качестве примера проанализируем модель предложения труда на симулированных данных. Предположим что зависимость ожидаемого количества отработанных часов в год, $y^{*}$ от почасовой заработная плата, $w$, описывается логарифмической функцией, а процесс генерации данных представлен тремя уравнениями:

\begin{equation}
y^{*}=-2500+1000ln{w}+\varepsilon\\
\varepsilon{\sim}N[0,1000^2],\\
ln{w}{\sim}N[2.75,0.60^2].
\end{equation}


Эта тобит-модель подробно рассмотрена в разделе 16.3. Согласно модели, эластичность заработной платы равна $1000/y^{*}$, следовательно, при полной занятости (2,000 часов) эластичность равна $0,5$. При увеличении заработной платы на $1\%$, количество часов работы увеличивается на $10$.

На рисунке 16.1 изображен график рассеивания $y$ по $ln{w}$ для сгенерированной выборки из двухсот наблюдений. График безусловного среднего $y^{*}$ равного $-2500+1000 Ln{w}$ -- нижний график в виде прямой линии.

При цензурировании в нуле отрицательные значения $y^{*}$ обнуляются, поскольку отрицательное значение ожидаемого количества рабочих часов, означает что индивиды предпочитают отдых. Как показывает практика, примерно $35\%$ индивидов предпочитают отдых. Замена отрицательных значений $y^{*}$ нулевыми, приводит к завышению среднего значения низкой заработной платы и практически не влияет на среднее высокой заработной платы, поскольку незначительный процент $y^{*}$ принимает нулевые значения. На среднем графике изобажено итоговое значение цензурированного среднего, рассчитанное по формуле (16.23).


При усечении в нуле $35\%$ данных отбрасываются. Следовательно, для цензурированных данных среднее выше, чем для усеченных данных, поскольку отрицательные значения не учитываются. График усеченного среднего отображает верхняя линия на рисунке 16.1.

Очевидно, что среднее цензурированных и усеченных данных нелинейно по $x$, даже если линейно по $x$ среднее генеральной совокупности. Оценка цензурированной или усеченной регрессии МНК даст несостоятельные оценки коэффициентов наклона. Из графика видно, что график линейно апроксимированных усеченного и цензурированного средних имеет более пологий наклон, чем график неусеченного среднего. Таким образом, среднее цензурированных или усеченных данных должно рассчитываться по спецальным формулам. 

Как правило, в регрессионном анализе $y$ обозначает наблюдаемое значение зависимой переменной для скрытой переменной $y^{*}$ и зависимость можно описать следующим уравнением:

\[
y=g(y^{*}),
\]

где $g(\bullet)$ обозначает некоторую функцию. Варианты функциональной зависимости рассмотрены ниже. 


Цензурирование


При цензурировании каждому значению параметра множества $x$ соответствует значение из подмножества $y^{*}$, а остальные значения $y$ подмножества ненаблюдаемы. При цензурировании снижу (или слева):

\begin{equation}
y=
\begin{cases}
y^{*}, \text{ если } y^{*}>L\\
L, \text{ если }y^{*}<L.
\end{cases}
\end{equation}

Например, всех потребителей можно рабить на две группы: к первой группе относятся индивиды с ненулевыми затратами на товары длительного пользованич, т.е. $y^{*}>0$, а ко второй группе с нулевыми затратами, т.е. $y^{*}{\leq}0$. При цензурировании сверх (или справа):

\begin{equation}
y=
	\begin{cases}
	y^{*},	 \text{ если }y^{*}>U\\
	U,		\text{ если }y^{*}<U.
	\end{cases}
\end{equation}

Например, может быть определена верхняя граница для данных о доходе, к примеру, $U=100,000$. Такое ограничение, в литературе по методам дюрации, получило название цензурирование первого типа (см.раздел 17.4.1). 


Усечение
Усечение приводит к потере информации, поскольку теряются все пограничные данные теряются. При усечении снизу:

\begin{equation}
y=y^{*}, \text{ если } y^{*}>L
\end{equation}

Следовательно, к примеру, выборка может включать данные только по индивидам, которые купили товары длительного пользования ($L=0$). При усечении сверху

\begin{equation}
y=y^{*}, \text{ если } y^{*}<U.
\end{equation}

Например, в выборку можно включить только данные по индивидам с низким уровнем дохода.

Интервальные данные
Интервальные данные записываются через интервал. Как правило, именно в этой форме записываются данные исследования для обеспечения анонимности персональных данных. Например, доход может меняться в промежутке от 10,000 долл. до 100,000 долл. Для таких данных может быть установлено несколько границ цензурирования, когда в интервале для наблюдаемой переменной $y$ может находиться ненаблюдаемое значение $y^{*}$. 

\subsection{Цензурироваанная и усеченная ML-оценка}

Проблему цензурирования и усечения легко преодолеть, если исследователь использует полностью параметрический подход. Это характерно для интервальных или ограниченных сверху данных, например, где целесообразно предположить логнормальное распределение дохода или использовать для оценки отрицательную биномиальную модель для оценки количества посещений к доктору.

Если условное по параметрам распределение $y^{*}$ известно, тогда возможно рассчитать эффективные и состоятельные ML-оценки, учитывая цензурированное или усеченное распределение $y$. Предположим, что $f^{*}(y^{*}|x)$ и $F^{*}(y^{*}|x)$ обозначает функцию плотности условного распределения (иначе, функцию распределения масс) и кумулятивную функцию распределения скрытой переменной $y^{*}$. Тогда всегда можно найти $f(y|x)$ и $F(y|x)$, соответствующую условную функцию распределения вероятностей и кумулятивную функцию распределения наблюдаемой зависимой переменной $y$, поскольку $y=g(y^{*})$ преобразование для $y^{*}$.

Ограниченность в применении семи параметрического подхода обусловлена сильными предпосылками о распределении. Например, ML-оценка линейной регрессионной модели остается состоятельно даже при нарушении предпосылки о нормальности распределения ошибок, тогда как ML-оценка цензурированной регрессии будет несостоятельной (см. раздел 16.3.2). Более гибкие модели и семи параметрические методы будут рассмотрены в последующих разделах. 


Цензурированный метод максимального правдоподобия


Цензурирование и усечение оказывают влияние на величину условного среднего и условной плотности. В первую очередь рассмотрим влияние на плотность.


В качестве примера рассмотрим ML оценку при цензурировании снизу. Для $y>L$ плотность $y$ принимает такое же значение как плотность $y^{*}$, следовательно, $f(y|x)=f^{*}(y|x)$. Для нижней границы $y=L$ плотность есть дискретная величина с основанием равным вероятности наблюдения $y^{*}<L$ или $F^{*}(L|x)$. Таким образом, при цензурировании снизу 

\[
f(y|x)=
\begin{cases}
f^{*}(y|x),& \text{если $y>L$}.\\
F^{*}(L|x),& \text{если $y=L$}
\end{cases}
\]


Ранее было отмечено, что при $y^{*}<L$ условие $y=L$ необязательно должно выполняться. Даже если все значения $y$ не наблюдаемы, при $y^{*}{\leq}L$, значение плотности равно $F^{*}(L|x)$. По аналогии с бинарными моделями, введем индикаторную переменную 

\begin{equation}
d=
\begin{cases}
1, & \text{если $y>L$}, \\
0, & \text{если $y=L$}.
\end{cases}
\end{equation}


Тогда условную плотность цензурированных снизу данных можно записать:

\begin{equation}
f(y|x)=f^{*}(y|x)^{d}F^{*}(L|x)^{1-d}.
\end{equation}



Например, для $N$ наблюдений ML-оценка максимизирует значение выражения:

\begin{equation}
Ln{L_N{\\theta}}=\sum_{i=1}^{N} \lbrace{d_i}ln{f^{*}(y_i|x_i,\theta)-d_i)ln{F^{*}}(L_i|x_i,\theta)\rbrace} ,
\end{equation}


где $\theta$ является параметрами распределения для $y^{*}$. В общем случае, при цензурировании нижняя граница может быть для каждого индивида своя, хотя, как правило, $L_i=L$. ML-оценка цензурированной регрессии состоятельна и асимптотически нормально распределена, что позволяет правильно определить исходное значение плотности до цензурирования, $f^{*}(y^{*}|x,\theta)$.

При цензурировании сверху функция максимального правдоподобия имеет вид (16.8), за исключением того, что $d=1$, если $y<U$ и $d=0$, в ином случае, а вместо $F^{*}(L|x,\theta)$ используется $F^{*}(U|x,\theta)$. Хорошим примером являются справа усеченные данные дюрации. 


Усеченная ML-оценка


При усечении снизу в точке $L$ и исключении зависимости от $x$ условная плотность распределения $y$ равна 


\[
f(y)=
\begin{cases}
f^{*}(y|y>L) \\
f^{*}(y)/Pr[y|y>L] \\
f^{*}/[1-F^{*}(L)].
\end{cases}
\]


Тогда, усеченная ML-оценка минимизирует значение функции


\begin{equation}
ln{L_N(\theta)}=\sum_{i=1}^N \lbrace ln{f^{*}(y_i,x_i,\theta)-ln[1-F^{*}(L_i|x_i,\theta)]}\rbrace.
\end{equation}

При усечении сверху, функция максимального правдоподобия примет вид (16.9), где $F^{*}(L|x,\theta)$ заменяется на $F^{*}(U|x,\theta)$.


Если не учитывать усечение или цензурирование оценки регрессии будут несостоятельны. Например, если не учитывать усечения, тогда будет максимизироваться значение функции $\sum_{i} ln{f^{*}(y_i,x_i,\theta)}$, что является неверным, поскольку отбрасывается второе слагаемое (16.9). Состоятельность цензурированных и усеченных ML-оценок обеспечивается правильной спецификацией $f(\bullet)$, что, в свою очередь, требует правильной спецификации плотности скрытой переменной $f^{*}\bullet$. Даже если $f^{*}(\bullet)$ функция плотности LEF (см. раздел 5.7.3), не только среднее, но и плотность должны быть правильно определены.

Пусть значения скрытой переменной $y^{*}$ принадлежат одному из $(J+1)$ взаимоисключающих интервалов $(-\infty,a_1], (a_1,a_2],\ldots ,(a_J,\infty)$, где значения $a_1,a_2,\ldots ,a_J$ известны. Следовательно,

\[
Pr[a_j<y^{*}<a_{j+1}]=Pr[y^{*}{\leq}a_{j+1}]-Pr[y^{*}{\leq}a_j] \\
F^{*}(a_{j+1})-F^{*}(a_j),
\]

и ML-оценка интервальных данных максимизирует значение функции 

\begin{equation}
ln{L_N(\theta)}=\sum_{i=1}^N\sum_{j=0}^J d_i ln[F^{*}(a_j|x_j,\theta)-F^{*}(a_j|x_j,\theta)].
\end{equation}


где $d_ij, j=0,\ldots ,J$, бинарный коэффициент равен 1, если $y_{ij}{\epsilon}(a_j,a_{j+1}]$ и $0$, иначе. Результаты аналогичны выводам логит- и пробит- регрессий (см. раздел 15.9.1)., за исключением того, что границы интервалов $a_1,\ldots ,a_J$ известны


\subsection{Пример пуассоновской усеченной и цензурированной регрессии}


Предположим, что $y^{*}$ распределено по Пуассоновскому закону, т.е. $f^{*}(y)=e^{-\mu}\mu^{y}/y!$ и $ln{f^{*}(y)}=-\mu+yln{\mu}-ln{y!}$, где среднее значение $\mu=exp(x'\beta)$.

Предположим, что задача состоит в оценке количества визитов в больницу, но данные известны только для тех, кто посещал врача. Следовательно, данные усечены снизу и $y=y^{*}$ только для $y^{*}>0$. Тогда $F^{*}(0)=Pr[y^{*}{\leq}0]=Pr[y^{*}=0]=e^{-\mu}$ и оценка $\beta$ максимизирует значение выражения

\[
ln{L_N(\beta)}=\sum_{i=1}^N{\lbrace-exp(x_i'\beta)+y_ix_i'\beta-ln{y!}-ln[1-exp(-exp(x_i'\beta))]\rbrace}
\]


Теперь предположим, что верхняя граница данных равна 10, тогда $y=y^{*}$ если $y^{*}<0$ и $y=10$, если $y^{*}{\geq}10$. Тогда $Pr[y^{*}{\geq}10]=1-Pr[y^{*}<10]=1-\sum_{k=0}^9 f^{*}(k)$. Из формулы (16.8) следует, что $\beta$ максимизирует значение функции


\[
Ln{L_N(\beta)}=\sum_{i=1}^N \lbrace d_i[-exp(x_i'\beta)+y_ix_i'\beta-ln{y_i}!]+(1-d_i)ln{\left[\sum_{k=0}^9 e^{-exp(x_i'\beta)(exp(x_i'\beta))^{k}}/k!\right]}\rbrace.
\]


В обоих случаях условия первого порядка значительно усложняются из-за усечения и цензурирования. Вместе с тем, максимизация исходной функции плотности, т.е. при отсутствии усечения и цензурирования, даст несостоятельные оценки параметров.

\subsection{Условное среднее в цензурированных и усеченных регрессиях}

Цензурирование или усечение данных приводит к изменению условного среднего.

Например, рассмотрим усеченное Пуассоновское распределение, где зависимая переменная неотрицательна. Усеченная плотность равна $f^{*}(y)/[1-F^{*}(0)], y=1,2,...$, тогда усеченное среднее $\sum^{\infty}_{k=1}kf^{*}(k)/[1-F^{*}(0)]=\sum^{\infty}_{k=0}=\sum^{\infty}_{k=0}kf^{*}(k)/[1-F^{*}(0)]=\mu/[1-e^{-\mu}]$. Следовательно, условное математическое ожидание примет значение:


\[
E[y|x]=exp(x'\beta)/[1-exp(-exp(x'\beta))],
\]

а не $exp(x'\beta)$, что справедливо для полных данных.

Это значение $E[y|x]$ может использоваться при расчете оценок отличным от МНК способом. Тем не менее, существует незначительное преимущество оценок, полученных отличным от МНК способом, поскольку в этих методах накладываются предпосылки о распределении ошибок, выполнение которых необходимо для получения более эффективных МНК-оценок.

\section{Тобит-модель}

Усеченные и цензрированные данных чаще всего встречаются в эконометрическом анализе линейных регрессионных моделей с нормально-распределенными ошибками и положительно определенной зависимой переменной. Эти модели получили название тобит-модели, в честь Тобина (1958), исследователя, который применил модель с выше обозначенными характеристиками для оценки затрат индивидов на товары длительного пользования. На практике модель учитывает множество ограничений. Тем не менее, существует необходимость в детальном изучении модели Тобина, поскольку тобит-модель является основой для построения моделей более общего класса, которые будут рассмотрены в последующих главах.

\subsection{Тобит-модель}

Цензурированная регрессионная модель с нормально распределенными данными, или тобит-модель, принадлежит классу моделей с цензурированием снизу в нуле, где латентная переменная линейно зависит от параметров, ошибки аддитивны, нормально распределены и гомоскедастичны. Таким образом, 

$y^{*}=x'\beta+\varepsilon$,

где остаточный член распределен нормально, с параметрами $0$ и $\sigma^2$:

\[
\varepsilon{\sim}N[0,\sigma^2],
\]

и $\sigma^2$ константа. Следовательно, что распределение латентной переменной имеет вид: $y^{*}{\sim}N[x'\beta,\sigma^2]$. Значения $y$ определены в выражении (16.2), приравнивая значение функции Лагранжа L к нулю, тогда 

\begin{equation}
y=
\begin{cases}
y^{*}, &\text{если $y^{*}>0$}, \\
--, & \text{если $y^{*}{\leq}0$},
\end{cases}
\end{equation}

где $-$ означает, что $y$ не определено. Однако, в некоторых случаях, затраты на товары длительного пользования могут быть равны нулю. 

Уравнения (16.11)-(16.13) задают прототип исходной тобит-модели. В более общем виде, тобит-модель для латентных переменных может быть определена (16.11) и (16.12). Вместе с тем, с учетом различных способов цензурирования: сверху, одновременно сверху и снизу (двухпредельная тобит-модель) и интервальное цензурирование, -- общий вид модели может меняться. В этом разделе все параметры цензурирования удовлетворяют условию (16.13). Иногда эти модели называют обобщенные тобит-моделями.

Приравнивание $L$ к нулю является как стандартным, так и необходимым условием построения линейной модели с константой и постоянным пороговым значением $LL$. Тогда, переменная $y$ наблюдаема, при $y^{*}>L$, что эквивалентно выражению $\beta_1+x'_2\beta_2+\varepsilon$ или $(\beta_1-L)+x'\beta_2+\varepsilon>0$ при известном значении $\beta_1 -- L$. В общем случае, модель с латентными переменными $y^{*}=x'\beta$ при цензурировании по $L=x'\gamma$, эквивалентна модели $y^{*}=x'\beta+\varepsilon$ с фиксированным значением $L=0$. Эти выводы являются следствием цензурирования данных линейной модели с аддитивной ошибкой и не применимы к нелинейным моделям, например, для Пуассоновского распределения.

Подставляя выражение (16.7) в формулу для плотности цензурированного распределения, где $f^{*}(y){\sim}N[x'\beta, \sigma^2]$ и 

\[
F^{*}(0)=Pr[y^{*}\leq0] \\
=Pr[x'\beta+\varepsilon{\leq}0] \\
=\Phi(-x'\beta/\sigma) \\
=1-\Phi(x'\beta\sigma), \\
\]

где $\Phi(\bullet)$ кумулятивная функция стандартного нормального распределения и для получения последнего равенства используется свойство симметрии стандартного нормального распределения. Тогда, плотность цензурированного распределения равна:

\begin{equation}
f(y)=\left[\dfrac{1}{\sqrt{2\pi\sigma^{2}}}exp\lbrace-\dfrac{1}{2\sigma^{2}}(y-x'\beta)^{2}\rbrace\right]\left[1-\Phi\left(\dfrac{x'\beta}{\sigma}\right)\right]^{1-d},
\end{equation}

где значение бинарного индикатора $d$ определено в (16.6) путем приравнивая $L$ к нулю. Оценка параметра тобит-модели методом максимального правдоподобия равна $\hat{\theta}=(\hat{\beta}',\hat{\sigma^2})'$ и является максимумом цензурированной функции (16.8). Подставляя (16.8) в (16.4), получим смешение плотностей дискретного и непрерывного распределения: 

\begin{equation}
ln L_N(\beta,\sigma^2\sum_{i=1}^N
\left\lbrace d_i\left(-\dfrac{1}{2}ln{2\pi}-\dfrac{1}{2}ln{\sigma^2-\dfrac{1}{2\sigma^2}(y_i-x_i')^2}\right)+(1-d_i)ln \left(1-\Phi
\left( \dfrac{x_i'\beta}{\sigma}\right)\right)\right\rbrace,
\end{equation}

и условие первого порядка:

\begin{equation}
\dfrac{\partial ln L_N}{\partial\beta}=\sum_{i=1}^N\dfrac{1}{\sigma^2}\left(d_i(y_i-x_i'\beta)-(1-d_i)\dfrac{\sigma\phi_i}{(1-\Phi_i)}\right)x_i=0 \\
\dfrac{\partial ln L_N}{\partial\sigma^2}=\sum_{i=1}^N\sum\left\lbrace d_i \left(-\dfrac{1}{2\sigma^2}+\dfrac{(y_i-x_i')^2}{2\sigma^4}\right)+(1-d_i)\dfrac{\phi_i x_i'\beta}{(1-\Phi_i)2\sigma^3}\right\rbrace=0
\end{equation}


$\partial\Phi(z)/\partial{z}$, где $\phi(\bullet)$ pdf и, согласно определению, $\phi_i=\phi(x_i'\beta/\sigma)$ и $\Phi_i=\Phi(x_i'\beta/\sigma)$.


Как правило, $\hat{\theta}$ состоятельна, если плотность условного распределения корректно определена, т.е. модель задана уравнением (16.11) и (16.12) и принцип цензирирования отражен в (16.13). Оценка максимального правдоподобия имеет нормальное распределение, варианты значений ковариационной матрицы для нормального распределения приведен в работах Maddala (1983, стр. 155) и Amemia (1985, стр.373).

Тобин (1958) предложил оценивать тобит-модель методом максимального правдоподобия и обосновал возможность применения ML оценки. В работе Amemiya (1973) представлено формальное доказательство применимости стандартной теории для плотности смешенного, дискретно-непрерывного, цензурированного распределения. Приложение к работе Amemiya, где подробно рассмотрена асимптотическая теория для экстремумов оценок, представлено в разделе 5.3.
Если данные усечены снизу от нуля, тогда ML-оценка Тобит регрессии $\hat{\theta}=(\hat{\beta}',\hat{\sigma}^2)$ является максимумом для усеченной функции правдоподобия


\begin{equation}
ln{L_N(\beta,\sigma^2)}=\sum_{i=1}^N{\sum\left\lbrace -\dfrac{1}{2}ln{\sigma^2}-\dfrac{1}{2}{ln{2\pi}}-\dfrac{1}{2sigma^2}(y_i-x_i'\beta)^2-ln{\Phi(x_i'\beta/\sigma)}\right\rbrace }
\end{equation}

где для $y^{*}$ используется выражение (16.9) и параметры распределения $y^{*}$ определены в (16.11) и (16.12).

\subsection{Несостоятельность Тобит оценок метода максимального правдоподобия}

Главным недостатком тобит-моделей является жесткость предпосылок о распределении ошибок. При нарушении предпосылки о гетероскедастичности ошибок или о нормальном распределении, тогда оценки максимального правдоподобия будут несостоятельны.

Это утверждение следует из условий первого порядка (16.16) максимального правдоподобия, заданные сложной функцией, зависящей от переменных $d, y_i, \phi_i$ и $\Phi_i$. Первое уравнение в (16.16), которое удовлетворяет условию $E[\partial{lnL_N}/\partial\beta]=0$, являются необходимыми условиями состоятельности оценок (см. Раздел 5.3.7), если

\[
E[d_i]=\Phi_i, \\
E[d_{i}y_{i}]=\Phi_{i}x'_{i}\beta+\sigma\phi_i.
\]

Можно показать, что эти моментные условия выполняются, если спецификация модели задана выражениями (16.11) и (16.12) и принцип цензурирования соответствует (16.13). Тем не менее, эти условия не будут выполняться, если спецификация модели определена иначе, чем в (16.12) и (16.13), поскольку не будет выполняться условие гомоскедастичности или предпосылка о нормальности распределения. Например, если ошибки гетероскедастичны оценка будет несостоятельна, поскольку $E[d_i]=\Phi(x'_{i}\beta/\sigma_{i}){\neq}\Phi_{i}$, не смотря на то, что $\sigma^2_i=\sigma^{2}$.

Тем не менее, при гетероскедастичности нормально распределенных ошибок возможно получение состоятельных оценок, если задать выражение для дисперсии $\sigma^2_i=exp(z'_i\gamma)$. При цензурировании данных от нуля для функции максимального правдоподобия $lnL_{N}(\beta,\gamma)$, определенной в (16.15) значение дисперсии $\sigma^2$ равно $exp(z'_i\gamma)$. Обязательными условиями состоятельности оценки являются нормально распределенные ошибки и верно заданная функциональная форма для гетероскедастичности.


Очевидно, что выполнение предпосылок распределения необходимо для правильного построения модели. Тесты на спецификацию тобит-модели представлены в разделе 16.3.7. Для многих цензурированных данных Тобит регрессии не применимы. Модели общей спецификации рассмотрены далее.


\subsection{Цензурированные и усеченное среднее в линейной регрессии}


Для цензурированных и усеченных линейных регрессий (16.11) условное математическое ожидание наблюдаемой переменной $y$ отлично от $x'\beta$, а условная дисперсия отлична от сигма-квадрат даже если ошибки $\varepsilon$ гомоскедастичны. Распределение $y$ также не является нормальным, не смотря на нормальное распределение ошибок. В этом разделе приведены общие выводы оценки линейной регрессии, в последующих разделах (разделах 16.3.4-16.3.7) рассмотрены частные случаи, когда ошибки нормально распределены. Результаты учитывают цензурирование и усечение и являются основой для методов, не входящих в группу методов максимального правдоподобия оценивания.

Вначале рассмотрим усеченное среднее. Влияние усечения данных можно предположить. Усечение данных слева исключает малые значения, следовательно, среднее значение должно увеличиться, а усечение справа, наоборот, предполагает уменьшение среднего. Поскольку усечение предполагает сокращение диапазон значений, дисперсия также должна сократиться.

При усечении слева, значения $y$ наблюдаемы, если $y^{*}>0$. Пусть математическое ожидание $y$ не зависит от $x$, тогда среднее усеченных слева данных равно

\begin{equation}
E[y]=E[y^{*}|y^{*}>0]
\end{equation}

\[
=E[x'\beta+\varepsilon|x'\beta+\varepsilon>0]\\
=E[x'\beta|x'\beta+\varepsilon>0]+E[\varepsilon|x'\beta+\varepsilon>0]\\
=x'/beta+E[\varepsilon|\varepsilon>-x'\beta],
\]

где второе равенство получается при подстановке в (16.18) выражения (16.11), а в последнем равенстве используется свойство о независимости $\varepsilon$ от $x$. Последнее свидетельствует о том, что усеченное среднее превышает значение $x'\beta$, поскольку $E[\varepsilon|\varepsilon>c]$ справедливо для любого значения константы $c$.

Для данных ,цензурированных слева от нуля, вместо $y^{*}{\leq}0$ предположим, что $y=0$. Цензурированное среднее рассчитывается дифференцированием наблюдаемых значений $y$ по бинарному индикатору $d$, определенному в (16.6) при $L=0$. При отсутствии зависимости от $x$, среднее значение слева цензурированных данных равно:


\begin{equation}
E[y]=E_{d}[E_{y|d}[y|d]] \\
=Pr[d=0]{\times}E[y|d=0]+Pr[d=1]{\times}E[y|d=1]\\
=0{\times}Pr[y^{*}{\leq}0]+Pr[y^{*}>0]{\times}E[\varepsilon|\varepsilon>-x'\beta],\\
=Pr[y^{*}>0]{\times}E[y^{*}|y^{*}>0],
\end{equation}

где $Pr[y^{*}>0]=1-Pr[y^{*}{\leq}0]=Pr[\varepsilon>-x'\beta]$ равно единица минус цензурированная вероятность и $E[y^{*}|y^{*}>0]$ усеченное среднее, ранее использовалось в (16.18).

Таким образом, при цензурировании или усечении данных с пороговым значением ноль условное среднее будет равно:

для модели с латентными переменными: \[E[y|x^{*}]=x'\beta\]
для модели, усеченной слева (в нуле):

\begin{equation}
E[y|x,y>0]=x'\beta+E[\varepsilon|\varepsilon>-x'\beta],
\end{equation}

для модели, цензурированной слева (в нуле): 

\[
E[y|x]=Pr[{\varepsilon}>x'\beta]\lbrace{x'\beta+E[\varepsilon|\varepsilon>{-x}'\beta]}\rbrace.
\]

Очевидно, что даже если условное среднее начальной переменной линейно, то при цензурировании или усечении данных линейность исчезает, что приводит к несостоятельности МНК-оценок.

Для решения проблемы несостоятельности можно использовать параметрический метод, накладывая ограничения на распределение $\varepsilon$. Следовательно, $E[\varepsilon|\varepsilon>x'\beta]$ и $Pr[\varepsilon>x'\beta]$ и, следовательно, можно рассчитать цензурированное или усеченное среднее. Параметрический метод оценки с нормально распределенными ошибками представлен в следующем разделе.

Цель второго подхода заключается в поиске решений, для которых отсутствовует необходимость принятия предпосылок о нормальном распределении ошибок. Этот подход будет также рассмотрен в последующих главах, но следует отметить, что выражение для усеченного среднего это модель «одного индекса» с корректирующим членом убывающим по $x'\beta$, поскольку $E[\varepsilon|\varepsilon>-x'\beta]$ монотонно убывающая функция от $x'\beta$.

\subsection{Цензурированное и усеченное среднее в тобит-модели}

Для тобит-модели остатки регрессии $\varepsilon$ нормально распределены. При дальнейшем рассмотрении будем использовать вывод из раздеда 16.10.1:

Утверждение 16.1 (Усеченные моменты для стандартного нормального распределения): Предположим, что $z{\sim}N[0,1]$. Тогда моменты усеченных слева значений $z$ равны:


(i) $E[z|z>c]=\phi(c)/[1-\Phi(c)]$, и $E[z|z>-c]=\phi(c)/\Phi(c)$,\\
 (ii) $E[z^{2}|z>c]=1+c\phi(c)/[1-\Phi(c)]$, и \\
 (iii) $V[z|z>c]=1+c\phi(c)/[1-\Phi(c)]-\phi(c)^{2}/[1-\Phi(c)]^{2}$ \\

Результат (i) Утверждения 16.1 изображен на рисунке (16.2). Рассмотрим усечение нормально распределенной величины $z{\sim}N[0,1]$ снизу вверх от некоторого значения $c$, где $c$ принадлежит промежутку от $-2$ до $2$. Средняя линия изображает график кумулятивной функции распределения $\Phi(c)$, оцененной в точке $c$ и задает вероятность усечения при усечении в точке $c$. Значение этой вероятности приближенно равно $0.023$ в точке $c=-2$ и $0.977$ при $c=2$. Верхняя линия изображает график усеченного среднего $E[z|z>c]=\phi(c)/[1-\Phi(c)]$. Как и предполагалось, значение математического ожидания $E[z]$ равно нулю при $c=-2$ и $E[z|z>c]>c$. Следует отметить, что $\phi(c)/[1-\Phi(c)]$ приближенно линейна. Значение моментов можно рассчитать по формуле $E[z|z<c]=-E[-z|-z>-c]=-phi(c)/\Phi(c)$. 

Подставляя полученный результат в (16.18), усеченное среднее случайной ошибки равно:

\begin{equation}
E[\varepsilon|\varepsilon>{-x}'\beta]={\sigma}E[\dfrac{\varepsilon}{\sigma}|\dfrac{\varepsilon}{\sigma}>\dfrac{{-x}'\beta}{\sigma}]  
\end{equation}

\[
=\sigma\phi(-\dfrac{x'\beta}{\sigma})/[1-\Phi(-\dfrac{x'\beta}{\sigma})] \\
=\sigma\phi(\dfrac{x'\beta}{\sigma})/[\Phi(\dfrac{x'\beta}{\sigma})] \\
=\sigma\lambda(\dfrac{x'\beta}{\sigma}),
\]

где второе равенство следует из утверждения 16.1, для получения третьего равенства использовалось свойство симметрии функции $\phi(z)$ относительно нуля и мы определяем 

\begin{equation}
\lambda(z)=\dfrac{\phi(z)}{\Phi(z)}.
\end{equation}

При определении $\lambda$ мы руководствовались опредлениями и терминологией, используемых в работе Amemiya (1985), параметр $\lambda(\bullet)$ получил название обратное отношение Миллса. В своей работе Johnson и Kotz (1970, p.278) отметили, что фактически Mills свел в одну таблицу отношение $(1-\Phi(z))/\phi(z)$ и обратное значение этого отношения $\phi(z)/[1-\Phi(z)]=\phi(z)/\Phi(-z)$, которое задает функцию риска нормального распределения. Ряд авторов записывают (16.21) в другом виде, а именно: $E[\varepsilon|\varepsilon>-x'\beta]=\sigma\lambda^{*}(-x'\beta/\sigma)$, где $\lambda^{*}(z)=\phi(z)/\Phi(-z)$ обратное отношение Миллса.

Вместе с тем, $Pr[\varepsilon>-x'\beta]=Pr[-\varepsilon/\sigma]=\Phi(x'\beta/\sigma)$. Тогда условное среднее в (16.20) равно:

для модели со скрытыми переменными: 

\begin{equation}
E[y^{*}|x]=x'\beta
\end{equation},
для моделей слева-усеченными данными (в нуле): $E[y|x,y>0]=x'\beta+\sigma\lambda(x'\beta/\sigma),$
для моделей слева цензурированными данными (в нуле): $E[y|x]=\Phi(x'\beta/\sigma)x'\beta+\sigma\phi(x'\beta/\sigma)$

Дисперсия рассчитывается по аналогичным формулам (см. упражнение 16.1). Пусть $w=x'\beta/\sigma$, тогда 

для модели со скрытыми переменными: $V[y^{*}|x]=\sigma^2$

для моделей слева-усеченными данными (в нуле): $V[y|x,y>0]=\sigma^2[1-w\lambda{w}-\lambda(w)^2],$

для моделей слева цензурированными данными (в нуле): $V[y|x,y>0]={\sigma}^2\Phi(w)\left\lbrace  w^2+w\lambda(w)+1-\Phi(w)[w+\lambda(w)]\right\rbrace^2$.

Очевидно, что усечение и цензурирование приводят к гетероскедастичности ошибок и при усечении $V[y|x<\sigma^2]$, следовательно, усечение позволяет сократить изменчивость значений.

Необходимым условием достижения выше обозначенных результатов является выполнение предпосылки о нормальном распределении ошибок. В работе Maddala (1983, p.369) представлены результаты использования утверждений из 16.1 для лог-нормального, логистического, экспоненциального, гамма распределений и распределения Лаапласа.

\subsection{Предельные эффекты в тобит-модели}

Под предельным эффектом понимают влияние изменений значений параметров на их условное среднее. Значение предельного эффекта может меняться в зависимости от интересующего объекта, это может быть среднее латентной переменной, значение которого равно $x'\beta$ или среднее цензурированных или усеченных данных, определенное в (16.23).

Дифференцируя каждое выражение по $x$, получим следующие результаты:

Модель со скрытыми переменными: 


модель со скрытой переменной: $\partial E[y^{*}|x]/{\partial{x}}=\beta$, \\
модель с данными усеченными слева (от нуля): $\partial{E}[y,y>0|x]/{\partial}x={1-w\lbrace\lambda}(w)-\lambda(w)^2\rbrace\beta$, \\
модель с данными усеченными слева в нуле: $\partial E[y|x]/\partial x=\Phi(w)\beta$, 



где $w=x'\beta/\sigma$, $\partial\Phi(z)/\partial{z}=\phi(z)$ и $\partial\phi(z)/\partial{z}=-z\phi{(z)}$. После некоторых преобразований, получим упрощенное выражение для среднего цензурированных данных. Можно выделить два эффекта: для $y=0$ и для $y>0$ (см.McDonald и Moffitt, 1980).

В некоторых случаях, цензурирование это искусственный способ отбора данных, а значение усеченного и цензурированного среднего не представляют заинтересованности 
В других случаях, усечение и цензурирование являются методомами анализа поведенческих факторов. Например, при моделировании рабочего времени рассчитываются три предельных эффекта (16.25), а именно: влияние изменения регрессоров на (1) ожидаемое количество часов работы, (2) фактическое количество отработанных часов и (3) фактическое количество отработанных часов работниками и неработающих. Для расчета (1) требуется значение оценки $\beta$, для расчета (2) и (3) коэффициенты наклона МНК-регрессии, при этом несостоятельность $\beta$ может привести к грубому приближению оценки предельного эффекта, поскольку среднее цензурированных и усеченных данных линейно по $x$.

\subsection{Альтернативные способы оценки тобит-модели}

Следует отметить, что нелинейный метод наименьших квадратов (НМНК) так же, как и метод максимального правдоподобия может дать состоятельную оценку параметров при корректном определении среднего усеченных и цензурированных данных. Далее рассмотрим МНК- и нелинейные МНК-оценки.

Нелинейный МНК

На основе полученных результатов (16.23) с помощью нелинейного МНК могут быть рассчитаны состоятельные оценки параметров тобит-модели. Например, для усеченных данных минимизируется значение функции $S_N$

\[
S_{N}(\beta,\sigma^2)=\sum^N_{i=1}\left(y_{i}-{x'}_{i}{\beta}-{\sigma}{\lambda}({x'}_{i}{\beta}/{\sigma})\right)^2
\]

по параметрам $\beta$ и ${\sigma}^2$, и далее задаются условия гетероскедастичности (16.24). Аналогичные вычисление могут быть сделаны для цензурированных данных. Аналогичный способ может применяться к цензурированным данным.
На практике нелинейный МНК не используется. Неотъемлемым условием состоятельности оценок является корректная спецификация усеченного среднего, при этом, согласно (16.21), корректная спецификация возможна при выполнении предпосылки о нормальном распределении и гомоскедастичности случайных ошибок. Вместе с тем, оценка $S_N$ может быть рассчитана методом максимального правдоподобия, поскольку метод основан на строгих предпосылках, что позволяет получить эффективные оценки. Кроме того, на практике оценка НМНК может быть неточной. Из графика 16.2 можно сделать вывод, что $\lambda(x'\beta/\sigma)$ приближенно линейна по $x'\beta/\sigma$, что приводить к линейной коллинеарности, поскольку $x$ также является регрессором. В разделе 16.5 будут представлены модели, в которых используется поправочный коэффициент похожий на $\sigma\lambda(x'\beta/\sigma)$ в (16.23), но не зависящий от $x$.


Двухшаговая процедура Хексмана

Из (16.23) следует, что среднее усеченных данных (в нуле) равно

\begin{equation}
E[y|x]=x'\beta+\sigma\lambda(x'\beta/\sigma).
\end{equation}

Вместо НМНК, значение можно оценить по двухшаговой процедуре Хекмана, если данные цензурированы. На первом шаге, оцениваем Пробит-регрессию $d$ по $x$, где бинарная переменная $d$ равна 1, если $y>0$, в результате получим состоятельные оценки параметра $\hat{\alpha}$, где $\alpha=\beta/\sigma$. На втором шаге, для расчета состоятельных оценок $\beta$ и $\sigma$, регрессия $y$ на $x$ с усеченными данными, а также $\lambda(x'\hat{\alpha})$ оцениваются методом МНК.
Описание и применение процедуры Хекмана (1976, 1979) для моделей выборки общего класса описана в разделе 16.5.4. В разделе 
Вывод формулы для оценки стандартной ошибки $\hat{\beta}$, которая необходима для расчета значения регрессора $\lambda(x'\hat{\alpha})$, а также для корректировки гетероскедастичны содержится в разделе 16.10.2.

МНК оценка тобит-модели.


\subsection{Спецификация тестов для тобит-моделей}


Устойчивость результатов тобит-модели проверяют с помощью тестов на неверную спецификацию. Существует 4 стратегии.

Согласно первому подходу, модель дополняют параметрами и проводят тест Вальда, LR или LM тест. Наиболее простым вариантом является использование LM теста. Для LM теста альтернативная гипотеза предполагает гетероскедастичность вида $\sigma_i^2=exp(x_i'\alpha)$. Используя метод внешнего произведения градиентов (см. раздел 7.3.5) $N$ раз рассчитывается $R^2$ вспомогательной регрессии $1$ на $s_{1i}$ и $s_2i$, $f_i=f(y_i|x_i,\beta,\alpha)$ плотность, определенная в (16.14), где $\sigma$ заменяется на $exp(x'\alpha)$, а $s_{1i}=\partial ln f_i/\partial\beta$ и $s_{2i}=\partial ln f_{i}/\partial \alpha$, где $\sim$ обозначает оценку цензурированной Тобит регрессии с ненулевой константой в точке цензурирования. 


Во втором подходе проводятся тесты условных моментов (см. раздел 8.2), которые не требуют определения альтернативной модели. В частности, согласно условиям первого порядка (16.16) для цензурированной Тобит регрессии значение $t$-статистики рассчитывается по формуле обобщенных остатков: 

\[
e_i=d_i\dfrac{y_i-x'_i\beta}{\sigma^2}-(1-d_i)\dfrac{\phi_i}{\sigma(1-\Phi_i)}.
\]

При правильной спецификации тобит-модели $E[e_i|x_i]=0$, поскольку условия регулярности предполагает $E[\partial{ln{f(y_i)}}/\partial\beta]=0$. Тогда можно проверить нулевую гипотезу $H_0:E[ez]=0$ где альтернативная гипотеза равна $H_a:E[ez]{\neq}0$ и используется выражение $N^{-1}\sum_{i=1}^N{\hat{e}_iz_i}$, где $\hat{e}_i=e_i$, ML-оценка Tobit модели в точке $(\hat{\beta};\hat{\sigma}^2)$. Из раздела 8.2.2 следует, что этот тест можно применить, рассчитав $N$ раз uncentered $R^2$ приближенной регрессии -- 1 на $\hat{e}_iz_i$ -- , где $\hat{s}_{1i}$ и $s_{2i}$, при плотности распределения $f_{i}=f(y_{i}|x_{i},\beta,\sigma^2)$, которая определена в (16.14), а $s_{1i}=\partial{ln}f_{i}/\partial\beta$ и $s_{2i}=\partial{ln}f_{i}/\partial\sigma^2$ (16.16) рассчитаны в точке $(\hat{\beta},\hat{\sigma}^2)$. Значения переменных $z_i$ и $x_i$ могут быть неравны, тогда тест\ldots . В настоящее время основу расчета теста условного среднего составляют моменты более высокого порядка. Более подробный анализ представлен у Chesher и Irish (1987) и Pagan и Vella (1989). 

Третий подход состоит в адаптации диагностические методы и методы тестирования, разработанные для данных дюрации цензурированных справа.


Согласно четвертому подходу, противопоставляются значения ML-оценки $\beta$ тобит-модели с альтернативыми оценками параметра $\beta$, например оценкой семипараметрического метода, представленного в разделе 16.9, которые являются состоятельными в соответствии с более слабыми предпосылками о распределении.

Для более глубокого изучения спецификации тестов тобит-моделей можно обратиться к работе Pagan и Vella, в которой рассмотрена теория и практические примеры, а также к работе Melenberg и Van Soest (1996), где автор более подробно остановился на рассмотрении практических вопросов. Обе работы посвящены вопросу спецификации тестов как для тобит-модели , так и для моделей отбора с более полной выборкой (см. раздел 16.5).


\section{Двусоставная модель}

В ранее рассмотренных моделях с цензурированными данными для достижения первоначального результата накладывались ограничения на способ цензурирования. В более общем случае, способ цензурирования, а также выводы могут быть получены в два шага. Например, для расчета ежегодных затрат индивида на госпитализацию одна модель может быть для госпитализации, вторая – для последующих затрат на госпитализацию. Необходимость использования двух моделей может быть вызвана тем, что некоторые значения получаются слишком часто или, наоборот, слишком редко, что характерно для простейшей модели. Например, в результате оценки модели частота появления нуля может быть высока, что характерно для Пуассоновского распределения. Возможность генерации нулевых и ненулевых значений при помощи разных плотностей распределения повышает устойчивость результатов. Следует отметить, что двусоставная модель относится к особому типу смешанной модели.

Существует два подхода к генерализации, а именно: рассмотренная в этом разделе двусоставная модель, в которой обозначен способ цензурирования, и модель, результат оценки которой зависит от полученного ранее результата. Модель отбора наблюдений, рассмотренная в следующем разделе, задает совместное распределение способа цензурирования и результата, и далее задается подразумеваемое распределение, зависящее от полученного результата. Сравнение этих подходов дано в разделе 16.5.7.

\subsection{Двусоставная модель}

Пусть индивид, данные о котором известны называется участником учебного процесса. Бинарная переменная $d$ равна 1 для участников и 0 для неучастников. Предположим, что для участников наблюдаемое значение $y>0$, а для тех, кто не обучается $y=0$. Для не участвующих, известно только значение $Pr[d=0]$. В то время, как условная плотность $y$ для участников при $y>0$ задана выражением $f(y|d=1)$, для некоторого значения плотности $f(\bullet)$. Двусоставная модель для $y$ определена следующей системой:

\ldots .

Эта модель была подробно рассмотрена в работе Cragg (1971) как обобщенная для тобит-модели, где тобит-модель можно определить как особый случай (16.27). Очевидно, что оценить бинарную модель можно с помощью пробит- или логит- регрессии. Срытая переменная $d$ равна 1, если $I=x'\beta+\varepsilon$ больше нуля и тогда модель может быть обозначена как «модель перехода», поскольку пересечение порогового значения будет означать участие. Для того, чтобы обеспечить положительные значения $y$ для участников, плотность $f(y|d=1,x)$ должна быть положительно-определена, что может обеспечить лог-нормальное распределение, или можно взять любую плотность, которая позволит получить положительные значения $y$, например, плотность нормально распределенных значений, отсеченных снизу от нуля.

Для простоты, одинаковые параметры могут использоваться как на первом, так и на втором шаге, однако это может быть необязательным, если обозначены ограничения на исключение наблюдений. Прямым методом оценки является метод максимального правдоподобия, поскольку позволяет отделить оценку моделей дискретного выбора, где используется полный массив данных и оценку параметров плотности $f(y|d=1,x)$ для положительных значений, $y>0$.


\subsection{Пример двусоставной модели}


Duan и др. (1983) привели ключевой пример применения двусоставной модели для прогнозирования расходов на лечение, используя базу данных Rand Health Insurance Experiment. Авторы составили пробит-модель, с помощью которой можно было определить тратил ли индивид средства на лечение в течении года, где $Pr[d=1|x]=\Phi(x'_1+\beta_{1})$, и модель затрат на лечение с лог-нормальным распределением параметров задана уравнением $ln{y|d}=1, x{\sim}N[x'_2\beta_{2},\sigma^{2}_{2}]$. Тогда ожидаемое значение затрат на лечение из начальной выборки равно

\begin{equation}
E[y|x]=\Phi(x'_1\beta_1)exp[\sigma^{2}_2/2+x'_2\beta_2],
\end{equation}
где второй член выражения получается при использовании результата того, что если $ln{y}{\sim}N[\mu,\sigma^2]$ тогда $E[y]=exp(\mu+\sigma^{2}/2)$. Более подробно вопрос перегруппировки рассмотрен в работе Mullahy (1998).

Двусоставная модель часто используется для моделирования счетных данных. Например, при моделировании количества визитов к доктору одна модель позволяет определить посещал ли пациент врача, а вторая модель рассчитывает количество повторных визитов только для индивидов, которые имеют хотя бы по одному визиту к врачу. Тогда $Pr[d=1]$ задает вероятность того, что переменная с Пуассоновским или отрицательным биномиальным распределением больше нуля, в то время как плотность $f(y|d=1)$ плотность Пуассоновского или отрицательной биномиальной плотности распределения усеченных снизу данных. В литературе по счетным данным, благодаря Mullahy (1986), эта модель получила название модель ограждений, которая подробно рассматривается в разделе 20.4.5. 

Двусоставная модель с непрерывными данными используется для оценки модели затрат с большим количеством нулевых данных (идея предложена Cragg’s). В следующем разделе рассмотрен альтернативный методу – метод отбора данных.


\section{Модели отбора данных}


Отбор наблюдений может возникнуть при решении любого вопроса и, в настоящее время разработано много моделей отбора наблюдений. Прежде чем приводить примеры практического применения, рассмотрим теоретическую сторону вопроса. К самым ярким показателям модели относит  бинарную модель выбора Хекмана (1979) и модель Роя (см. раздел 16.7).


\subsection{Модели отбора наблюдений}


Исследования по данным наблюдений редко основаны на на чисто случайных выборках. Как правило используется экзогенно заданная выборка (см. раздел 3.2.4) и, следовательно, могут быть применены стандартные методы. В случае, если выборка, намеренно или случайно, сформирована из значений зависимой переменной, оценки параметров будут несостоятельными, только если не будут применены коррекционные меры. Такие выборки получили широкое название репрезентативной выборки.

Существует много методов моделей отбора данных, поскольку существует много способов формирования репрезентативной выборки. Вместе с тем, можно не знать, была ли использована репрезентативная выборка. Например, при оценке среднего балла за тестирование по успеваемости, такого, как экзамен на определение академически способностей (Scholastic Aptitude Test), когда участие обязательно. Понижение среднего балла может быть следствием ухудшения знаний студентов. Это также может быть обусловлено тем, что относительно меньшее количество студентов было протестировано и участники студенты с более низким средним баллом.

Возможен само отбор, где результат частично определяется выбором индивида принимать участие или нет в действии, оценка которого интересует. 
Стр. 546 (последний абзац)


В этой главе рассматриваются только три модели отбора наблюдений. Самая простая это тобит-модель, см. раздел 16.3. Первая широко используемая модель, получившая название модель бинарного выбора, рассмотрена в этом разделе. Модель бинарного выбора данных обобщает тобит-модель путем введения скрытой переменной цензурирования, отличающейся от скрытой переменной тем, что позволяет получить результаты исследований. В разделе 16.7 рассмотрена модель Роя. В модели Роя выбор одного из двух результатов зависит от выбранного значения цензурированной переменной. Перечисленные модели по нумерации Amemiya (1985, стр.384), модель 1,2 и 5.


Состоятельность оценки зависит от предпосылок распределения, даже в случае семи параметрических методов. Исследования на экспериментальных данных являются альтернативой моделей отбора наблюдений, поскольку случайный характер распределения может решить проблему отбора. Однако, использование экспериментальных данных может быть затруднено высокими издержками на его проведение и рядом других причин. В главе 25 подробно рассмотрена модель эффективности результата, при оценке которой применяется экспериментальный подход.


\subsection{Модель бинарного отбора данных (Тобит-2)}


Пусть $y^{*}_{2}$ обозначает интересующий нас результат. В стандартной тобит-модели с усеченными данными результат известен только при $y^{*}_{2}>0$. В моделях общего класса вводится дополнительная латентная переменная $y^{*}_1$ и результат $y^{*}_2$ известен, только при $y^{*}_{1}>0$. Например, $y^{*}_1$ индикатор наличия работы и $y^{*}_2$ количество отработанных часов, при этом $y^{*}_1{\ neq}y^{*}_2$, поскольку существуют фиксированные издержки, например, ежедневные затраты на проезд, которые более значимы для идентификации наличия работы, чем количество фактически отработанных часов.

Модель бинарного выбора включает уравнение участия,

\begin{equation}
y_1=
\begin{cases}
1,  \text{если} y_1^{*}>0,
0,  \text{если } y_1^{*}{\leq}0
\end{cases}
\end{equation}

и итоговое уравнение результата:

\begin{equation}
y_2=
\begin{cases}
y_2^{*},  \text{ если } y_1^{*}>0,
-,  \text{ если }y_1^{*}{\leq}0
\end{cases}
\end{equation}

Согласно этой модели $y_2$ известно, только при $y^{*}>0$, при $y^{*}_{1}{\leq}0$ $y_2$ не должно принимать значения, имеющие смысл. В стандартной модели определяется линейная регрессия с латентной переменной и аддитивными ошибками:

\begin{equation}
y_1^{*}=x'_{1}\beta_1+\varepsilon_1, \\
y_2^{*}=x'_{2}\beta_2+\varepsilon_{2},
\end{equation}

при наличии корреляции между $\varepsilon_1$ и $\varepsilon_2$ возможны ошибки при расчете $\beta_2$.Тобит-модель является частным случаем этой модели, когда $y^{*}_1=y^{*}_2$.

Для этой модели отсутствует общепринятое понятие. Хекман (1979) использовал эту модель для демонстрации результатов оценки регрессии при отборе наблюдений. По своей спецификации модель эквивалентна тобит-модели со стохастическим пороговым значением (Nelson, 1977). Предположим, что значение $y^{*}_2$ наблюдаемо, если $y^{*}_{2}>L^{*}$, где $y^{*}_2$ определено в (16.31) и пороговое значение задается выражением $L^{*}=z'\gamma+u$ вместо $L^{*}=0$, как в разделе 16.3. Тогда, равнозначно, что $y^{*}_2$ наблюдаема, если $y^{*}_1>0$ и $y^{*}_{1}=y^{*}_{2}-L^{*}=(x'_2\beta_{2}-z'\gamma)+(\varepsilon_2-\nu)=x'_{1}\beta_{1}+\varepsilon_1$ и где $x_1$ равно сумме $x_2$ и $z$, и $\beta_1$ и $\varepsilon_1$ имеют обычные для себя характеристики. Amemiya (1985, стр.384) назвал эту модель Тобит-2 или тобит-модель второго типа. Wooldridge(2002, стр.506) предложил название модель с уравнением пробит выбора. В других работах можно встретить названия обобщенная Тобит- модель или модель отбора данных.

Самым простым способом оценки является ML метод, при условии, что коррелированные ошибки имеют совместное нормальное распределение и гомоскедастичны:

\[
\begin{matrix}
\varepsilon_1\\ \varepsilon_2
\end{matrix}
=
N
\begin{matrix}
\begin{matrix}
0 \\ 0
\end{matrix},
\begin{matrix}
1 &\sigma_{12} \\ \sigma_{12}&\sigma_{22}^2
\end{matrix}
\end{matrix},
\]

Как и для пробит-модели в разделе 14.4.1, нормируем дисперсию $\sigma^{2}_1=1$, поскольку известен только знак $y^{*}_1$. 

При заданных значениях (16.29) и (16.30) для $y^{*}>0$ значения $y^{*}_2$ наблюдаемы с вероятностью равной $y^{*}>0$ умноженной на вероятность $y^{*}_2$ условную по $y^{*}>0$. Следовательно, для положительных значений $y_2$ значение плотности равно $f^{*}(y^{*}_2|y^{*}_1>0){\times}Pr[y^{*}_1>0]$. Для $y^{*}_{1}{\leq}0$, можно с уверенностью сказать, это событие произошло и вероятность наступления данного события равна плотности. Следовательно, функция правдоподобия для модели бинарного выбора имеет вид:

\begin{equation}
L=\Pi_{i=1}^n{\lbrace Pr[y_{1i}^{*}{\leq}0]\rbrace}^{1-y_i}{\lbrace f(y_{2i}|y_{1i}^{*}>0){\times}Pr[y_{1i}^{*}>0]\rbrace}^{y_{1i}}
\end{equation}

где первый множитель дискретный компонент, при $y^{*}_{1i}{\leq}0$ поскольку тогда $y_{1i}=0$ и второй множитель непрерывный компонент, определяемый при $y^{*}_{1i}>0$. Эта функция правдоподобия может использоваться не только для линейных регрессий с совместно и нормально распределенными ошибками, но и при оценке широкого класса моделей.

Для линейной регрессии с совместно и нормально распределенными ошибками бинарная плотность нормального распределения равна $f^{*}(y^{*}_1,y^(*)_2)$, используя это плотность рассчитывается условная нормальная плотность второго множителя. Подробный анализ можно увидеть в Almedia (1985, стр.385-387), в том числе точную форму функции правдоподобия. 

Как правило, модель спользовалась для анализа предложения труда, где $y^{*}_1$ ненаблюдаемое ожидаемое предложение труда или способность к труду, а $y_2$ фактически отработанное количество часов. Вместе с тем, модель больше подходит к оценке предложения труда, поскольку в отличие от тобит-модели не требует искусственного массива данных <<ожидаемых>> часов работы. 
Эту трудность можно преодолеть путем добавления уравнения для предлагаемой заработной платы и, далее, подставить данное значение в исходное уравнение, хотя модель не является моделью бинарного выбора. Хороший пример оценки предложения труда рассмотрен в работе Mroz (1987).

\subsection{Условное среднее в модели бинарного выбора}

В этом разделе рассмотрим условное среднее усеченных данных модели бинарного выбора. Значение среднего не равно $x'_{2}\beta_2$, а МНК регрессия $y_2$ на $x_2$ дает несостоятельные оценки параметров. Тем не менее, выражение для условного среднего может быть использовано в качестве мотивации для использования альтернативного метода оценивания, рассматриваемого в последующем разделе и использующего более слабые предпосылки о распределении чем для ML оценки. 

Рассмотрим усеченное среднее в модели отбора данных, где используются только положительные значения $y_2$. Общий вид модели:

\begin{equation}
E[y_2|x,y_1^{\ast}>0]=E[x_2^{\prime}\beta_2+\varepsilon_2|x'\beta_1+\varepsilon_1>0] = x_2'\beta_2+E[\varepsilon_2\varepsilon_1>x_1'\beta_1]],
\end{equation}

где $x$ обозначает сумму $x_1$ и $x_2$. Если случайные ошибки не зависят друг от друга, тогда последнее слагаемое упрощается и принимает вид: $E[\varepsilon_2]=0$ и МНК-регрессия $y_2$ на $x_2$ даст состоятельные оценки $\beta_2$. Однако, если существует зависимость между средним значением двух ошибок, когда усеченное среднее не равно $x'\beta_2$, необходимо учитывать механизм отбора. 

Для расчета $E[\varepsilon_2|\varepsilon_1>-{x'}_1\beta_1]$, где $\varepsilon_1$ и $\varepsilon_2$ коррелированы. Хекман (1979) отметил, что если ошибки $(\varepsilon)1,\varepsilon_2)$ в (16.31) имеют совместное нормальное распределение как в (16.32), тогда для уравнения (16.36) справедливо, что 

\begin{equation}
\varepsilon_2=\sigma_{12}\varepsilon_1+\psi,
\end{equation} 

где случайная переменная $\psi$ независима от $\varepsilon_1$. Следует отметить, что для получения этого результата использовались свойства совместного нормального распределения

\[
\begin{matrix}
z_1\\z_2
\end{matrix}
=
N
\begin{matrix}
\begin{matrix}
{\mu}_1\\{\mu}_2
\end{matrix},
\begin{matrix}
\Sigma_{11}&\Sigma_{12} \\ \Sigma_{21}&\Sigma_{22}
\end{matrix}
\end{matrix},
\]

где условное нормально распределение равно

\[
z_2|z_1{\sim}N[\mu_2+\sum_{21}{\sum^{-1}}_{11}(z_{1}-\mu_1),\sum_{22}-\sum_{21}{\sum^{-1}}_{11}\sum_{12},
\]

следовательно

\begin{equation}
z_2=\mu_2+\Sigma_{21}{\Sigma^{-1}}_{11}(z_1-\mu_1)+\psi,
\end{equation}

где $\psi{\sim}N[0,\Sigma_{22}-\Sigma_{21}{\Sigma^{-1}}\Sigma_{12}$ независима от $z_1$. Для расчета совместной плотности распределения (16.32) известно, что $\mu_1=\mu_2=0$ и ${\sigma^{2}}_1=1$, следовательно, выражение (16.36) является частным случаем (16.35).

Подставляя (16.35) в формулу для усеченного среднего, (16.34), получим:

\[
E[y_2|x,y^{*}_1>0]=x'_2\beta_2+E[(\sigma_{12}\varepsilon_1+\psi)|\varepsilon_1>-x^{-1}\beta_1]=x'_{2}\beta_2+\sigma_{12}E[\varepsilon_1|\varepsilon_1>x'_1\beta_1],
\]
 
где, для расчета итогового выражения используем свойство независимости $\psi$ и $\varepsilon_1$. Условие выбора аналогично условию для тобит-модели и используя выражение $E[z|z>{-c}]$ из 16.1:

\[
E[y_2|x,y^{*}_1>0]={x'}_2+E[(\sigma_{12}\varepsilon_{1}+\psi)|\varepsilon_1>-{x'}_1\beta_1]
\]

\[
={x'}_2\beta_2+\sigma_{12}E[\varepsilon_1|\varepsilon_1>-{x'}_1\beta_1],
\]

где для получения выражения используется свойство независимости $\psi$ и $\varepsilon_1$. Критерий выбора совпадает с критерием тобит-модели и используя выражение для $E[z|z>-c]$ из 16.1 получим выражение для $E[y_2|x,{y^{*}}_1>0]$

\begin{equation}
E[y_2|x,{y^{*}}_1>0]={x'}_2\beta_2+\sigma_{12}\lambda({x'}_1\beta_1),
\end{equation}

где $\lambda(z)=\phi(z)/\Phi(z)$ и ${\sigma}_1=1$.  Вместе с тем, результат 16.1 (iii) позволяет выразить дисперсию усеченных данных

\begin{equation}
V[y_2|x,{y^{*}}_1]={\sigma^2}_2-{\sigma^2}_{12}\lambda({x'}_1\beta_1)({x'}_1\beta_1+\lambda({x'}_1\beta_1)).
\end{equation}

В предыдущем анализе невозможно было определить значения для $y_2$ при ${y^{*}}{\leq}0$. В некоторых случаях, при ${y^{*}}<0$ $y_2$ может быть равен нулю. В таком случае целесообразно рассматривать среднее значение усеченных данных. 


Условное распределение наблюдаемой величины $y_2$ при условии ненаблюдаемой $y^{*}_1$ и $y^{*}_2$ равно

\begin{equation}
\begin{split}
E[y_2|x]=E_{{y^{*}}_1}[E[y_2|x,{y^{*}}_1]] \\
=Pr[{y^{*}}_1{\leq}0|x]{\times}0+Pr[{y^{*}}_1>0|x]{\times}E[{y^{*}}_2|x,{y^{*}}_2>0] \\
=0+\Phi({x'}_1\beta_1)\left\lbrace{x'}_2\beta_2+\sigma_{12}\lambda\left({x'}_1\beta_1\right)\right\rbrace \\
=\Phi({x'}_1\beta_1){x'}_2\beta_2+\sigma_{12}\phi({x'}_1\beta_1),
\end{split}
\end{equation}

где третья строка получается на основе соотношения (16.37) и последняя строка на основе $\lambda(z)=\phi(z)/{\Phi}(z)$. Можно показать, что дисперсия цензурированных данных гетероскедастична.


\subsection{Двусоставная модель Хекмана}

МНК-оценки регрессии $y_2$ на $x_2$ при использовании только наблюдаемых и положительных значений $y_2$ дает несостоятельные оценки $\beta$, даже если ошибки не коррелированы, т.е. $\sigma_{12}=0$. Это следует из формулы среднего усеченных данных (16.37) присутствует дополнительный «независимый параметр» $\lambda(x'_1\beta_1)$. 

Иногда двухшаговую модель Хекмана называют Хекит оценка (Heckit estimator), где в МНК регрессию добавляется пропущенная переменная $\lambda(x'_1\beta_1)$. Таким образом, используя положительные значения $y_2$ оценивается МНК методом регрессия:

\begin{equation}
y_{2i}={x'}_{2i}\beta_2+\sigma_{12}\lambda({x'}_{1i}\hat{\beta}_1)+\nu_i,
\end{equation}

где $\nu$ случайная ошибка, $\hat{\beta}_1$ оценка, полученная на первом шаге пробит- регрессии $y_1$ на $x_1$, поскольку $Pr[y^{*}_1>0]=\Phi({x'}_1\beta_1)$ и $\lambda({x'}_1\hat{\beta}_1)=\phi({x'}_1\hat{\beta}_1)/{\Phi}({x'}_1\hat{\beta}_1)$ оценка обратного отношения Миллса. Результатом будет оценка усеченной дисперсии $\hat{\sigma}_2^2=N^{-1}\sum_i[\hat{v}_i^2+\hat{\sigma}_{12}^2\hat{\lambda}_i(x_1'\hat{\beta}_1+\hat{\lambda}_i)]$, где $\hat{v}_i$ предсказанное значение случайных ошибок методом наименьших квадратов регрессии (16.40) и $\hat{\lambda}_i=\lambda(x_{1i}'\hat{\beta}_1)$. Корреляция между ошибками в (16.32) может быть оценена по формуле $\hat{\rho}=\hat{\sigma}_{12}/\hat{\sigma}_2.$

Тестирование гипотезы $\sigma_{12}=0$ или $\rho=0$ проверка корреляции ошибок и необходимость корректировки отбора наблюдений. Одним из таких тестов является тест Вальда, основу которого составляет обратное отношение Миллса, $\hat{\sigma}_{12}$. 

Следует отметить, что как стандартные ошибки МНК, так и робастные к гетероскедастичности стандартные ошибки из выражения (16.40) некорректны. Для правильного расчета стандартных ошибок на втором этапе оценки вводятся два условия. Во-первых, даже если $\beta_1$ известно ошибки в (16.40) гетероскедастичны, что следует из (16.38). Во-вторых, вместо $\beta_1$ используется оценка параметра, этот прием рассмотрен в разделе 6.6, а применение к обычной тобит-модели в разделе 16.10.2. Корректные формулы для расчёте стандартных ошибок даны в работе Хекмана (1979); см. также Greene (1981). Вывод формулы для случая простой Тобит регрессии рассмотрен в разделе 16.10.2. На практике применение формулы может вызвать трудности, поэтому лучше воспользоваться возможностями статистического пакета или использовать бутстрэп.

Полученная оценка $\beta_2$ состоятельна . Несмотря на потерю эффективности по сравнению с MLE-оценкой из-за принятия предпосылки о стандартном нормальном распределении ошибок, метод популярен по ряду причин: 1) прост в применении; 2) применим к моделям выбора, в частности, к моделям из раздела 16.7; 3); 3) используются более слабые предпосылки о распределении, чем для совместного нормального распределения случайных ошибок $\varepsilon_1$ и $\varepsilon_2$; и 4) предпосылки о распределении можно ослабить для оценки семи параметрическим методом, см. раздел 16.9.

Предпосылка, которая всегда должна выполняться (16.35), в общем виде может быь записана:

\begin{equation}
\varepsilon_2=\delta\varepsilon_1+\xi,
\end{equation}

где $\xi$ независима от $\varepsilon_1$. Эта модель имеет смысл. Согласно этой модели справедливо, что количество ошибок в уравнении издержек на товары длительного пользования кратно количеству ошибок в уравнении принятия решения о покупке; фактически уравнение (16.41) линейная регрессия для оценки случайных ошибок.

Учитывая выражение (16.41) условное среднее (16.34) можно записать как:

\begin{equation}
E[y_2|y_1^{*}>0]=x_2'\beta_2+\delta E[\varepsilon_1|\varepsilon_1>-x_1^{*}\beta_1].
\end{equation}

Если $\varepsilon_1$ имеет стандартное нормальное распределение , тогда (16.42) эквивалентно (16.37), основанием для МНК регрессии служит (16.40).

В общем случае, уравнение (16.42) можно оценить методом Хекмана, если ошибки $\varepsilon_1$ имеют распределение, отличное от нормального; см. Olsen (1980). Вместе с тем, $E[y_2|y_1^{*}>0]$ можно оценить семи параметрическим методом, в котором не накладываются ограничения на функциональную форму  $E[\varepsilon_1|\varepsilon_1>-x_1'\beta_1]$ (см. раздел 16.9). 

\subsection{Идентификация}

Теоретически, бинарная модель выбора с нормально распределенными ошибками может быть идентифицирована без дополнительных ограничений на параметры. В частности, модель бинарного выбора можно использовать для записи $y_1^{*}$ и $y_2^{*}$. 

Вместе с тем, если в модели с нормально распределенными ошибками значения двух параметров совпадают, тогда модель может быть неидентифицируема. Если $x_1=x_2$, тогда, используя (16.37) и  вывод из раздела 16.3.2 о том, что обратное отношение Миллса, $\lambda(\bullet)$, можно приближенно описать как линейное по параметрам, $E[y_2|y_1^{*}]{\simeq}x_2'\beta_2+a+bx_2'\beta_1$. Идентичность значений параметров приводит к мультиколлинеарности. Анализу мультиколлинеарности посвящено много работ среди которых Nawata (1993), Nawata и Nagase (1996) и Leung и Yu (1996). 


\section{Модель отбора данных: оценка затрат на здоровье}

Для иллюстрации метода используем данные RAND Health Insurance Experiment (RHIE). Данные взяты из статьи Deb и Trivedi (2002), авторы использовали модель счетных данных для анализа посещений амбулаторных больных к лечащему врачу и другим специалистам. В разделе 20.3 обобщаются данные, а в разделе 20.7 представлены выводы по некоторым стандартных счетных моделей.


В этом разделе модель строится для ежегодных затрат на здоровье. Параметры определены в Таблице 20.4 и могут быть разбиты на несколько групп: медицинское страхование (LC, IDP,LPI и FMDE), социально-экономические характеристики (LINC,LFAM,AGE,FEMALE,CHILD,FEMCHILD,BLACK и EDUCDEC) и индикаторы состояния здоровья (PHYSLIM,NDISEASE,HLTHG,HLTHF и HLTHP). В главе 20 анализ строится на данных за 4 года, в этом примере данные взяты только для второго года, что дает 5574 наблюдения и итоговая статистика похожа на результаты в Таблице 20.4.

Зависимая переменная $y$ обозначает ежегодные затраты индивида на здоровье. При построении эконометрической модели необходимо учитывать два фактора: 1) затраты на здоровье равны нулю для $23.2\%$ наблюдений и 2) распределение $y$ скошенно вправо, среднее значение равно $221 $долл. при медиане $53 $долл. Логарифмирование функции позволяет понизить скошенность, для логарифма функции среднее равно $4.07$, а медиана $3.96$; статистика скошенности сокращается от 24.0 до 0.3. Куртозиз равен $3.29$, что примерно равно нормальному значению, $3$. 

Далее основное внимание будет сосредоточено на моделировании $ln{y}$, где $y$ положительная величина.  Затраты на здоровье можно также оценивать используя двусоставная модель, см. раздел 16.4.2. и модель бинарного выбора, см. раздел 16.5.2., где $y_1$ в (16.29) индикатор положительного значения затрат, а $y_2$ в (16.30) равен $ln{y}$. Следует отметить, что при $y_1=0$ $y_2$ не имеет смысла, поскольку значение $ln{0}$ неопределено. Двусоставная модель частный случай модели бинарного выбора, когда $\sigma_{12}=0$, (16.32).

Таблица 16.1. Затраты на здоровье: результаты оценок двусоставной модели и модели отбора данных


В таблице 16.1  показаны оценки коэффициентов для группы факторов медицинского страхования и индикаторов состояния здоровья. Оценки коэффицентов группы социально-экономических характеристик сокращены для краткости изложения.

Для начала сравним результаты двусоставной модели и модели бинарного выбора с двухшаговой процедурой оценки. Оценки DMED идентичны, поскольку используется пробит-модель с одними и теми же регрессорами. Вместе с тем, оценки LMED отличаются, поскольку в модели бинарного выбора на втором шаге в МНК регрессию добавляется предсказанное значение обратного отношения Миллса. Этот дополнительный регрессор статистически незначим $(t=0.47)$ и его абсолютное значение мало, а $\hat{\rho}$ близко к нулю и равно $0.168$. В результате две модели дают аналогичные оценки коэффициентов для LNMED.


Как было отмечено в разделе 16.4.4 двух шаговый метод может не дать хороших результатов, если обратное отношение Миллса сильно коррелировано с другими регрессорами. В рассматриваемом примере результаты корректны, поскольку прогнозное значение вероятности может меняться в диапазоне от $0.15$ до $0.99$, а коэффициент переноса (см.раздел 10.4.4) для регрессоров на втором шаге	увеличивается лишь в два раза после добавления обратного отношения Миллса. Не смотря на то, что для улучшения качества оценок, как правило, накладываются ограничения на параметры, для рассматриваемого примера трудно установить какие именно факторы нужно исключить из DMED, чтобы улучшить результат LNMED.

ML-оценка бинарной модели отбора данных, значительно отличается от двух предыдущих, как для DMED, так и для LNMED. В модели скрытых переменных случайные ошибки высоко коррелированы, как для DMED, так и для LNMED $\hat{\rho}=0.736$ и коэффициент корреляции статистически значим $(t=16.43)$. Большая разница между оценками $\sigma_{12}$ (или $\rho$), полученными двух шаговой процедурой и ML-спасобом,  может означать наличие ошибок в применении бинарной модели. Отвергание нулевой гипотезы теста Хаусмана (см. раздел 8.4) согласно которой оценки параметров имеют одинаковый предел по вероятности, может означать отсутствие в необходимости принимать дополнительное предположение о совместном нормальном распределении ошибок при переходе ко второму шагу ML-оценки в бинарной модели выбора. Также возникает вопрос о необходимости предпосылки (16.41) и предпосылки о нормально и равномерно распределенных ошибках $\varepsilon_1$. Неустойчивость является характерной чертой для моделей бинарного выбора, особенно, если одни и те же параметры используются в обеих частях модели. Следовательно, возможность ошибки идентификации исключается принятием предпосылок модели. В частности, в модели затрат на здоровье предпосылка о нормальном распределении остатков может не выполняться из-за большого количества возможных отклонений. Даже если  скошенность LNMED равную нулю, а кортозиз равен $3$, стандартные тесты на гетероскедатичность, скошенность и куртозиз отвергают нулевую гипотезу о нормальном распределении LNMED, p-value=0.000.


\section{модель Роя}


В бинарной модели выбора отдельное значение зависимой переменной может быть не наблюдаемо. Таким образом, задается условие, что $y_2$ наблюдаема, если $y_1$ и не наблюдаемо при $y_1=0$. В этом разделе рассмотрим модель, в которой $y_2$ наблюдаема для всех индивидов, но только в одном из двух возможных случаев. Рассмотрение модели предполагает анализ влияния дополнительных факторов на результат, а также ссылки на литературу по программам оценки, подробно рассмотренной в Главе 25. 

\subsection{Модель Роя}

В одной из самых популярных работ Роя, 1951 анализируется последствие разделения населения на группы по двум признакам: профессия и зарплата (среднего и дисперсии), индивиды отличаются навыками, а также индивиды разделяются на группы по профессиям самопроизвольно. Данные обрабатывались по общей схеме, и не использовался математический аппарат. Вместе с тем, предполагается, что производительность индивида, принадлежащего к определенной группе, имеет лог-нормальное распределение при отсутствии возможности выбора. Вместе с тем, модель в целом не оценивалась. В 1970-е гг. ряд авторов, независимо друг от друга, разработали аналогичные модели, оценка которых строилась на структурных данных и выборка формировалась из наблюдаемых и ненаблюдаемых значений. Эти модели получили название модели Роя. 

Определим типовую форму модели Роя. Значение скрытой переменной $y^{*}_1$ зависимости от результата, $y^{*}$ или $y^{*}_3$. Например, определим знак $y_1^{*}$

\begin{equation}
y_1=
\begin{cases}
	1, & \text{если $y_1^{*}>0$,} \\
	0, & \text{если $y_1^{*}\leq0$,}
\end{cases}
\end{equation}

и, следовательно, можно определить $y_2^{2}$ и $y_2^{3}$:

\begin{equation}
y_1=
\begin{cases}
	y_2^{2}, & \text{если $y_1^{*}>0$,} \\
	y_2^{3}, & \text{если $y_1^{*}\leq0$,}
\end{cases}
\end{equation}

Как правило определяют линейную модель с аддитивной ошибкой для скрытых переменных,

\begin{equation}
y_1^{*}=x_1^{*}\beta_1=\varepsilon_1,
\end{equation}

\[
y_2^{*}=x_2^{*}\beta_2=\varepsilon_2,
\]

\[
y_3^{*}=x_2^{*}\beta_3=\varepsilon_3.
\]

Модель с аддитивным эффектом имеет вид $x_3'\beta_3=x_2'\beta_2+\alpha$. Самая простая параметрическая модель с коррелированными случайными ошибками получается, если ошибки имеют совместное нормальное распределение с параметрами:

\begin{equation}
\begin{vmatrix}
\varepsilon_1 \\ \varepsilon_2 \\ \varepsilon_3
\end{vmatrix}
{\sim}N
\begin{vmatrix}
	\begin{vmatrix}
	0 \\ 0 \\ 0
	\end{vmatrix},
	\begin{vmatrix}
	1 & \sigma_{12} & \sigma_{13} \\
	\sigma{12} & \sigma_2^{2} & \sigma_{23} \\
	\sigma_{13} & \sigma_{23} & \sigma_3^2
	\end{vmatrix}
\end{vmatrix}
\end{equation}

где значение дисперсии $\sigma^2$ нормируется к единице, поскольку известен знак $y_1^{*}$.

Вид функции максимального правдоподобия похож на модель бинарного выбора (раздел 16.5), за исключением того, что $y_3^{*}$ наблюдаемая величина при $y_1^{*}{\leq}0$, следовательно выражение (16.33) $Pr[y_{1i}^{*}{\leq}0]$ заменяется на $f(y_{3i}|y_{1i}^*{\leq}0){\times}Pr[y_{1i}^{*}{\leq}0].$

Как правило, модель с аддитивными ошибками оценивают используют двух шаговый метод Хекмана, который применяется для оценки математического ожидания усеченных данных:

\begin{equation}
\begin{split}
E[y|x,y_1^{*}>0]=x_2'\beta_2+\sigma_{12}\lambda(x_1'\beta_1), \\
E[y|x,y_1^{*}>0]=x_3'\beta_3+\sigma_{13}\lambda(x_1'\beta_1)
\end{split}
\end{equation}

где $\lambda(z)=\phi(z)/\Phi(z)$ и $\sigma_1^{2}=1$. На первом шаге, рассчитываются оценки $\beta_1$ и $\lambda(x_1'\hat{\beta}_1)$, при условии что $y_1^{*}>0$. Далее рассчитываются $\beta_2, \sigma_{12}$ и $(\beta_3,\sigma_{13})$. Оценки дисперсий $\sigma_2^2$ и $\sigma_3^2$ можно вычислить используя значения квадратов остатков регрессий, по аналогии с техникой в бинарной модели выбора, применяемой после (16.40). Madalla (1983, стр.225) детально изучил особенности этой модели, назвав последнюю модель переключающейся регрессии с эндогенным переключением. В работе Amemiya (1985, стр.399) модель обозначена как тобит-модель пятого вида.

\subsection{Вариации модели Роя}

Многие модели принадлежат классу моделей Роя. В работе Madalla (1983, глава 9) дается несколько ссылок  на модели самоотбора. Также см. Amemiya (1985, глава 10). Далее рассмотрен несколько основных показательных примеров.

К частному случаю модели Роя можно отнести модель бинарного выбора, когда обнуляется $y_3$ и модель строится только для среднего усеченных данных $E[y_2^{*}|y_1^{*}>0]$. Более показательным примером может быть модель бинарного выбора, где $y=0$ при $y_1^{*}{\leq}0$, например, модель предложения труда, когда $y=y_2^{*}$ или $y=0$, следовательно, $y_3^{*}=0$.

В работе L.-F. Lee (1978), $y_2^{*}$ и $y_3^{*}$ обозначают заработную плату по профсоюзным ставкам и не по профсоюзным ставкам, соответственно, и $y_1^{*}$ стремление вступить в профсоюз. Следовательно, появляется надстройка модели

\[
y_1^{*}=y_2^{*}-y_3^{*}+z'\gamma+\zeta,
\]

где $z'\gamma+\zeta$ отражает затраты на членство в профсоюзе и эта надстройка очень характерно для модели Роя (1951). Заменяяя $y_2^{*}$ и $y_3^{*}$, получим приведенную форму для $y_1^{*}$:

\[
y_1^{*}=(x_2'\beta_2+x_3'\beta_3+z'\gamma)+(\varepsilon_2-\varepsilon_3+\zeta).
\]

Эта модель идентична идентична ранее полученной модели при оценке пробит-модели $y$ на $x_1$ с корректирующим членом $\lambda(x_1'\hat{\beta}_1)$ на первом шаге, где $x_1$ единственный параметр в выражении для $x_2$, $x_3$ и $z$.

Если значение константы может меняться в пределах двух значений, например, на $\alpha$, тогда в модели Роя будет только две латентных переменных:

\[
y_1^{*}=x_1'\beta_1+\varepsilon_1,
\]

\[
y^{*}=x'\beta+{\alpha}y_1+\varepsilon,
\]

где $y=y^{*}$ всегда наблюдаемая величина, а бинарная переменная $y_1$ равна единице, если $y_1^{*}{\geq}0$ и нулю, в ином случае. Эта модель может быть отнесена к моделям с эндогенной дамми переменной $(y_1)$. Модель может быть оценена с применением двух шаговой процедуры Хекмана к $E[y'|x]$. Кроме того, для оценки могут вводиться инструментальные переменные, например для $y_1$. Инструментальные переменные не определяют уровень результата, но определяют какой из результатов был выбран.

Рассмотренные модели Роя похожи на модели, рассмотренные в литературе по оценке эффективности результата, когда существует два варианта исхода, $y_2^{*}$ и $y_3^{*}$, но мы можем наблюдать только один из них. Подход, обозначенный в этой главе, основан на более сильных предпосылках о характере распределения ненаблюдаемых переменных. В главе 25 представлены альтернативные методы, особое внимание стоит обратить на раздел 25.3, в котором проводится сравнение подходов.

\section{Структурные модели}

Особенность моделей регрессии отбора данных заключается в том, что результат исследования частично зависит от решения об участии, которое в свою очередь зависит от ожидаемого результата. При этом, решение об участии и желаемый результат определяются одновременно. В предыдущих главах для описания этой взаимозависимости использовалась приведенная форма уравнения участия. В  частности см. представление статьи Lee (1978) в разделе 16.7.2. Использование приведенной формы часто используемый прием, хотя и менее эффективен, чем использование полной версии структурной модели. 

В этом разделе подробно анализируются структурные экономические модели, в основе которых лежит максимизация полезности, и структурные статистические модели, позволяющие расширить систему одновременных уравнений, тем самым устраняя влияние цензурирования и усечения, в том числе и на результат бинарной регрессии.

\subsection{Структурные модели, построенные на принципе максимизации полезности}

Изначально, структурные модели использовали для анализа предложения женского труда. Модель включает в себя максимизацию полезности индивидов, функцию потребления товаров, время досуга, бюджетное ограничение и ограничение по времени. При этом весь временной промежуток разделен на время для работы и время для отдыха. Для решения во внутренней области предельная норма замещения (MRS) работы досугом равна ставке заработной платы. Однако, угловое решение, когда женщины решают не работать, может возникнуть, если MRS превышает ставку заработной платы. Gronau (1973) и Heckman (1974) представили эконометрические модели, согласующиеся с моделями максимизации полезности. Модели Gronau и Heckman похожи на тобит-модели; для неработающих женщин размер зарплаты равен нулю. В последующих вариантах добавляются фиксированные издержки работы, что характерно для моделей отбора данных, а также используются панельные данные, что приводит к панельной тобит-модели. Исследование этих моделей проводили Killingsworth и Heckman (1986), а также Bundell и MaCurdy (2001), а практическое применение продемонстрировал Mroz (1987).


Для иллюстрации структурного подхода приведем следующий пример. Dubin и McFadden (1984) построили модель потребления электроэнергии домашними хозяйствами (ДХ) (электричества или природного газа) и выбора электрического прибора (электрической или газовой печи) как взаимосвязанных решений, принимаемых исходя из функции полезности. Так, для $j$-го ДХ, пользующегося $m$ приборами косвенная функция полезности отдельного домашнего хозяйства имеет вид:

\begin{equation}
V_j=\lbrace\alpha_1/\beta+\alpha_1{p_1}+\alpha_2{p_2}+w'\gamma+\beta(y-r_j)+\eta\rbrace{e}^{-{\beta}p_i}+\varepsilon_j,
\end{equation}

где $p_1$ и $p_2$ цены на электроэнергию и газ, $y$ доход ДХ и $r_j$ ежегодные затраты на энергию $j$-го ДХ равны:

\[
r_j=p_1q_{1j}+p_2q_{2j}+\rho{c}_j,
\]

где $q_{1j}$ и $q_{2j}$ количество потребляемого газа и электроэнергии, $c_j$ затраты на потребление и $\rho$ ставка дисконтирования. Отличия в предпочтениях ДХ определяется наблюдаемой переменной $w$, ненаблюдаемой переменной $\eta$ и случайной ошибкой $\varepsilon_i$; $\varepsilon_i$ независимы между собой, но коррелированы с $\eta$. Вместе с тем, общим для всех является "фактор вкуса" $\alpha_{0j}$.


Спрос на энергию для $j$-го ДХ равен $-(\partial{V_j}/\partial{p_1})(\partial{V_j}/\partial{y})$, иначе, используя тождество Роя, можно записать


\[
x_1-q_{1j}=\alpha_{0j}+\alpha_{1}p_1+\alpha_2{p_2}+w'\gamma+\beta(y-r_j)+\eta.
\]

Следует отметить, что выбор пакета потребляемой энергии $j$ задан эндогенно, а введение $m$ заменяет иникаторную переменную $\delta_{jk},k=1,...,m$, где

\[
\delta_{jk}=
	\begin{cases}
	1, & \text{если }k=j\\
	0, & \text{если }k{\neq}j
	\end{cases}
\]

Тогда спрос на электроэнергию $x_1$ с учетом потребностей $j$-го ДХ определяется следующим выражением:

\begin{equation}
x_1-q_{1j}=\sum_{k=1}^m 
\sum\alpha_{0k}\delta_{jk}+\alpha_{1}p_1+\alpha_{2}p_2+w'\gamma+\beta\left(y-\\sum_{k=1}^{m}{r_j\delta_{jk}}\right)+\eta.
\end{equation}

Даже если модель (16.50) линейна по параметрам, МНК-оценки будут несостоятельны из-за эндогенного характера $\delta_{jk}$. Dubin и McFadden (1984) рассмотрели два варианта алгоритма оценки.

Четвертый подход позволяет оценить (16.50), используя в качестве инструментов для $\delta$ и $r_j\delta_{jk},k=1,...,m$ переменные $\hat{p}_k$ и $r_{j}\hat{p}_k$, соответственно, где $\hat{p}_k$  предсказанные значения вероятности для заданного портфеля потребления. $V_j$ обозначает косвенную функцию полезности, которая состоит из детерминистической функции $U_i$ и стохастического компонента. Такая запись функции соответствует представлению $U_i$ в разделе 15.5.1 с помощью модели полезности с аддитивными случайными ошибками ('additive random utility model'=ARUM). Согласно аналогичному подходу, 

\[
p_k=Pr[V_k>V_l,l{\neq}k,l=1,...,m]
\]

\[
=Pr[\varepsilon_l-\varepsilon_k<\lbrace(\alpha_{0k}-\alpha_{0l})-\beta(r_k-r_l)\rbrace{e^{-\beta{p_1}}},\text{ для всех } l{\neq}k]
\]

\[
=\dfrac{exp[(\alpha_{0k}-\beta{r_k})e^{\beta{p_1}}\pi/\lambda\sqrt{3}]}{\sum_{l=1}^{m} exp[(\alpha_{0l}-\beta_{r_l})e^{\beta{p_1}\pi/\lambda\sqrt{3}}]},
\]


при условии, что $\varepsilon_j, j=1,...,m$ распределены одинаково и независимо, а функция плотности критических точек второго рода равна $F(\varepsilon)=exp(-exp(-\gamma-\varepsilon\pi/\lambda\sqrt{3}))$, где $\gamma{\approx}0.5772$ константа Эйлера. В данном примере среднее значение $\varepsilon_j$ равно нулю, а дисперсия $\lambda^2/2$, что отличается от распределения критических точек второго рода, используемого в Главе 14 и 15. Оценка нелинейной мультомиальной логит-модели дает предсказанные значения вероятности $\hat{p}_k$.

В альтернативном методе отбора данных $E[\eta|j-\text{ый портфель}]{\neq}0$ и для расчета математического ожидания принимаются предпосылки о распределении $\eta$ и $\varepsilon_1,...,\varepsilon_m$. В частности, предположим, что $\eta|\varepsilon_1,...,\varepsilon_m$ равномерно и одинаково распределены со средним $\sqrt{2}\sigma/\lambda\sum_{k=1}^{m}R_{k}\varepsilon_k$ и дисперсией $\sigma^{2}(1-\sum_{k=1}^m R_k^2)$, где $\sum_{k=1}^m R_k=0$ и $\sum_{k=1}^m R_k^2<1$ и распределение $\varepsilon_k$ было определено ранее. После некоторых математических преобразований, используемых в работе Dubin и McFadden, получим значение 

\[
E[\eta|j-\text{ый портфель}]{\neq}0=\sum_{k \neq j}^m
(\sigma\sqrt{6}R_k/\pi)[\dfrac{p{k}ln{p_k}}{1-p_k}+ln{p}].
\]

Тогда, МНК-оценка двух шаговой процедуры Хекмана равна 

\[
x_1-q_{1j}=\
\]

где $p_k$ предсказанное значение вероятности $p_k$ и $\xi$ ошибка с асимптотическим средним равным нулю.


Dubin и McFadden оценили эти модели, используя наблюдения по $3,249$ ДХ для двух вариантов потребностей: 

Heckman (1984) также смоделировал уровень потребления товаров с торговым знаком, где индивиды покупают только один товар из множества, а Cameron (1988) показал, что спрос на медицинское обслуживание зависит от выбора медицинского полиса.

Креативность необходима, когда требуется найти аналитическое выражение для вероятности выбора и для спроса, зависящего от выбора. Преимущества вычислительных методов детально рассмотрены в 12-ой и 13-ой главах. Эти методы позволяют определить оценки модели, даже когда отсутствует аналитическое решение. Тем не менее, результат всегда зависит от функциональной формы полезности и распределения ненаблюдаемых значений.

\subsection{Системы одновременных уравнений в тобит- и логит-моделях}

Для иллюстрации усовершенствования метода, ранее рассмотренного в разделе 2.4, возьмем модель отбора данных с двумя латентными переменными и зададим уравнение для латентной переменной. Общий вид такой модели:

\begin{equation}
y_1^{*}=\alpha_1y_2^{*}+\gamma_1y_1+\delta_1y_2+x'_1\beta_1+\varepsilon_1,\\
y_2^{*}=\alpha_2y_1^{*}+\gamma_2y_1+\delta_2y_2+x_2'\beta_2+\varepsilon_2,
\end{equation}

где $y_1^{*}$ и $y_2^{*}$ частично наблюдаемы, но количества наблюдений достаточно, чтобы рассчитать значения $y_1$ и $y_2$, и ошибки имеют совместное нормальное распределение. Например, можно задать бинарный индикатор, $y_1=1$, если $y_1^{*}>0$ и $y_2=y_2^{*}$, если $y_1^{*}>0$. Теоретически либо латентная переменная, либо результат наблюдений или оба значения могут выступать в качестве регрессоров, хотя для правильной идентификации необходимы ограничения, описанные ниже.

Эндогенные скрытые переменные


Самое простое ограничение: латентные переменные могут быть только независимыми параметрами (16.51). Тогда,

\begin{equation}
y_1^{*}=\alpha_{1}y_2^{*}+x_1'\beta_1+\varepsilon_1,\\
y_2^{*}=\alpha_{2}y_1^{*}+x_2'\beta_2+\varepsilon_2.
\end{equation}

Примером модели бинарного выбора с эндогенными скрытыми переменными является (16.31), для получения которого должно выполняться дополнительное условие $\alpha_2=0$ и приведенная форма должна быть четко определена. Модель (16.52) можно легко оценить, поскольку приведенная форма $y_1^{*}$ и $y_2^{*}$ получена способом, который используется для невырожденной системы одновременных уравнений. Следовательно, параметры приведенной форме можно легко оценить, используя пробит или Тобит, в зависимости от способа расчета $y_1$ и $y_2$ при заданных значениях $y_2^{*}$ и $y_1^{*}$. Оценки параметров в (16.52) могут быть расссчитаны через замену регрессоров $y_2^{*}$ и $y_1^{*}$ на $\hat{y_2^{*}}$ и $\hat{y_1^{*}}$. 

Модели типа (16.52) получили название тобит-модели с одновременной системой уравнений. Если зависимые переменные $y_1$ и $y_2$ бинарны, тогда (16.52) -- пробит-модель с одновременной системой уравнений. Способы оценки рассмотрены в работах Nelson и Olson (1978), Amemiya (1979), а также в статье Lee, Maddala и Trost (1980) и общий подход представил L.-F.Lee (1981). Стандартные ошибки рассчитываются с использованием двухшаговой процедуры для $m$-оценки. Однако, намного проще рассчитать стандартные ошибки методом парного бутстрэпа, см. раздел 11.2. Идентификация требует наложения ограничений на систему уравнений (16.51) по аналогии с линейной системой уравнения.

Эндогенные регрессоры

Модели типа (16.52) относятся к классу тобит-моделей с полностью наблюдаемыми эндогенными переменными. Тогда справедливо, что $y_2^{*}$ полностью наблюдаема, т.е. $y_2=y_2^{*}$, в то время как $y_1=y_1^{*}$, если $y_1^{*}>0$ и $y_1=0$, в иных случаях. Модель можно записать:

\begin{equation}
y_1^{*}=\alpha_1{y_2}+x_1'\beta_1+\varepsilon_1 (1),\\
y_2=x'\pi+\nu (2),
\end{equation}

где (1) -- структурное уравнение, а (2) -- приведенная форма для эндогенного регрессора $y_2$. Вновь отметим, что в этом примере $y_2$ непрерывна. Для совместно нормально распределенных ошибок $\varepsilon_1=\gamma\nu+\xi$, где $\xi$ независимые нормально распределенные ошибки (см. раздел 5.1), следовательно $y_1^{*}=\alpha_1{y_2}+x_1'\beta_1+\gamma\hat{\nu}+e_1$; $e_1$ нормально распределены. Для тестирование на эндогенность $y_2$ можно использовать тест Вальда с нулевой гипотезой $\gamma=0$, а стандарнтные ошибки взять из тобит-модели.

Эндогенные цензурированные или бинарные переменные

Анализ усложняется, если цензурированные или бинарные эндогенные переменные $y_1$ или $y_2$ выступают в роли регрессоров в (16.51). Heckman (1978) проанализировал следующую модель:

\begin{equation}
y_1^{*}=\gamma_1{y_1}+\delta_1{y_2^{*}}+x_1'\beta_1+\varepsilon_1, \\
y_2^{*}=\alpha_2{y_1^{*}}+\gamma_2{y_1}+x_2'\beta_2+\varepsilon_2,
\end{equation}

где $y_1=1$, если $y_1^{*}>0$, $y_1=0$, если $y_1^{*}{\geq}0$ и $y_2=y_2^{*}$ всегда наблюдаема. Модель усложняется тем, что $y_1$ выступает в роли регрессора. В приведенной форме для $y_1^{*}$ регрессорами могут быть только $x_1$ или $x_2$. Следовательно, должно выполняться условие согласованности, $\delta_1\gamma_1=0$. Если это условие выполняется, тогда приведенная форма примет вид:

\[
y_1^{*}=x'\pi_1+\nu_1,\\
y_2=\gamma_2{y_1}+x'\pi_2+\nu_2.
\]

Это частный случай модели Роя, где наличие признака ($y=1$) приводит только к сдвигу графика вверх или вниз (на $\gamma_2$).В целом, модели с цензурированными или усеченными эндогенными переменными трудно оценивать. Например, см. Blundell и Smith (1989).

Пример

Brooks, Cameron и Carter (1998) применили тобит-модель с систему одновременных уравнений для объяснения результатов голосования представителей конгресса по вопросу улучшения качества сахара. Ответ на голосовании, количество голосующих за улучшение качества сахара или сахарозаменителя обозначены $y_1, y_2$ и $y_3$, соответственно; $y_1$ -- бинарная переменная, а $y_2$ и $y_3$ цензурированы в нуле. Авторы составили систему одновременных уравнений для $y_1^{*}$, $y_2^{*}$ и $y_3^{*}$, таким образом, структурная модель имеет простейший вид (16.52).

Насколько приемлема данная спецификация? В рассматриваемом примере $y_2^{*}$ и $y_3^{*}$ должны зависеть от скрытой переменной $y_1^{*}$, поскольку фактически результат будет позже. Более сложный вариант, когда скрытая переменная $y_1^{*}$ зависит от фактических значений $y_2$ и $y_3$. Однако, если модель оценивается периодически, тогда можно использовать скрытые переменные $y_2^{*}$ и $y_3^{*}$. Очевидно, что обоснованность данного предположения будет зависеть от конкретного случая. Оценки параметров будут состоятельны, если ошибки имеют совместное нормальное распределение.

\subsection{Семи параметрическая оценка}

В результате цензурирования, усечения или отбора данных формируется выборка, которая отличается от совокупности, иными словами возникает проблема пропущенных данных. по сравнению с ранее рассмотренными случаями, эта проблема более серьезна, поскольку пропущены данные для зависимой переменной(-ых).

В ранее рассмотренных методах проблема пропуска данных решалась введением дополнительных ограничений на распределение так, чтобы можно было использовать функцию правдоподобия или цензурированное, усеченное или условное среднее.

Оценки уязвимы даже к незначительным погрешностям в установлении распределения случайных ошибок. Например, оценки, полученные методом максимального правдоподобия или с помощью двух шаговой процедуры Хекмана в стандартной тобит-модели несостоятельны, если нарушается либо предпосылка о нормальности, либо предпосылка о гомоскедастичности. 

Далее рассмотрим семи параметрические методы, оценки которых состоятельны даже при принятии слабых предпосылок о распределении. Перед тем как Вместе с тем, а качестве альтернативы можно продолжать использовать полностью параметрический метод, в основе которого лежат более строгие предпосылки.

\subsection{Гибкие параметрические модели}

Для начала возьмем классическую тобит-модель $y_i^{*}=x_i'\beta+\varepsilon_i$. Возможны два варианта послабления предпосылки $\varepsilon_i{\sim}N[0,\sigma_i^2]$. Во-первых, можно внедрить формулу для гетероскедастичности, $\sigma_i^2=exp(z_i'\gamma)$, тогда нужно оценить оба переметра, $\beta$ и $\gamma$. Во-вторых, можно использовать менее строгое распределение. Например, разложение в квадратный полином нормального распределения (см. раздел 9.7.7).

Для бинарной модели отбора данных может использоваться аналогичный подход, при выполнении предпосылки о совместном нормальном распределении случайных ошибок $(\varepsilon_1,\varepsilon_2)$. Lee (1983) предложил использовать $(\varepsilon_1^{*},\varepsilon_2^{*})$ вместо $(\varepsilon_1,\varepsilon_2)$? для которых предпосылка о двумерном нормальном распределении может быть более ощитима. 

Можно также использовать байесвоские методы. Chib (1992) рассматривал цензурированную тобит-модель. Автор ввел дополнительную скрытую переменную $y^{*}$ и использовал метод аугментации данных (см. раздел 13.7). Выборка Гиббса периодически используется для расчета условного апостериорного распределения (1) $\beta|y,y^{*},\sigma^2$, (2) $\sigma^2|y,y^{*},\beta$ и (3) $y^{*}|y,\beta,\sigma^2$.

Гибкий параметрический подход следует использовать для анализа нелинейных цензурированных, усеченных регрессий и регрессий отбора для счетных данных, данных дюрации и смешенных данных.
Он лучше подходит как семи параметрический метод


\subsection{Семи параметрические методы оценки цензурированных регрессий}


Рассмотрим линейную модель для скрытой переменной $y_i^{*}=x_i'\beta+\varepsilon_i$, слева цензурированной в нуле, т.е. $y_i=y_i^{*}$, если $y_i^{*}>0$ и $y_i=0$, если $y_i^{*}{\geq}0$. Как правило семипараметрическая модель имеет вид:

\begin{equation}
y_i=max(x_i'\beta+\varepsilon_i,0).
\end{equation}

Это тобит-модель (16.11)-(16.13), за исключением того, что предпосылка о нормальном распределении $\varepsilon$ не выполняется. Вместе из, с помощью преобразований (16.55) можно использовать для оценки цензурированных слева, при известном граничном значении, или справа моделей. Например, если $y=min(x'\beta+\varepsilon,U)$, тогда $U-y=max(U-x'\beta_\varepsilon,0)$. Цель состоит в получении состоятельных оценок при отсутствии полного параметрического распределения. Методы оценки называются семи параметрическими, поскольку распределение не усеченного среднего $x_\beta'$ параметризировано, а распределение случайных ошибок нет. Представленные ниже методы отличаются по предпосылкам о распределении $\varepsilon$. 

Согласно (16.8) для ML оценки известна функция кумулятивного распределения $y^{*}$ и, следовательно, $\varepsilon$. Для цензурированных данных дюрации непараметрическая оценка функции плотности распределения может быть рассчитана через формулу множительной оценки функции распределения Каплана-Майера. Вместе с тем, непараметрическая оценка $\varepsilon$ определяется через разложение в ряд Gallant и Nychka (1987); см. раздел 9.7.7. Эти семи параметрические методы максимального правдоподобия редко используются.

В литературе наиболее часто встречается расчёт оценки через условные моменты. Из (16.20) следует, что формула условного цензурированного среднего $E[y|x]$ соответствует модели «одного индекса», согласно которой $E[y|x]=g(x'\beta)$, где функция $g(\bullet)$ неизвестна, если распределение $\varepsilon$ не определено. Модель «одного индекса» (см. раздел  9.7.4) можно применять, однако $\beta$ должна быть оценена с учетом параметра сдвига и масштаба. 

В более популярном подходе рассматриваются условные цензурированные моменты, которые менее изменчивы к цензурированию. Пауэлл (Powell, 1984) предложил использовать условную медиану. Главная предпосылка –медиана $\varepsilon|x$ равна нулю, следовательно, условная медиана $y|x$ равна условному среднему $x'\beta$. Интуицию метода Пауэлла легче всего понять, предположив, что $y{\sim}iid$. Если меньше половины значений выборки цензурировано и меньше половины принимают нулевые значения, а остальные значения положительны, тогда цензурированное выборочное среднее медианы является состоятельной оценкой медианы по совокупности.  


Пауэлл (1984) применил эту идею к регрессионному анализу, действуя по такой же логике, т.е. если меньше половины значений $\varepsilon|x$ цензурированы, где $\varepsilon=y-x'\beta$ и для расчета используются оцененные значения $\beta$, тогда регрессионный анализ производится по аналогии с оценкой медианы по методу LAD (см. раздел 4.6). В результате цензурированная оценка метода наименьших модулей (CLAD) равна:

\begin{equation} 
Q_N(\beta)=N^{-1}\underline{i=1}{\overline{N}{|y_i-max(x_i'\beta,0)|}}.
\end{equation}

Необходимым условием состоятельности оценок является равенство $\varepsilon|x$ нулю. При выполнении этого условия оценки будут состоятельны, даже если условные ошибки гетероскедастичны. Оценка $\beta$ $\sqrt{N}$ состоятельна и асимптотически нормальная. Эффективность оценки может возрасти, если взвешенное по $f(0|x_i)$ значение $\varepsilon_i|x_i$ будет рассчитано в нуле. Метод CLAD может использоваться для расчета условных квантилей.

Вместо медианы можно использовать симметричное усеченное среднее, значение которого также не меняется при цензурировании. Пусть $\varepsilon|x$ симметрично распределено. Тогда, для наблюдений с положительным средним (т.е. $x'\beta>0$) $y|x$ имеет симметричное распределение на интервале $(0,2X'\beta)$. Следовательно, с равной вероятностью $x'\beta+\varepsilon+<0$ и $y=0$ или $x'\beta+\varepsilon>2x'\beta$ и все данные искусственно приравниваются к $2x'\beta$ для сохранения симметрии относительно $x'\beta$. В результате:

\begin{equation}
E[1(x'\beta>0)[min(y,2x'\beta)-x'\beta]x]=0,
\end{equation}

где $1(x'\beta)>0$ ограничение, согласно которому используются только наблюдения с положительным средним и зависимая переменная или $y=0$, или $0<y<2x'\beta$, или $2x'\beta$ если $y>2x'\beta$. Оценка момента по формуле (16.57) не дает единственного решения для $\beta$. Пауэлл (1986b) предложил симметричный цензурированный метод наименьших квадратов (SCLS):

\begin{equation}
Q_N(\beta)=N^{-1}\lbrace[y_i-max(y_i/2,x'\beta)]^{2}+1(y_i>2x_i'\beta)[y_i^2/4-max(0,x_i'\beta)]^2\rbrace,
\end{equation}

можно показать что выражение (16.58) эквивалентно условиям первого порядка для моментов выборки (16.57). Chay и Honore (1998) графически отобразили оценки SCLS, также как Honore и Powell (1994) показали попарное различие в методах. 

Melenberg и Van Soest (1996), Chay и Honore (1998) и Chay и Powell (2001) продемонстрировали практические примеры CLAD и SCLS. Pagan и Ullah (1999) рассмотрели ряд других методов.

Рассмотрим пример использования CLAD для оценки данных тобит-модели с нормальными ошибками. Оценка параметра наклона, при предполагаемом значении 1000, получилась равной 956 (стандартная ошибка равна 117) по ML-методу и равной 838 (стандартная ошибка 165) по методу CLAD. Как и предполагалось, устойчивость предпосылки о нормальном распределении для CLAD идет в счет эффективности оценок.

\subsection{Полупараметрическая оценка для моделей выбора}

Семи параметрическая оценка моделей отбора данных наиболее трудный вопрос. В качестве примера, рассмотрим часто встречающуюся модель -- бинарную модель отбора данных --, определение которой было дано в разделе 16.5.2, однако здесь опускается предположение о совместном нормальном распределении ошибок $\epsilon_1,\epsilon_2$.


Возможно найти семи параметрическую ML-оценку. В частности, Gallant и Nychka (1987) в явном виде представили бинарную модель отбора данных как метод оценки числовой последовательности, см. раздел 9.7.7.

Вместе с тем, в литературе. В качестве отправной точки, как правило, используют выражение для усеченного условного среднего, которое, согласно (16.34), равно: 

\begin{equation}
E[y_{2i}|x_i,y_{1i}^{*}>0]=x_{2i}^{*}\beta_2+E[\varepsilon_2|\varepsilon_1>-x_{1i}'\beta_1]\\
=x_{2i}'\beta_2+g(x_{1i}'\beta_1),
\end{equation}

по аналогии с (16.41), предполагается, что распределение $\varepsilon_{2i}|x_i,\varepsilon_{1i}$ зависит только от $x_{1i}$. Поскольку распределение $(\varepsilon_1,\varepsilon_2)$ не определено, нельзя определить функцию $g(\bullet)$, что затрудняет применение семи параметрического метода. 


\section{Вывод тобит-модели}

\subsection{Моменты стандартного нормального распределения для усеченных данных}

Пусть $z{\sim}N[0,1]$, плотность распределения равна $\phi(z)=(1/\sqrt{2\pi})exp(-z^2/2)$ и функция распределения обозначена $\Phi$. Поскольку $Pr[z>c]=1-\Phi(c)$, условная плотность $z|z$ равна $\phi(z)/(1-\Phi(c))$. Следовательно,


\begin{multline}
E[z|z>c]=\int_c^{\infty}z(\phi(z)/[1-\Phi(c)])\,dz\\
=\int_c^{\infty} z (1/\sqrt{2\pi})exp(-z^2/2) \,dz /[1-\Phi(c)]\\
=\int_c^{\infty}
\dfrac{\partial}{\partial{z}}
\left(-(1/\sqrt{2\pi})exp(-z^2/2)\right)
dz/
[1-\Phi(c)]\,dz\\
=\left[ -(1/\sqrt{2\pi})exp(-z^2/2) \right]_c^{\infty}/ [1-\Phi(c)]\\
=\phi(c)/[1-\Phi(c)].
\end{multline}

Аналогичным образом, 

\begin{multline}
E[z^2|z>c]=\int_c^{\infty}z^2(\phi(z)/[1-\Phi(c)])\,dz \\
=\int_c^{\infty} z{\times}z \times (1/\sqrt{2\pi}exp(-z^2/2)/[1-\Phi(c)]\,dz \\
=\int_c^{\infty}z{\times}\dfrac{\partial}{\partial{z}}\left(-(1/\sqrt{2\pi})exp(-z^2/2)\right)dz/[1-\Phi(c)]\,dz \\
=\left[z{\times}-(1/\sqrt{2\pi})exp(-z^2/2)\right]_c^{\infty}/[1-\Phi(c)] \\
-\int_c^{\infty}z{\times}\dfrac{\partial}{\partial{z}}(z)\left(-(1/\sqrt{2\pi})exp(-z^2/2)\right)dz/[1-\Phi(c)]\,dz\\
=c\phi(c)/[1-\Phi(c)]+(1-\Phi(c))/[1-\Phi(c)] \\
=c\phi(c)/[1-\Phi(c)]+1.
\end{multline}

После некоторых математических преобразований, 


\begin{align}
V[z|z>c]=E[z^2|z>c]-(E[z|z>c])^2 \\
=1+c\phi(c)/[1-\Phi(c)]-\phi(c)^2/[1-\Phi(c)]^{2}.
\end{align}



\subsection{Асимптотическая теория применения двух шаговой процедуры Хекмана к тобит-модели}

Составление матрицы асимптотической дисперсии для метода Хекмана осложнено зависимостью значений матрицы от оценок параметров, полученных на первом шаге. Существует несколько способов расчета асимптотической дисперсии, ряд из которых рассмотрен в работе Amemiya (1985, стр.369-370). Далее в основное расчета лежит общий вывод для расчета дисперсии при использовании двух шагового метода с m параметрами, ранее рассмотренный в разделе 6.6. В качестве примера приведем самый простой случай для тобит-модели (см. раздел 16.3.6). Метод Хекмана можно применить к двух шаговой оценке моделей бинарного выбора (см. раздел 16.5.4) и системе одновременных уравнений тобит-модели. Наиболее простым способ является парный бутстрэп (см. раздел 11.2).

Оценим параметр $\gamma=[\beta'\sigma]$ в (16.26) из модели для положительных значений $y_i$:

\[
y_i=x'_{i}\beta+\sigma\lambda(x'_{i}\alpha)+\nu_i
\]

\[
=w_i(\alpha)'\gamma+\nu_i,
\]

где $w_{i}(\alpha)={[{x'}_i\lambda_i({x'}_i\alpha)]}'$ и $\nu_i=y_i-{x'}_i\beta-\sigma\lambda({x'}_i\alpha)$ гетероскедастичны с дисперсией $\sigma^2_{\nu_i}$, которая определена в (16.24). На первом шаге находим оценку $\hat{\alpha}$ неизвестного параметра $\alpha$ ML методом. Двух шаговая процедура Хекмана может быть записана двумя уравнениями:

\begin{equation}
\sum_{i=1}^N(y_i-\Phi({x'}_i\alpha))
\frac{\phi^2({x'}_i\alpha)}{\Phi({x'}_i\alpha)(1-\Phi({x'}_i\alpha))}x_{i}=0
\end{equation}


\[
-\sum_{i=1}^N d_iw_i(\alpha)(y_i-w_i(\alpha)'\gamma) =0,
\]

где первое и второе выражения условия первого порядка МНК, позволяющие найти значения $\alpha$ и $\gamma$, соответственно, при положительных значениях $y_{i}(d=1)$.

В общем виде эти уравнения можно записать: $\sum_{i=1}^Nh(x_i,\theta)=0$, где $\theta=(\alpha',\gamma')'$. При обычном разложении в ряд Тейлора до первой степени $\hat{\gamma}-\gamma{\to}^dN[0,G^{-1}_0S_0(G^{-1}_0)']]$, где $G_0=limN^{-1}E[\sum_{i=1}^N\partial h(x_i,\theta)/\partial\theta]$ и $S_0=limN^{-1}E[\sum_{i=1}^N\partial h(x_i,\theta)h(x_i,\theta)]'$. Задача заключается в том, чтобы найти такое значение субэлемента, которое можно было бы подставить вместо $\gamma$. Такое упрощение возможно, поскольку $\partial h(x_i,\theta)/\partial\theta$ ограничивает треугольную область, поскольку $\gamma$ отсутствует в изначальной системе уравнений. Разделение дает следующий результат:

\[
V[\hat{\theta}_2=G_22^{-1}\left\lbrace S_22+G_21[G_11^{-1}S_11G_11^{-1}]G_21'-G_{21}G_{11}'S_{12}-S_{21}G_{11}^{-1}G_{21}'\right\rbrace{G_{22}^{-1}}],
\]

где значение матриц определено в разделе 6.6.

При детальном рассмотрении задачи, выразим все через $G_0$. Тогда
\[
G_{11}=lim\dfrac{1}{N}\sum_{i=1}^N \dfrac{\phi^2(x_i'\alpha)}{\Phi(x_i')(1-\Phi(x_i'\alpha))}x_ix_i'
\]

\[
G_{21}=lim\dfrac{1}{N}\sum_{i=1}^N d_iw_i\dfrac{\partial\lambda(x'_{i}\alpha}{\partial\alpha},
\]

\[
G_{22}=lim\dfrac{1}{N}\sum_{i=1}^N E[d_{i}w_iw'_i].
\]

Для выражения $G_11$ используется факт того, что $G^{-1}_{11}$ равно дисперсии ML оценки Пробит-модели. Выражение $G_{21}$ получается при подстановке: 

\[
E\left[\dfrac{{\partial}h_{2i}}{\partial\theta'_{i}}\right]=E \left[\dfrac{\partial d_{i}w_{i}(\alpha)(y_{i}-w_{i}(\alpha)')\gamma}{\partial{\alpha}}\right]
\]

\[
=E\left[w_{i}\dfrac{{\partial}d_{i}w_{i}(\alpha)}{\partial\alpha'}\right]
\]

\[
=E\left[d_{i}w_{i}\dfrac{\partial\lambda(x'_{i}\alpha)}{\partial\alpha}\right].
\]

Выражение для $G_{22}$ построено на основе выражения

\[
\dfrac{\partial h_{2i}}{\partial\theta'_{2}}=\dfrac{{\partial}d_{i}w_{i}(\alpha)(y_i – w_{i}(\alpha)'\gamma)}{\partial\gamma}=d_{i}w_{i}w'_i
\]

Возвращаясь к $S_0$, получим:

\[
S_{11}=G^{-1}_{11},
\]

\[
S_{21}=0
\]

\[
S_{22}=lim\dfrac{1}{N}\sum^{N}_{i=1}E[d_{i}(y_i – w_{i}(\alpha)'\gamma)^2]
\]

Для получения выражения $S{11}$ применяем равенство информационной матрицы. Взяв математическое ожидание и сделав несколько манипуляций, получим, что $S_{21}=0$ и $S_{22}$ эквивалентно $V[\nu_i]$.

Объединив эти результаты, можно рассчитать двух шаговую оценку Хекмана $\hat{\gamma}{\sim}^{a}N(\gamma,V_{\gamma})$, где

\begin{equation}
\hat{V}_{\gamma}=(\hat{W}'\hat{W})^{-1}(\hat{W}'\sum_{\hat{\nu}}\hat{W}+\hat{W}'\hat{D}\hat{V}_{\alpha}\hat{D}\hat{W})(\hat{W}'\hat{W})^{-1},
\end{equation}

и, где, $\hat{W}'\hat{W}=\sum^{N}_{i=1}d_{i}\hat{w}_{i}\hat{w}'_{i},\hat{D}=Diag[\partial\lambda(x'_{i}\alpha)/\partial\alpha|_{\hat{\alpha}}]$, $\hat{V}_{\alpha}$ ковариационная матрица для ML оценки пробит-модели на первом шаге, а $\Sigma_{\hat{\nu}}$ диагональная матрица и значения на диагонали равны $\hat{\sigma}^{2}_{\nu_i}$. Значение $\hat{\sigma}^{2}_{\nu_i}$. Можно легко рассчитать, если программа предусматривает расчет матриц. Сложнее рассчитать $\sigma^{2}_{\nu_i}=V[\nu_i]$, данное в (16.24). При возникновении трудностей в расчете $\sigma^{2}_{\nu_i}=V[\nu_i]$, возможно использовать подход Уайта (1980) $\sigma^{2}_{\nu_i}=V[\nu_i]$ и заменить $\sigma^{2}_{\nu_i}$ на $\hat{\sigma}^{2}_{i}=(y_{i}-x'_{i}\hat{\beta}+\hat{\sigma}\lambda_{i}(x'_{i}\hat{\alpha}))^2$

\section{Практика применения}

В большинстве статистических пакетов предусмотрена ML оценка тобит-модели при выполнении предпосылки о нормальности распределения. Двусоставную модель легко оценить , поскольку можно по-отдельности оценить каждую часть. Бинарная модель выбора может быть оценена по двух шаговой процедуре Хекмана, используя пробит и МНК. Тем не менее, стандартные ошибки трудно рассчитать через пробит и МНК из-за двух шаговой процедуры и намного проще использовать двух шаговый инструмент Хекмана. Как правило, использование семи параметрических методов требует специальной программы в языке программирования, например, GAUSS. В некоторых статистических пакетах предусмотрена возможность ML оценки цензурированных или усеченных данных, например модели Пуассона и модели Паскаля с дискретными данными.

Цензурирование и усечение можно легко выразить, если распределение параметров верно определено. Например, цензурированные сверху данные могут быть легко определены, если логнормальное распределение хорошо согласовывается с данными. Аналогично могут использоваться данные низкой точности, предпосылки о распределении которых менее строгие. 

Больше проблем возникает с оценкой моделей отбора данных. Большинство моделей этого типа полагаются на строгие предпосылки о распределении. Семи параметрические методы до сих пор борются с требованием к спецификации модели, что переменная, которая определяет участие, не должна определять конечный результат. Более простой метод, обозначенный в литературе по эффектам условий эксперимента, заключается в ограничении внимания к случаям, когда может быть обосновано в необходимости выбора только для наблюдаемых данных.

\section{Последующая литература}

Существует много литературы по моделям отбора данных. Подробный список источников дан в работе Maddala (1983) и Gourieroux (2000), более краткий список в работе Amemiya (1984,1985) и Greene (2003). 

16.3 Тобин (1958) предложил и примененил тобит-модель к анализу затрат. Amemiya (1973) формально обосновал состоятельность оценок и нормальное распределение последних, полученных данным методом. Heckman (1974) применил тобит-модель к анализу предложения женского труда с последующим детальным рассмотрением результатов.

16.4. Многие исследования rand health insurance experiment, например, работа Duan и др. (1983) могут послужить примером двусоставной модели.

16.5 Heckman (1976,1979) рассмотрел двух шаговый метод оценки бинарной модели выбора, который лежит в основе многих семи параметрических способов оценки. Mroz (1987) показал роль принятия предположения об экзогенном характере заработной платы.

16.7. Существует много интерпретаций идей Роя (1951), также как много вариантов тобит-модели. L.-F.Lee (1978) оценил разницу между оплатой труда работников, состоящих и не состоящих в профсоюзе.

16.8. Работа Dubin и McFadden (1984) является одним из основных примеров структурного микроэконометрического анализа, построенного на полной спецификации функции полезности и распределения ненаблюдаемых значений.

16.9 Семи параметрический метод оценки моделей бинарного выбора детально рассмотрена в книге M.-J.Lee (1996), Pagan и Ullah (1999), обзор моделb дан в работе Vella (1998) и L.-F.Lee(2001). Вместе с тем, Chay и Honore (1998), а также Chay и Powell (2001)показали применение модели к оценке цензурированных данных, а Melenberg и Van Soest (1996) к оценке бинарных моделей выбора. 

16-1 В упражнении рассматривается как влияет степень участия на выводы тобит-модели.

(а) Сгенерируйте 200 раз скрытую переменную $y^{*}=k+3x+u$, где $u{\sim}N[0,3]$ и $x{\sim}uniform[0,1]$. Выберите такое $k$, чтобы $30\%$ значений $y^{*}$ были бы отрицательны.
(b) Сгенерируйте усеченную или цензурированную подвыборку, отбрасывая наблюдения для которых $y^{*}<0$
(c) Оцените модель методом наименьших квадратов для 2,000 наблюдений, предполагая, что скрытая переменная наблюдаема. Сравните полученные результаты с теорией, учитывая, что была сделана одна репликация.

(d) Оцените модели МНК используя усеченную подвыборку снизу, т.е. $y>0$.

(e) Найдите оценки параметров, используя метод максимального правдоподобия для усеченных данных на всей выборке. Сравните полученные результаты с выводами в (c) и (d)

(f) Повторите шаги (a)-(f) для $k$ равного $20\%, 40\%$ и $50\%$. Сравните результаты с выводами при $k=30\%$. На основе полученных результатов, сделайте вывод о влиянии цензурирования высокого порядка на значения оценок параметров. Подкрепите ваши аргументы теорией.

16-2 Рассмотрите модель скрытой переменной $y_i^{*}=x_i'\beta+\varepsilon_i$, $\varepsilon_i{\sim}N[0,\sigma^2]$. Предположим, что $y_i^{*}$ цензурирована сверху, следовательно $y_i=y_i^{*}$, если $y_i^{*}<U_i$ и $y_i^{*}{\geq}U_i$, если $y_i^{*}U_i$, верхний предел $U_i$ известная константа для каждого индивида (например, данные) и может меняться от индивида к индивиду.

(a) Запишите функцию максимального правдоподобия. (Примечание. Функция имеет вид отличный от стандартной функции максимального правдоподобия, поскольку добавляется функция $U_i$ и  )

(b) Запишите выражения для усеченного среднего $E[y_i, x_i,y_i<U_i]$. [Примечание. Для $z{\sim}N[0,1]$ $E[z|z>c]=\phi(c)/[1-\Phi(c)]$; $E[z|z<c]=-E[-z|-z>-c]$ и $-z{\sim}N[0,1].$]

(c) Запишите двух шаговую процедуру Хексмана для оценки модели из пункта (a).

(d) Запишите выражение для усеченного среднего $E[y_i|x_i]$. [Примечание. Ответ практически полностью совпадает с результатом в пункте (b).]

16-3 Оцените последствия неправильной спецификации тобит-модели. Для анализа возьмите модель из упражнения 16.1.

(а) Сгенерируйте $y^{*}$ при гетероскедастичных случайных ошибках, т.е. $u{\sim}N[0,\sigma^2z]$, где $z>0$ и корреляция между $z$ и $x$ ненулевая, но и не равна единице. Пусть $k$ равно $30\%$ всех цензурированных данных. Оцените модель цензурированных данных с нормально распределенными ошибками и сравните полученные результаты с оценками, если случайные ошибки гомоскедастичны.

(b) Пусть предпосылка о нормальности не выполняется. Используя процедуру Монте-Карло, оцените модель, если количество наблюдений равно 1,000 и процедура повторяется 500 раз. Для каждого повтора сгенерируйте цензурированную выборку так, чтобы ошибки были нормально распределены и параметры распределения принимали одно из двух значений $N[1,9]$ или $N[0.4,1]$ c вероятностями $0.4$ и $0.6$, соответственно. Оцените модель  и сравните полученные результаты с результатами, когда предпосылка о нормальности выполняется.

16-4 Рассмотрим модель Пуассоновской регрессии, где плотность распределения $y^{*}$ равна $f^{*}(y^{*})=e^{-\mu}\mu^{y}/y^{*}, y_i^{*}=0,1,2,...$ и наблюдения не зависимы по $i$. Из-за ошибки кодирования значение $y$ наблюдаемо при $y^{*}{\geq}2$. Если $y^{*}=0$ или $1$ известно только, что $y^{*}{\leq}1$, иначе можно записать $y^{*}=1$. Таким образом, $y=y^{*}$ для $y_i^{*}{\geq}2$ и $y=1$ для $y_i^{*}=0$ или $1$.

(а) Найдите значение $f(y)$ для наблюдаемых значений $y$.
(b) Найдите $E[y]$. Для данного ввода требуются математические преобразования.


(с) Запишите точную формулу для целевой функции, которая позволяла бы рассчитать состоятельные оценки $\beta$, используя данные $y_i$, $d_i$ и $x_i$.

(d) Запишите точную формулу для целевой функции, которая позволяла бы рассчитать состоятельные оценки $\beta$, используя данные $d_i$ и $x_i$.

(e) Возможно ли получить состоятельные оценки $\beta$, используя только $d_i$ и $x_i$. Поясните ваш ответ.

16-5 
Используя 50\% данных RAND по затратам на здоровье за 12 месяцев оцените модели, представленные в этой главе и дайте ответ на вопрос: какая из моделей наилучшим образом подходит для оценки затрат? Опишите процесс формирования моделей, сравните результаты и выберите одну из трех моделей.
Обратите внимание на выбор ограничений.

(a)	Используя выводы по переменным затрат, проанализируйте к чему приводит большая пропорция нулевых наблюдений. Приводит ли это к нарушению предпосылки о нормальности? Существует ли преобразование, которое бы позволяло сделать предпосылку о нормальности более применимой?
(b)	Проанализируйте три модели, с одинаковыми независимыми переменными. Параметры совпадают с параметрами в упражнении 20.6. Среди моделей: (i) тобит-модель; (ii) двусоставная модель (TPM) и (iii) модель отбора данных. Опишите соотношения и взаимосвязи между моделями, сравните и выберете одну из моделей. Если вы столкнулись с проблемами, касающихся спецификации или оценки параметров, обозначьте их и предложите возможные пути решения. Особое внимание обратите на ограничения.
(c)	Оцените все три модели. В двусоставной модели второе уравнение составлено только для индивидов с ненулевыми затратами. Для оценки модели отбора данных используется ML-оценка и двух шаговая процедура Хекмана. 
(d)	Каким образом можно сравнить статистические выводы по трем моделям? Какая модель наилучшим образом согласуется с данными? Какие критерии вы используете для сравнения?
(e)	Оцените влияние двух переменных, log income и log (1+доля совместного страхования) на уровень затрат на здоровье. Сравните предельные эффекты изменения этих переменных для тобит-модели и TPM. Подумайте, как наилучшим образом проинтерпретировать полученные результаты для гетерогенной выборки.
(f)	Дайте краткое пояснение, при выполнении каких предпосылок квантильная регрессия (см. раздел 4.6) может быть альтернативным методом оценки. Какие преимущества и недостатки такой альтернативы?


