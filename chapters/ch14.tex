
\part{Модели пространственных данных}

Часть 4, состоящая из глав с 14 по 20, охватывает базовые нелинейные модели ограниченных зависимых переменных для пространственных данных,  определяемые диапазоном значений,  принимаемых зависимой переменной. Затронутые темы включают модели для бинарных, мультиномиальных, счетных данных и данных о длительности состояний. Также рассматриваются сложности, связанные с цензурированием, усечением и самоотбором выборки (sample selection). Основную методологическую базу для моделей в Части 4 составляют метод наименьших квадратов и метод максимального правдоподобия.

Главы 14 и 15 посвящены моделям для бинарных и мультиномиальных данных,  которые обычно используются при анализе ситуаций дискретных исходов и дискретного выбора. Метод максимального правдоподобия здесь является ведущим. Различные способы параметризации условной вероятности в моделях такого типа приводят к применению различных моделей. Особенно прочно установилось использование логит и пробит-моделей. Современная литература сфокусирована на менее жестких методах моделирования с более гибкими функциональными формами для условной вероятности и учитывающих индивидуальную ненаблюдаемую неоднородность. Эти задачи побуждают к применению полупараметрических  и симуляционных  методов оценивания.

Цензурирование,  усечение и самоотбор при построении выборки приводят к  нескольким важным классам моделей. Эти модели анализируются в Главе 16. Давно существующая тобит-модель занимает здесь центральное  место,  но её состоятельное оценивание и статистические выводы опираются на сильные  предположения о распределении переменных. Также мы исследуем более новые полупараметрические методы,  которые основываются на более слабых допущениях.

Главы  17 --- 19 посвящены моделям длительности, которые фокусируются на факторах определяющих  продолжительность того или иного состояния,  таких как длительность периода безработицы,  или на моделировании функции риска при переходе из некоторого начального состояния в другое. Анализ охватывает как модели с дискретным,  так и с непрерывным временем,  а также использование как параметрических,  так и полупараметрических методов,  включая стандартные модели как,  например,  экспоненциальное распределение,  распределение Вейбулла или модель пропорциональных рисков. Глава 18 содержит формулировку и интерпретацию широкого круга моделей,  включающего исследования ненаблюдаемой неоднородности. Относительная важность влияния состояния и ненаблюдаемой неоднородности на среднюю длительность является главным вопросом,  решение которого ставит вопрос об альтернативных подходах к моделированию. В главе 19 описаны модели с несколькими типами событий с использованием подхода конкурирующих рисков и модели множественных состояний.

В главе 20 приведен анализ счетных событий,  типа данных,  который обычно используется для экономики здравоохранения. Существует много общего между моделями счетных данных и моделями продолжительности,  поскольку их общим основанием является анализ случайных процессов. Анализируются широкоиспользуемые распределение Пуассона и отрицательное биномиальное распределение. Также рассмотрены  такие важные классы моделей как \hl{модель с двойным барьером,  модель с раздутым нулем,  модель латентных признаков,  модели с эндогенным регрессором},  каждая из которых описывает одну из черт случайного процесса.



\chapter{Модели бинарного выбора}

\section{Введение}

\textbf{Модель дискретного исхода или качественной реакции} --- это модель зависимой переменной, которая показывает, в какой из $m$ взаимно исключающих классов значений попадет интересующий нас исход. Часто отсутствует естественная упорядоченность классов значений. Например,  классификация может быть проведена по роду деятельности наемных работников.

В этой главе рассматривается простейший случай \textbf{бинарного выбора}, для которого возможны только два исхода. Например, является ли индивид занятым или безработным или приобретет ли покупатель товар или нет. Ситуации бинарного выбора просты для моделирования, и модели обычно оцениваются методом максимального правдоподобия,  поскольку распределение значений обязательно является распределением Бернулли. Если вероятность одного исхода равна $p$, то вероятность другого исхода будет равна $\left(1-p\right)$. В регрессионных моделях вероятность $p$ будем изменяться между индивидами в зависимости от значений регрессоров. Две стандартные модели бинарного выбора, логит и пробит-модели,  устанавливают разные функциональные формы для этой вероятности как функции аргумента. Качественная разница между этими двумя подходами заключается примерно в том же,  в чём и при использовании различных функциональных форм условного среднего в линейной регрессии.

В Разделе 14.2 приведен пример бинарных данных. Раздел 14.3 представляет обобщение статистических результатов для стандартных моделей,  включая логит и пробит-модели. В Разделе 14.4 модели бинарного выбора представлены как возникающие из лежащих в их основе скрытых переменных. Эта формулировка полезна,  потому что позволяет легко перейти к моделям множественного выбора (см. Главу 15) и моделям с цензурированными значениями и самоотбором выборки  (см. Главу 16). В Разделе 14.5 подробно описывается необходимые модификации стандартных методов оценки,  когда в выборку включено слишком большое число исходов из некоторой группы исходов. Проблемы агрегации рассматриваются в разделе 14.6. Полупараметрические методы для моделей бинарного выбора, которые снимают ряд ограничений на параметры модели вероятности $p$,  представлены в Разделе 14.7.

\section{Пример бинарной зависимой переменной: выбор способа рыбалки}

В этом разделе моделируется выбор между рыбалкой с судна и рыбалкой с пристани. Зависимая переменная задается следующим образом

\[
y_i=
\begin{cases}
1, \text{если выбрана рыбалка с судна,} \\ 
0, \text{если выбрана рыбалка с пристани,}
\end{cases}
\] 
где значения $1$ и $0$ выбраны для простоты. Единственной объясняющей переменной является $x_i=\ln  relp_i= \ln  \left(relp_i\right) $ где $relp$ обозначает отношение цены рыбалки с судна ($price_{charter}$) к цене рыбалки с пристани $(price_{pier})$. Таким образом, 

\[
x_i=\ln  relp_i=\ln  (price_{charter, i}/price_{pier, i}).
\] 
Цены на рыбалку с судна и на рыбалку с пристани варьируются среди индивидов под влиянием разнообразных факторов,  например,  разницы в доступности. Ожидается,  что вероятность выбора рыбалки с судна снижается,  если ее относительная цена растет.

Рассмотрим данные,  приведенные в таблице 14.1. Выборка из 630 индивидов --- это подмножество набора данных,  детально описанного в разделе 15.2,  в котором рассматриваются 4 различных способа рыбалки,  а также принимаются во внимание дополнительные регрессоры. Рыбалку с судна предпочли 71.7\% участников выборки. Для людей,  выбравших рыбалку с судна,  она была в среднем дешевле,  чем рыбалка с пристани,  а именно 75\$ против 121\$. Для людей,  выбравших рыбалку с пристани,  верной оказывалась обратная ситуация. Таким образом,  как оказалось,  цена производит ожидаемый эффект.

\begin{center}
\begin{table}[h]
\caption{\label{tab:fishres} Выбор способа рыбалки: результаты}
\begin{tabular}{lccc} 
\hline 
\hline
 & \multicolumn{2}{c}{\textbf{Среднее по подмножествам выборки}} & \\ 
\hline 
 & ${\mathbf y}{\mathbf =}{\mathbf 1}$ & ${\mathbf y}{\mathbf =}{\mathbf 0}$ & \textbf{Итог по всем}\\ 
\textbf{Переменная} & \textbf{Рыбалка с лодки} & \textbf{Рыбалка с пристани} & ${\mathbf y}$ \\
\hline 
Цена рыбалки с судна & 75 & 110 & 85 \\  
$(price_{charter}(\$))$ & & & \\
Цена рыбалки с пристани & 121 & 31 & 95 \\
$(price_{pier}(\$))$ & & & \\
$\ln relp$  & -0.264 & 1.643 & 0.275 \\
Доля выбравших & 0.717 & 0.283 & 1.000 \\ 
Количество наблюдений & 452 & 178 & 630 \\ 
\hline
\hline 
\end{tabular}
\end{table}
\end{center}


\textbf{Линейная регрессия} зависимой переменной $y_i$ от независимой переменной $x_i$ игнорирует дискретность зависимой переменной и не ограничивает прогнозируемую вероятность интервалом от 0 до 1.

\textbf{логит-модель} является более подходящей (см. параграф 14.3.4) и определяет вероятность по формуле

\[
p_i=\Pr\left[y_i=1\left|x_i\right.\right]=\frac{\exp\left(\beta_1+\beta_2x_i\right)}{1+\exp\left(\beta_1+\beta_2x_i\right)}.
\] 
Эта модель несомненно обеспечивает $0<p_i<1$. Метод максимального правдоподобия (см. параграф 14.3.3) дает оценки параметров,  приведенные в первом столбце таблицы 14.2. Предполагаемый предельный эффект в логит-модели определяется по формуле

\[\frac{dp_i}{dx_i}=\frac{\exp\left(\beta_1+\beta_2x_i\right)}{{\left(1+\exp\left(\beta_1+\beta_2x_i\right)\right)}^2}\beta_2.\] 

\begin{table}[h]
\caption{\label{tab:fishlogit} Выбор способа рыбалки: расчеты для логит и пробит-моделей}
\begin{minipage}{17cm}
\begin{tabular}{lccc} 
\hline 
\hline
\textbf{Регрессор}\footnote{Зависимая переменная $y=1$,  если выбрана рыбалка с судна,  $y=0$,  если выбрана рыбалка с пристани. Регрессор $x=\ln relp$ --- это натуральный логарифм отношения цены рыбалки с лодки к цене рыбалки с пристани. Значимость коэффициентов моделей,  полученных методом максимального правдоподобия для логит и пробит-моделей и с помощью МНК для линейной регрессии,  оцениваются $t$-статистикой в скобках.} & \textbf{логит-модель} & \textbf{пробит-модель} & \textbf{Линейная регрессия} \\ 
\hline 
Константа & 2.053 & 1.194 & 0.784 \\ 
 & (12.15) & (13.34) & (65.58) \\
Коэффициент у $\ln relp$ & $-1.823$ & $-1.056$ & $-0.243$ \\  
 & $(-12.61)$ & $(-13.87)$ & $(-28.15)$ \\
$-\ln L$ & $-206.83$ & $-204.41$ & --- \\ 
Псевдо R-квадрат & 0.449 & 0.455 & 0.463 \\ 
\hline
\hline 
\end{tabular}
\end{minipage}
\end{table}
Поскольку $\widehat{\beta}_{2,LOGIT} < 0$ следовательно,  как и ожидалось,  $dp_i/dx_i<0$. Фактическая величина предельного эффекта изменяется вместе со значением $x_i$ (см. Параграф 14.3.2). Приближением предельного эффекта для логит-модели,  в отличие от других моделей,  является $dp_i/dx_i \simeq  \overline{y}\left(1-\overline{y}\right) \widehat{\beta}_2=-0.370$. Линейная регрессия напротив дает прямую оценку,  равную -0,243.

В качестве альтернативной используется \textbf{пробит-модель} (см. подраздел 14.3.5),  которая определяет

\[p_i=\Pr\left[y_i=1\left|x_i\right.\right]=\Phi \left(\beta_1+\beta_2x_i\right), \] 
где $\Phi (\cdot )$ --- это функция стандартного нормального распределения. 

Таким образом,  $p_i=\int^{\beta_1+\beta_2x_i}_{-\infty} \left(2\pi \right)^{-1/2} e^{-z^2/2}dz$. Коэффициенты,  полученные методом максимального правдоподобия,  приведены во втором столбце таблицы 14.2 и заметно отличаются от коэффициентов для логит-модели. Поскольку оценки были получены с использованием различных спецификаций моделей, эти коэффициенты не сопоставимы. Эта ситуация аналогична невозможности сравнивать коэффициенты моделей с условным средним $x'\beta $ и $\exp \left(x'\beta \right)$. Для пробит-модели справедливо $dp_i/dx_i =\phi\left(\beta_1+\beta_2x_i\right)\beta_2$,  где $\phi (\cdot )$ --- функция плотности стандартного нормального распределения. Тогда,  снова получаем,  что $dp_i /dx_i<0$,  пока $\widehat{\beta}_{2, PROBIT} < 0.$

Несмотря на то,  что коэффициент при независимой переменной неизбежно различается среди моделей,  из таблицы 14.2 видно,  что t-статистика везде примерно одинакова и достигает очень большой величины. Значение логарифмической функции правдоподобия для пробит-модели,  2,42,  выше этого же значения для логит-модели. Это свидетельствует в пользу пробит-модели,  поскольку обе модели используют одинаковое количество параметров. Для множества других примеров разница между значениями $\ln  L$ среди моделей невелика. Прогнозируемые с помощью трех моделей значения вероятности представлены на графике как функции от $x$ на рисунке 14.1. Для линейной регрессии предполагается,  что функция $\Pr  \left[y_i=1\left|x_i\right.\right]\ =\beta_1+\beta_2 x_i$ линейна по $x_i$,  тогда как нелинейные функции для логит и пробит-моделей в принципе эквивалентны.

\section{Логит и пробит-модели}

Далее будет приведена более формальная теория для этих моделей. Проблема бинарного выбора будет показана как прямое продолжение примера с подбрасыванием монеты из вводных статистических курсов, только теперь вероятность успеха  зависит от регрессора. Два обычно используемых способа параметризации приводят к логит и пробит-моделям. Обоснование таких способов параметризации с применением скрытых переменных будет приведено в разделе 14.4.

Оценка вероятности по рассмотренным моделям

\textbf{Красивый график со страницы 466}

Рисунок 14.1. Рыбалка с лодки: предсказанная вероятность с использованием логит,  пробит-моделей и линейной регрессии,  в качестве единственного регрессора используется натуральный логарифм отношения цен. Действительные значения исходов,  1 и 0,  также отражены на графике для наглядности. Приведены данные для 620 случаев.

\subsection{Общая модель бинарного выбора}

Для случаев бинарного выбора зависимая переменная $y$ принимает одно из двух возможных значений. Предположим,  что

\[ 
y= \begin{cases}
1 \text{с вероятностью} \hspace{0.3cm} p,  \\ 
0 \text{с вероятностью} \hspace{0.3cm} 1-p. 
\end{cases}
\] 
Общность модели никак не ограничивается выбором значений для исходов,  равных 1 и 0,  поскольку моделируется только переменная $p$,  обозначающая вероятность наступления конкретного исхода. Во вводном курсе статистики эта модель описывает результат подбрасывания монеты. Выпадение орла означает,  что $y=1$,  и происходит с вероятностью $p$.

Регрессионная модель строится путем параметризации вероятности $p$ в зависимости от вектора независимой переменной $x$ и вектора-столбца параметров $\beta$ размера $K \times 1$. Обычно используется модель с одноиндексной формой,  для которой \textbf{условная вероятность} полагается

\begin{equation} 
\label{GrindEQ__14_1_} 
p_i\equiv \Pr  \left[y_i=1\left|x_i\right.\right] =F\left(x'_i\beta \right),  
\end{equation} 
где $F(\cdot )$ --- выбранная функциональная форма модели. Чтобы обеспечить выполнение условия $0\le p\le 1$ естественно определить $F(\cdot )$ как некоторую функцию  распределения.

В таблице 14.3 представлены наиболее часто используемые модели бинарного выбора. \textbf{логит-модель} возникает,  если $F(\cdot )$ --- функция логистического распределения. \textbf{пробит-модель} возникает,  если $F\left(\cdot \right)$ ---функция стандартного нормального распределения. Обратите внимание,  что,  поскольку $F\left(\cdot \right)$ является функцией распределения,  то она используется только для моделирования значений параметра $p$,  и никак не указывает на функцию распределения переменной $y$. Реже используемая \textbf{двойная логарифмическая модель} возникает,  если для $F\left(\cdot \right)$ используется функция распределения экстремальных значений. Эта функция отличается от остальных,  поскольку является асимметричной относительно нуля,  и используется,  если один из исходов является более редким. В \textbf{модели линейной регрессии} не используется функция распределения,  вместо этого полагает $p_i=x'_i\beta $.
 
\begin{table}[h]
\begin{center}
\caption{\label{tab:binarychoice} Проблема бинарного выбора: наиболее часто используемые модели}
\begin{tabular}{lcc} 
\hline 
\hline
\textbf{Модель} & \textbf{Вероятность }$(p=\Pr[y=1\left|x\right.])$ & \textbf{Предельный эффект}$(\partial p/\partial x_j)$ \\ 
\hline
логит-модель & $\Lambda \left(x'\beta \right)=\frac{e^{x'\beta}}{1+e^{x'\beta}}$\newline  & $\Lambda \left(x'\beta \right)\left[1-\Lambda \left(x'\beta \right)\right]\beta_j$ \\
пробит-модель & $\Phi \left(x'\beta \right)=\int^{x'\beta }_{-\infty }{\phi (z)dz}$ & $\phi (x'\beta )\beta_j$ \\
Двойная логарифмическая & $C\left(x'\beta \right)=1- \exp(-\exp(x'\beta))$ & $ \exp(- \exp  (x'\beta))\exp  (x'\beta)\beta_j$ \\ 
модель & & \\
Линейная регрессия & $x'\beta $ & $\beta_j$ \\ 
\hline 
\hline
\end{tabular}
\end{center}
\end{table}

 

\subsection{Предельные эффекты}

Зачастую интерес представляет \textbf{предельный эффект} от изменения независимой переменной $x$ на условную вероятность наступления $y=1$. Для общей модели вероятности \eqref{GrindEQ__14_1_} и изменения значения $j$-го регрессора,  предельный эффект рассчитывается по формуле

\begin{equation} 
\label{GrindEQ__14_2_} 
\frac{\partial \Pr[y_i=1|x_i]}{\partial x_{ij}}=F'\left(x'_i\beta \right)\beta_j,  
\end{equation} 
где $F'\left(z\right)=\partial F(z)/\partial z$. Предельные эффекты изменяются с  изменением $x_i$, как и для любой нелинейной модели, а также зависят от выбора формы $F(\cdot )$. В последнем столбце таблицы 14.3 приведены формулы предельных эффектов для моделей,  используемых для ситуаций бинарного выбора.

Предельные эффекты для нелинейных моделей обсуждаются в параграфе 5.2.4. Для каждой конкретной модели существует несколько методов расчета среднего предельного эффекта. Лучше всего использовать формулу $N^{-1}\sum_i F'(x'_i\widehat\beta) \widehat\beta_j$,  то есть среднее предельных эффектов по выборке. Некоторые программы вместо этого  рассчитывают предельный эффект для среднего арифметического каждого регрессора, $F'( \overline{x}' \widehat\beta) \widehat\beta_j$. Еще один способ расчета предельного эффекта --- оценивание в точке  $\overline{y}$, выборочного среднего $y$, т.е. $F(x'\beta)=\overline{y}$ и $F'(x'\beta)=F'(F^{-1}(\overline{y}))$. Такой подход особенно удобен для логит-модели,  поскольку тогда предельный эффект будет оценен как $\overline{y}(1-\overline{y}){\widehat\beta}_j$. Дальнейшие рассуждения для конкретных моделей приведены в параграфах 14.3.4 --- 14.3.7.

Многие исследования вместо предельных эффектов  приводят только коэффициенты регрессии. Стандартные модели бинарного выбора --- это одноиндексные модели,  следовательно,  отношение коэффициентов двух разных регрессоров равно отношению их предельных эффектов.Знак коэффициента  модели совпадает со знаком предельного эффекта, т.к. $F'(\cdot)>0$. Зная коэффициенты модели можно оценить сверху  значение предельных эффектов. Для логит-модели --- это $\partial p/ \partial x_j \le 0.25\widehat\beta_j$, т.к. $\Lambda (x'\beta) (1-\Lambda (x'\beta)) \le 0.25$, с максимальным значением при $\Lambda (x'\beta)=0.5$ и $x'\beta=0$. Для пробит-модели --- $\partial p/\partial x_j \le 0.4 \widehat\beta_j$, т.к. $\phi(x'\beta)\le 1/\sqrt{2\pi} \simeq 0.4$,  с максимальным значением при $\Phi (x'\beta)=0.5$ и $x'\beta =0$

\subsection{Метод максимального правдоподобия}

Оценивание производится по выборке $(y_i,  x_i)$, $i=1, \ldots,  N$,  в которой предполагается независимость по $i$. Здесь приведены результаты для вероятности $p_i$,  определяемой по формуле \eqref{GrindEQ__14_1_},  с уточнением сначала для логит, а затем --- для пробит-модели.

\subsubsection*{Метод максимального правдоподобия для общей модели бинарного выбора}

Исход имеет распределение Бернулли или биномиальное распределение с одним испытанием. Очень удобно использовать следующую  компактную форму  запись для \textbf{функции вероятностей}  $y_i$:

\begin{equation} 
\label{GrindEQ__14_3_}
 f(y_i|x_i)=p^{y_i}_i(1-p_i)^{1-y_i}, y_i=0, 1,  
\end{equation} 
где $p_i=F(x'_i\beta )$. Данная формула даёт вероятности $p_i$ и $(1-p_i)$,  т.к.  $f(1)=p^1(1-p)^0=p$ и $f(0)=p^0(1-p)^1=1-p$.

Из формулы \eqref{GrindEQ__14_3_} следует формула для логарифма вероятности $\ln f(y_i)=y_i \ln p_i +(1-y_i) \ln (1-p_i)$. С учетом независимости по $i$ и модели \eqref{GrindEQ__14_1_} для $p_i$ логарифмическая функция правдоподобия принимает вид

\begin{equation} 
\label{GrindEQ__14_4_}
 \mathcal{L}_N (\beta)=\sum^N_{i=1} \{ y_i \ln F(x'_i\beta)+ (1-y_i) \ln (1-F(x'_i\beta)) \}.
 \end{equation} 

Продифференцировав по $\beta$,  получаем,  что \textbf{оценка} параметра $\widehat\beta_{ML}$,  полученная \textbf{методом максимального правдоподобия}, является решением уравнения

\[
\sum^N_{i=1} \{ \frac{y_i}{F_i} F'_i x_i - \frac{1-y_i}{1-F_i} F'_ix_i \} =0, 
\] 
где $F_i=F(x'_i\beta)$, $F'_i=F'(x'_i\beta)$,  а $F'(z)=\partial F(z)/\partial z$. Приведя выражение в скобках к общему знаменателю $F_i(1-F_i)$ и упростив результат, получим условие первого порядка максимизации функции правдоподобия

\begin{equation} 
\label{GrindEQ__14_5_} 
\sum^N_{i=1} \frac{y_i-F(x'_i\beta)}{F(x'_i\beta)(1-F(x'_i\beta))}F'(x'_i\beta)x_i=0. 
\end{equation} 
Явного решения этого уравнения в общем случае не существует.  Однако метод Ньютона-Рафсона очень быстро сходится к $\widehat\beta_{MLE}$, по крайней мере для логит и пробит-моделей,  поскольку для них функция правдоподобия вогнута на все области определения.

\subsubsection*{Состоятельность метода максимального правдоподобия}

Оценка, полученная методом максимального правдоподобия, \textbf{состоятельна},  если функция условного распределения $y$ при данном $x$ задана верно. Поскольку в данном случае используется распределение Бернулли,  то единственная возможная ошибка может быть в неверном задании формулы для вероятности. Таким образом,  метод максимального правдоподобия состоятелен,  если $p_i \equiv F(x'_i\beta)$,  и не состоятелен в противном случае.

Более формально,  заметим,  что для бинарных данных $\E[y]=1\times p+0\times (1-p)=p$. Поэтому из уравнения \eqref{GrindEQ__14_1_} следует,  что 

\begin{equation} 
\label{GrindEQ__14_6_} 
\E[y_i|x_i]=F(x'_i\beta). 
\end{equation} 

Это в свою очередь означает,  что ожидаемое значение левой части уравнения \eqref{GrindEQ__14_5_}  равно нулю, что есть основное  условие состоятельности. Данное особое условие состоятельности выполнено для распределений экспоненциального семейства, при условии правильно специфицированного среднего, см. параграф 5.7.3.  Распределение Бернулли принадлежит к экспоненциальному семейству.

\subsubsection*{Распределение ММП оценки}

В случае правильной спецификации  распределения,  $\widehat\beta_{ML} \overset{a}{\sim} \mathcal{N}[\beta,  \left(-\E[\partial^2 \mathcal{L}_N /\partial \beta \partial \beta' ]\right)^{-1}]$ (см. параграф 5.6.4). Продифференцировав выражение \eqref{GrindEQ__14_4_} по $\beta'$ и взяв с минусом ожидаемое значение,  получаем ожидаемую \textbf{асимптотическую ковариационная матрицу}

\begin{equation} 
\label{GrindEQ__14_7_} 
\hat{\V} \left[ \widehat\beta_{ML} \right] = \left( \sum^N_{i=1} \frac{1}{F(x'_i \widehat\beta) (1-F(x'_i \widehat\beta))} F'(x'_i\widehat\beta)^2 x_i x'_i\right)^{-1},  
\end{equation} 
выражение упрощается, поскольку $\E[y_i-F(x'_i\beta)]=0$. Ковариационная матрица имеет простую форму $(\sum_i \hat{w}_i x_i x'_i)^{-1}$,  где веса $\hat{w}_i$ приведены в выражении \eqref{GrindEQ__14_7_}.

Поскольку для состоятельности метода достаточно только правильной спецификации условного среднего или функции вероятности,  будет естественным рассмотреть метод квази-максимального правдоподобия (см. раздел 5.7) и строить выводы на сэндвич-форме ковариационной матрицы $A^{-1}BA^{-1}$, а не на матрице $-A^{-1}$,  используемой в выражении \eqref{GrindEQ__14_7_}. Здесь

\begin{equation} 
\label{GrindEQ__14_8_} 
\V [y_i| x_i]= F(x'_i\beta)(1-F(x'_i\beta)),  
\end{equation} 
т.к. $\V[y]=(1-p)^2 \times p + (0-p)^2 \times (1-p) = p(1-p)$. После некоторых алгебраических операций получаем,  что $A=-B$, и,  следовательно,  $A^{-1}BA^{-1}=-A^{-1}$,  при независимости по $i$. Единственный случай,  когда равенство \eqref{GrindEQ__14_8_} не соблюдается,  это $p\ne F(x'\beta)$. В этом случае метод максимального правдоподобия будет страдать от более фундаментальной проблемы несостоятельности.

Модели бинарного выбора необычны тем,  что нет никаких преимуществ от использования сэндвич формы матрицы,  если данные независимы по $i$. Единственная причина, из-за которой нужно использовать робастную  форму ковариационной матрицы, --- это наличие корреляции между наблюдениями в результате кластеризации. Тогда робастная оценка должна  быть устойчива к кластеризации (см. раздел 24.5), а не к неправильной спецификацией условной дисперсии.

\subsection{логит-модель}

\textbf{логит-модель} или \textbf{логистическая регрессионная модель} задает

\begin{equation} 
\label{GrindEQ__14_9_} 
p=\Lambda \left(x'\beta \right)=\frac{e^{x'\beta }}{1+e^{x'\beta }},  
\end{equation} 
где $\Lambda (\cdot)$ --- логистическая функция распределения (см. раздел 14.4.1 для более подробной информации) с $\Lambda \left(z\right)={e^z}/{\left(1+e^z\right)={1}/{(1+e^{-z})}}.$

Условие первого порядка максимизации функции правдоподобия для логит-модели упрощается до

\begin{equation} 
\label{GrindEQ__14_10_} 
\sum^N_{i=1} (y_i-\Lambda (x'_i\beta))x_i=0,  
\end{equation} 
поскольку $\Lambda'(z)=\Lambda (z)[1-\Lambda (z)]$.
Тогда простые остатки $y_i-\Lambda (x'_i\beta)$ ортогональны  вектору независимых переменных,  как и в модели линейной регрессии. Такое простое условие возникает поскольку $\Lambda (\cdot)$ --- каноническая функция связи для распределения Бернулли (см. параграф 5.7.4).

Если среди независимых переменных $x_i$ присутствует константа,  то \eqref{GrindEQ__14_10_} приводит к тому, что $\sum_i(y_i- \Lambda (x'_i\widehat\beta))=0$. Таким образом,  сумма остатков в логит-модели равна нулю. Это подразумевает,  что средняя предсказанная вероятность внутри выборки $N^{-1}\sum_i \Lambda (x'_i\widehat\beta)$ обязательно равняется выборочной доле $\overline{y}$. 

\textbf{Предельный эффект} для логит-модели может быть достаточно легко получен, когда известны коэффициенты,  поскольку $\partial p_i/\partial x_{ij}=p_i\left(1-p_i\right)\beta_j$, где $p_i=\Lambda_i=\Lambda (x'_i\beta)$. 
Подставив $p_i=\overline{y}$,  получаем грубую оценку предельного эффекта --- $(1-\overline{y})\widehat\beta_j$. 
Для $0.3<p_i<0.7$, например,  значение $\partial p_i/\partial x_{ij}$ лежит между $0.21\beta_j$ и $0.25\beta_j$. В случае данных,  для которых $p_i\simeq 0,0$, то есть когда большинство исходов равно нулю,  $\partial p_i/\partial x_{ij} = p_i \beta_j$. Тогда $\beta_j$ пропорционально влияет на вероятность того,  что $y_i=1$ при изменяющемся $x_{ij}$.

В литературе по статистике более распространена интерпретация коэффициентов в терминах предельных эффектов на отношение шансов (odds ratio), а не на вероятность. Для логит-модели 

\[
p=
\exp(x'\beta )/(1+\exp(x'\beta ))
\] 

\begin{equation} 
\label{GrindEQ__14_11_} 
\Longrightarrow \frac{p}{1-p}=\exp(x'\beta ) 
\end{equation} 

\[
\Longrightarrow \ln  \frac{p}{1-p}=x'\beta.
\] 
Здесь $1/\left(1-p\right)$ определяет отношение вероятности того,  что $y=1$ к вероятности того,  что $y=0$ и называется \textbf{отношением шансов} или  \textbf{относительным риском}. Например,  рассмотрим испытание фармацевтического средства,  для которого $y=1$ означает количество выживших,  а $y=0$ означает количество смертельных случаев. Независимые переменные включают дозировку препарата. Значение отношения шансов,  равное 2,  означает,  что вероятность  выживания превосходит вероятность смертельного случая в два раза. Для логит-модели \textbf{логарифм отношения шансов} линеен по независимой переменной.

В статистическом анализе и статистических пакетах используется второе равенство из \eqref{GrindEQ__14_11_}. Предположим,  $j$-ый регрессор увеличивается на одну единицу. Тогда $\exp(x'\beta )$ увеличивается до $\exp  (x'\beta +\beta_j)=\exp(x'\beta) \times \exp(\beta_j)$. Из \eqref{GrindEQ__14_11_} следует,  что отношение шансов возрастает в $\exp (\beta_j)$ раз. Таким образом,  коэффициент при независимой переменной в логит-модели равный,  например,  0,1 означает,  что увеличение независимой переменной на одну единицу увеличит величину отношения шансов в $\exp(0.1) \simeq 1.105$ раз. По-другому можно сказать, что отношение шансов увеличивается на долю 0.105, или что \textbf{относительная} вероятность выживания увеличивается на 10.5\%. Такая интерпретация логит-модели широко используется в приложениях к биостатистике.

Для экономистов более естественно интерпретировать второе или третье равенство из \eqref{GrindEQ__14_11_},  подразумевая,  что $\beta_j$ --- это \textbf{полуэластичность}. Тогда,  применив производную,  будем интерпретировать коэффициент при независимой переменной в логит-модели  равный 0,1,  таким образом:  увеличение регрессора на одну единицу увеличивает отношение шансов на долю 0,1. Это в точности совпадает с интерпретацией,  используемой в статистике для очень малых $\beta_j$, т.к. $\exp (\beta_j)-1 \simeq \beta_j$.

\subsection{пробит-модель}

В \textbf{пробит-модели} условная вероятность задается как 

\begin{equation} 
\label{GrindEQ__14_12_} 
p=\Phi (x'\beta) =\int^{x'\beta}_{-\infty} \phi(z)dz,
\end{equation} 
где $\Phi (\cdot)$ --- функция распределения стандартной нормальной величины с производной $\phi (z)=(1/\sqrt{2\pi})\exp (-z^2/2)$, которая является функцией плотности стандартного нормального распределения.

Условие первого порядка максимизации функции правдоподобия для пробит-модели следующее 

\[
\sum^N_{i=1} w_i (y_i-x'_i\beta)x_i=0, 
\] 
где, в отличие от логит-модели,  веса $w_i=\phi (x'_i\beta)/[\Phi (x'_i\beta)(1-\Phi (x'_i\beta))]$ варьируются в зависимости от наблюдений. Предельные эффекты в пробит-модели --- $\partial p_i/ \partial x_{ij}=\phi (x'_i\beta)\beta_j=\phi (\Phi^{-1}(p_i))\beta_j$, где $p_i=\Phi (x'_i\beta)$. 
Дальнейших упрощений как в логит-модели не последует, тем не менее, $\partial p_i/ \partial x_{ij} \le 0.40\beta_j$, поскольку $\phi(z) \le \phi (0)=1/\sqrt{2\pi}$. % здесь в английском оригинале ошибочно написано \phi(0.5)

пробит-модель не так проста как логит-модель. Несмотря на это,  она широко используется,  так как является естественной моделью,  если отправной точкой является  регрессионная модель с латентной нормально распределенной переменной (см. раздел 14.4).

\subsection{Линейная регрессионная модель}

Простой альтернативой для логит и пробит-моделей является \textbf{линейная регрессионная модель }зависимости переменной $y$ от переменной $x$. Эта модель имеет очевидный недостаток,  поскольку возможно получить значения предсказываемой вероятности $x'_i\widehat\beta$, которые будут отрицательны или превышать единицу.

Тем не менее,  МНК оценка полезна как исследовательский инструмент. На практике она обеспечивает разумную прямую оценку средних по выборке предельных эффектов изменения $x$ на вероятность события $y=1$, даже если является плохой моделью для оценки индивидуальных вероятностей. На практике эта оценка позволяет хорошо определять, какие из переменных являются статистически значимыми. Во многих случаях получается,  что $0<x'_i\widehat\beta<1$ для всех наблюдений, в этом случае использование линейной регрессии более разумно.

Если используется МНК оценка,  то оценки стандартных ошибок должны быть скорректированы на  \textbf{гетероскедастичность}. Линейная регрессия оправдана,  если вероятность $p_i=x'_i\beta$. Тогда $y_i|x_i$ имеет среднее $x'_i\beta $ и гетероскедастичную дисперсию $x'_i\beta (1-x'_i\beta)$,  которая изменяется вместе с $x_i$.

В теории возможно использование более эффективного метода максимального правдоподобия,  если $p_i=x'_i\beta$. Из \eqref{GrindEQ__14_5_} условие первого порядка максимизации функции правдоподобия --- $\sum_i x_i(y_i-x'_i\beta )/[x'_i\beta (1-x'_i\beta)]=0$. Эта оценка может быть численно неустойчивой,  поскольку большое значение придается наблюдениям со значением $x'_i\beta$,  близким к 0 или 1. Более того,  повышение эффективности по сравнению с МНК часто незначительны.

И, хотя, МНК-оценки с гетероскедастичными стандартными ошибками могут служить полезным инструментом анализа данных,  для окончательного анализа данных гораздо лучше использовать оценки,  полученные методом максимального правдоподобия,  в логит и пробит-моделях.

\subsection{Выбор бинарной модели}

Какую из моделей лучше выбрать -- логит или пробит-модель? Этот вопрос исследуется в настоящем параграфе.

\subsubsection*{Теоретические соображения}

Теоретически ответ на этот вопрос зависит от процесса, порождающего данные,  который неизвестен. В отличие от других приложений метода максимального правдоподобия здесь отсутствует проблема определения типа распределения --- единственно возможным распределением для переменной со значениями (0, 1) является распределение Бернулли. Основная сложность заключается в определении функциональной формы модели для параметров распределения. Если в процессе, порождающем данные, вероятность наступления события $p=\Lambda (x'\beta )$,  то следует использовать логит-модель,  а оценки,  основанные на других моделях,  таких как пробит-модель,  являются потенциально несостоятельными. Аналогичное качественное заключение следует сделать,  если в процессе, порождающем данные, вероятность наступления события $p=\Phi (x'\beta )$. В этом случае следует использовать пробит-модель. Очень маловероятно,  что $p=x'\beta $,  поскольку тогда вероятность  $p$ может принимать значения за пределами интервала от 0 до 1.

Теоретические последствия ошибки при определении спецификации модели,  однако,  не так велики как следующая трудность. Допустим, что регрессоры распределены таким образом,  что среднее каждого регрессора,  при фиксированной линейной комбинацией $x'\beta $,  линейно по $x'\beta $.  В этом случае  может быть показано,  что  выбор неправильной функции $F$ одинаково повлияет на все оценки параметра при независимых переменных.  Значит отношение параметров при независимых переменных будет постоянным для всех моделей, см. работу Рууда (1983). Этому условию удовлетворяет семейство сферических распределений,  включая и многомерное нормальное распределение.

логит-модель имеет относительно более простую форму условий первого порядка и асимптотического распределения. Популяризатор логит-модели Берксон  (1951)  считает это одной из причин, почему логит-модель предпочтительнее  пробит-модели. Среди  общих линейных моделей,  которые широко используются в биостатистике,  логит-модель является естественной моделью,  поскольку она соответствует использованию канонической связи для биномиального распределения. Также преимуществом логит-модели выступает интерпретация коэффициентов модели в терминах логарифма отношения шансов.

Еще одной мотивацией для логит-модели является \textbf{дискриминантный анализ}. С точки зрения дискриминантного анализа обе переменные $y$ и $x$ являются случайными. Переменная $x$ наблюдаемая,  а переменная $y$ --- ненаблюдаемая. При известном $x$,  необходимо определить принимает $y$ значение,  равное нулю или единице. Классическим примером является определение типа  гоминида ($y=0$ или $1$),  к которому принадлежит череп в зависимости от различных параметров черепа $(x)$. Если условное распределение характеристик $x$ для данного $y$ является многомерным нормальным,  то апостериорная  вероятность для $y$ при заданном $x$ будет аналогична вероятности в логит-модели. Для дополнительной информации см. работы Амэмии (1981,  стр. 1507 --- 1510) и Маддалы (1983,  стр.  17 --- 21).

С другой стороны, пробит-модель обосновывается нормальным распределением скрытой переменной. (см. раздел 14.4),  и естественным образом обобщается до тобит-модели (см. главу 16). Поэтому многие экономисты предпочитают использовать пробит-модель.

\subsubsection*{Эмпирические соображения}

С эмпирической точки зрения,  как логит,  так и пробит-модель могут быть использованы. Часто существует небольшая разница между вероятностями,  спрогнозированными с помощью логит и пробит-модели. Наибольшая разница получается для остатков,  для которых вероятности близки к 0 или 1. Разница получается намного меньше,  если наибольший интерес устремлен к средним по выборке предельным эффектам,  чем к индивидуальным показателям.

Общепринято считаемой корректной, естественной метрикой для сравнения моделей для вероятности $p_i$ является значение логарифмической функции правдоподобия,  т.к. логит и пробит-модели имеют одинаковое количество параметров. Таким образом,  для каждой модели можно посчитать 

\[
\mathcal{L}_n (\widehat\beta)=\sum_i \{y_i \ln \hat{p}_i+(1-y_i) \ln (1-\hat{p}_i) \}, 
\] 
где $\hat{p}_i=\Lambda (x'_i \widehat\beta_{Logit})$ или $\hat{p}_i=\Phi (x'_i\widehat\beta_{Probit})$. Часто значения логарифмической функции правдоподобия очень похожи для двух  моделей,  что снова говорит о незначительном преимуществе  одной модели по сравнению с другой. Для более подробного знакомства с формальными тестами для  невложенных моделей см. работу Песарана и Песарана (1995) и раздел 8.5.

Различные модели дают довольно различные оценки параметров регрессии $\widehat\beta$. Тем не менее,  это всего лишь следствие использования разных формул для вероятностей. Более осмысленным является сравнение предельных эффектов в разных моделях,  поскольку эти величины имеют одинаковый масштаб в рассматриваемых моделях. Из раздела 14.2.3 получаем что  $\partial p/\partial x_j \le 0.25 \widehat\beta_j$ для логит-модели,  $\partial p/\partial x_j\le 0.4\widehat\beta_j$ для пробит-модели,  и $\partial p/\partial x_j \le \widehat\beta_j$ для линейной регрессии. Отсюда следует эмпирическое правило 

\begin{equation} 
\label{GrindEQ__14_13_} 
\widehat\beta_{Logit} \simeq 4 \widehat\beta_{OLS},  
\end{equation} 

\[
\widehat\beta_{Probit} \simeq 2.5 \widehat\beta_{OLS}, 
\] 

\[
\widehat\beta_{Logit} \simeq 1.6 \widehat\beta_{Probit}.
\] 
В своей работе Амэмия (1981,  стр. 1488) продемонстрировал,  что эти неравенства для параметров наклона хорошо работают,  если $0.1 \le p \le 0.9$. Большие отличия моделей наблюдаются в хвостах распределения. Альтернативный метод для логит-модели,  основанный на данном далее \eqref{GrindEQ__14_18_} приводит к $\widehat\beta_{Logit} \simeq (\pi/\sqrt{3}) \widehat\beta_{Probit}$.

\subsubsection*{Эндогенные регрессоры}

Логит и пробит-модели могут быть обобщены на случай многих затруднений,  которые обычно возникают в микроэкономическом анализе. В частности,  эндогенные регрессоры могут быть учтены с помощью  методов,  аналогичных представленным для цензурированных данных в параграфе 16.8.2,  и для панельных данных в главе 23.

Из-за таких сложностей проще работать с линейными вероятностными моделями, так как стандартную линейную модель  можно применять при условии, что стандартные ошибки имеют поправку на гетероскедастичность. Даже если логит и пробит-модели используются в конечном счете, линейная модель может быть использована для того, чтобы провести интерпретационный анализ.

\subsection{Определение адекватности модели}

Методы диагностики и выбора нелинейных моделей были представлены в разделе 8.7. Здесь мы рассмотрим применение этих методов к моделям бинарного выбора. Не существует единственного универсального критерия  качества модели,  поэтому статистические пакеты предлагают несколько критериев,  подробно описанных в работах Амэмии  (1981)  и Маддалы (1983).

\subsection*{Псевдо-$R^2$}

Стандартным критерием качества линейной регрессионной модели является $R^2$. Обобщение этого критерия на класс нелинейных моделей называется \textbf{псевдо-}$R^2$. Этот показатель может быть получен несколькими способами.

Предпочтительным является критерий относительного прироста, обозначенный в параграфе 8.7.1 как $R^2_{RG}$. Значение этого критерия не всегда можно посчитать,  но это не касается моделей бинарного выбора,  поскольку $Q_{max}$,  максимально возможное значение логарифмической функции максимального правдоподобия,  равно нулю. Для получения данного результата, заметим, что наилучшее соответствие модели данным наблюдается, если $y^*$  предсказывает значение $y=1$ с вероятностью $p=1$ и значение $y=0$ с вероятностью $1-p=0$. В таком случае $f(y^*)=1, $ а $\ln f(y^*)=0$. Тогда $R^2_{RG}=1-(0-Q_{fit})/(0-Q_0)=1-Q_{fit}/Q_0$. Мы получаем критерий $R^2$ для моделей бинарного выбора,  предложенный МакФадденом  (1974): 

\begin{equation} 
\label{GrindEQ__14_14_} 
R^2_{Binary} = 1 - \frac{\mathcal{L}_N (\widehat\beta)}{\mathcal{L}_N (\overline{y})} = 1-\frac{\sum_i \{y_i \ln  \hat{p}_i+(1-y_i) \ln (1-\hat{p}_i) \}}{N[\overline{y} \ln \overline{y} + (1-\overline{y}) \ln  (1-\overline{y})]},  
\end{equation} 
где $\hat{p}_i=F(x'_i\widehat\beta)$ и $\overline{y}=N^{-1}\sum_i y_i.$

Другие $R^2$-подобные критерии,  часто специфичные для бинарных данных,  приведены в работах Амэмии  (1981)  и Маддалы  (1983). Одним из простых критериев является квадрат выборочной  корреляции между $y_i$ и $\hat{p}_i$. Один из этих дополнительных критериев был предложен в работе МакФаддена. Именно он,  а не $R^2$ по формуле \eqref{GrindEQ__14_14_}, часто приводится во многих исследованиях.

\subsubsection*{Предсказанные исходы}

Качество линейной регрессионной модели часто оценивается сравнением рассчитанных и реальных значений. Для бинарных данных спрогнозированная величина $\hat{y}$ должна быть бинарной,  поскольку исходная величина $y$ бинарна. Критерий $\sum_i (y_i - \hat{y}_i)^2$ равен количеству ошибочных прогнозов,  которые возникают,  если пара $(y,  \hat{y})$ принимает  значения $(1, 0)$ или $(0, 1)$. Естественным  правилом прогнозирования, будет правило присваивающее  $\hat{y}=1$,  если $\hat{p} = F(x'_i \widehat\beta) > 0.5$. Этот подход имеет недостаток,  поскольку,  если большинство исходов в выборке $y=1$,  то часто $\sum_i (y_i-\hat{y}_i)^2 = n(1-\overline{y})$. Тогда вполне вероятно,  что  $\hat{p} > 0.5$ и,  следовательно,  $\hat{y}=1$ для всех наблюдений. Эти же проблемы возникают,  если большинство исходов в выборке $y=0$.

Более того,  можно рассмотреть диапазон пороговых значений. Полагая $\hat{y}=1$  когда $\hat{p}>c$,  получим кривую \textbf{операционной характеристики приемника} (ROC-кривая),  которая отображает зависимость доли правильно классифицированных значений $y=1$ от доли неправильно классифицированных значений $y=0$ с изменением $c$. Для $c=1$ все прогнозные значения будут равны 0. Таким образом,  все значения  $y=1$ определены некорректно,  а все значения $y=0$ определены корректно. ROC-кривая принимает значение $(0, 0)$. Аналогично для $c=0$ ROC-кривая принимает значение $(1, 1).$

Если у модели нет предсказательной силы, то кривая ROC имеет вид прямой линии. Чем более выпукла кривая ROC, чем больше площади под ней, тем большей прогнозной силой обладает модель.

\subsubsection*{Прогнозируемые вероятности}

Поскольку бинарные данные имеют простое дискретное распределение,  можно, например, сравнить среднюю по выборке предсказанную вероятность  $y=1$, т.е. $N^{-1}\sum_i \hat{p}_i$,  где $\hat{p}_i = F(x'_i \widehat\beta)$,  с выборочной долей $\overline{y}$. Тем не менее,  этот подход непригоден для логит-модели с константой,  поскольку равенство $N^{-1}\sum_i \hat{p}_i=\overline{y}$ всегда выполняется, т.к.  условие первого порядка  ММП приводят к тому, что $\sum_i [y_i-\Lambda (x'_i\widehat\beta)]=0.$ Аналогичный результат верен и для модели линейной регрессии. Для пробит-модели результат будет несколько отличаться,  но на практике будет достаточно близким.

Тем не менее,  такой подход может быть использован для прогнозов по подвыборкам,  и,  быть  основой для построения хи-квадрат критерия качества модели,  приведенного в параграфе 8.2.6.

\section{Модели скрытых переменных}

\textbf{Скрытая переменная} --- это переменная,  которая наблюдается лишь частично. Скрытые переменные могут быть введены в модели бинарного выбора двумя различными способами. В первом случае скрытая переменная --- это индекс ненаблюдаемой склонности интересующего нас события к тому, что оно произойдет. Во втором случае скрытая переменная --- это разница в получаемой полезности,  если происходит желаемое событие. Этот случай предполагает,  что бинарный исход является результатом индивидуального выбора. Последний метод проясняет необходимость провести различие между регрессорами,  которые варьируются в зависимости от альтернатив для конкретного индивида,  и регрессорами,  такими как социально-экономические показатели,  которые постоянны для  конкретного индивида независимо от альтернатив.

Следует подчеркнуть,  что бинарные исходы имеют распределение Бернулли,  как  в разделе 14.3. Модели скрытых переменных просто дают обоснование для конкретной функциональной формы для параметра распределения Бернулли.

Модели скрытых переменных  обеспечивают обобщение моделей для случаев мультиномиальных или цензурированных исходов (подробнее см. в главах 15 и 16). Они также обеспечивают базу для Байесовского анализа с использованием метода пополнения данных (data augmentation), см. раздел 13.7. Байесовский анализ для случая данных бинарного и мультиномиального исходов кратко рассмотрен в параграфах 15.7.2 и 15.8.2.

\subsection{Индексная модель}

В формулировке с \textbf{индексной функцией} мы моделируем ненаблюдаемую непрерывную случайную переменной $y^*$,  при этом мы можем наблюдать бинарную переменную $y$,  которая принимает значение 1 или 0 в зависимости от того,  пересекает ли переменная $y^*$ заданный порог или нет. Различные предположения в отношении распределения переменной $y^*$ приводят к различным моделям бинарного выбора.

Пусть переменная $y^*$ является скрытой (или ненаблюдаемой),  например,  желание трудоустроиться при моделировании предложения труда. Естественной регрессионной моделью для переменной $y^*$ будет \textbf{индексная функциональная модель} 

\begin{equation} 
\label{GrindEQ__14_15_} y^*=x'\beta + u. 
\end{equation} 
Тем не менее,  эта модель не может быть оценена,  поскольку $y^*$ не наблюдаема. Вместо этого,  мы наблюдаем 

\begin{equation} 
\label{GrindEQ__14_16_} 
y = \begin{cases}
1  \ \text{если } y^*>0,  \\ 
0  \ \text{если } y^*\le 0,  
\end{cases} 
\end{equation}
где ноль в качестве граничного значения объясняется следующей нормализацией.

Из \eqref{GrindEQ__14_16_} следует, что

\begin{equation} 
\label{GrindEQ__14_17_} 
\Pr[y=1|x] = \Pr[y^* > 0] = \Pr[x'\beta + u > 0] = \Pr[-u < x'\beta] = F(x'\beta),  
\end{equation} 
где $F$ --- функция распределения $-u$,  которая равна функции распределения $u$, если плотность симметрична относительно нуля.

Индексная модель,  следовательно,  аргументирует использование функциональной формы $F(\cdot)$ в выражении \eqref{GrindEQ__14_1_}.

\subsubsection*{Пробит и логит-модели}

пробит-модель возникает,  если ошибка $u$ имеет нормальное стандартное распределение,  поскольку тогда из \eqref{GrindEQ__14_17_} следует, что  $\Pr[-u < x'\beta] = \Phi(x'\beta)$, где $\Phi(\cdot)$ --- функция стандартного нормального распределения.

Теперь рассмотрим \textbf{логистическое распределение}. В стандартной форме функция логистического распределения имеет следующий вид 

\begin{equation} 
\label{GrindEQ__14_18_} 
\Lambda(u) = e^u /(1+e^u), \, -\infty < u < \infty. 
\end{equation} 
Функция плотности $\Lambda'(u) = e^u/(1 + e^u)^2$ симметрична относительно 0. Для случайной переменной,  распределенной логистически,  среднее значение  равно 0,  а дисперсия --- $\pi^2/3\simeq {1,814}^2$.

логит-модель применяется,  если ошибка $u$ имеет логистическое распределение,  поскольку тогда из \eqref{GrindEQ__14_17_} следует $\Pr[-u < x'\beta] = \Lambda (x'\beta)$. Обратите внимание,  что $\beta$ рассчитывается по-разному в этих моделях,  поскольку разный вид имеет функция $\V[u].$ 

\subsubsection*{Соображения по поводу идентификации модели}

\textbf{Идентификация} одноиндексной модели требует наложения ограничения на дисперсию $u$, поскольку одноиндексная модель может оценить $\beta$ только с точностью до домножения на константу. Мы наблюдаем знаем только тот факт, принимает ли переменная $y^*$ значение больше нуля или нет,  или,  что эквивалентно,  выполнено ли неравенство $x'\beta +u>0$ или нет. Однако,  это эквивалентно неравенству $x'\beta^++u^+>0$, где $\beta^+=a\beta $ и $u^+=au$ для любых $a>0.$ Задавая условие на  дисперсию ошибок ($u$ или $u^+$) мы получаем уникальные  $\beta$. Дисперсия ошибки постулируется равной единицы для пробит-модели и $\pi^2/3$ для логит-модели.

Пороговое значение для индексной модели не обязательно должно быть равно нулю. В более общем случае, если  $y=1$, когда $y^*>z'\delta $,  то \eqref{GrindEQ__14_17_} принимает вид $\Pr[y=1] =F(x'\beta -z'\delta)$. Тогда $\delta $ может быть идентифицировано тогда и только тогда,  когда все компоненты $z$ и $x$ различаются. В частности,  если и $x$,  и $z$ содержат константу,  $\delta$ не может быть идентифицировано. В этом случае мы нормируем пороговое значение, приравнивая его к нулю. Обратите внимание,  что математическое ожидание ошибки также необходимо нормировать. Для логит и пробит-моделей это значение установлено равным нулю. 

\subsubsection*{Обсуждение}

Индексная модель подразумевает непосредственную интерпретацию $\beta$ как изменения в скрытой переменной $y^*$,  когда переменная $x$ изменяется на единицу. Несмотря на то,  что переменная $y^*$ ненаблюдаема,  такая интерпретация имеет смысл при фиксированной  дисперсии  ошибки $u$. Например,  параметр при независимой переменной в пробит-модели,  равный 0.5,  означает,  что изменение регрессора на одну единицу,  приведет к изменению стандартного отклонения $y^*$ на 0.5,  поскольку значение дисперсии $y^*$ в этой модели равно 1.

\textbf{Обобщения} индексного подхода включают в себя модели упорядоченного дискретного выбора (см. раздел 15.9) и модели для цензурирования и самоотбора выборки (см. главу 16). 

\subsection{Модели случайной полезности}

В моделях случайной полезности потребитель выбирает между альтернативами 0 и 1 в зависимости от того,  какая из них принесет ему большее удовлетворение или полезность. Дискретная переменная $y$ принимает значение 1,  если альтернатива 1 принесет большую полезность,  либо принимает значение 0,  если альтернатива 0 принесет большую полезность.

В \textbf{аддитивной модели случайной полезности} (additive random utility model, ARUM) полезности альтернатив 0 и 1 задаются следующим образом 

\begin{equation} 
\label{GrindEQ__14_19_} 
U_0 = V_0 + \e_0,  
\end{equation} 

\[
U_1 = V_1 + \e_1, 
\] 
где $V_0$ и $V_1$ являются детерминированными компонентами полезности,  а $\e_0$  и $\e_1$ --- случайными компонентами полезности. В качестве простого примера можно привести $V_0 = x'\beta_0$  и $V_1 = x'\beta_1$. Из раздела 14.4.3 следует, что тогда только величина $(\beta_1-\beta_0)$ является идентифицируемой.

Выбор делается в пользу альтернативы,  полезность которой больше. Допустим,  $y=1$ наблюдается,  если $U_1>U_0$. Благодаря наличию в полезности случайной компоненты,  это событие имеет вероятность  

\begin{equation}
\label{GrindEQ__14_20_} 
\begin{split}
\Pr[y=1] = \Pr[U_1 > U_0] \\
&= \Pr[V_1+\e_1 > V_0 + \e_0] \\
&= \Pr[\e_0 - \e_1 < V_1 - V_0] \\
&= F(V_1 - V_0),
\end{split}
\end{equation}
где $F$ функция распределения величины $(\e_0 - \e_1)$. Отсюда следует,  что $\Pr[y=1] = F(x'\beta)$, если $V_1 - V_0 = x'\beta$.

Применение модели ARUM требует нормирования, поскольку если $U_1 > U_0$, то $aU_1 > aU_0$. Это обычно обеспечивается определением дисперсии величины $\e_0 - \e_1$ или дисперсий величин $\e_0$ и $\e_1$.

Различные определения распределений величин $\e_0$ и $\e_1$ приводят к  различным $F(\cdot)$,  и,  следовательно,  различным моделям дискретного выбора. Модели случайной полезности особенно полезны при определении моделей неупорядоченного множественного выбора.

\subsubsection*{Пробит и логит-модели}

Вполне ясно,  что ошибки $\e_0$ и $\e_1$ из \eqref{GrindEQ__14_19_} имеют нормальное распределение. Тогда величина $(\e_0 - \e_1)$ также имеет нормальное распределение. Нормирование дисперсии величины $(\e_0 - \e_1)$ к единице приводит к пробит-модели,  поскольку тогда $F(\cdot)$ из выражения \eqref{GrindEQ__14_20_} --- функция стандартного нормального распределения.

Теперь рассмотрим \textbf{распределение экстремальных значений первого типа} или \textbf{ логарифмическое распределение Вейбулла}. Тогда плотность распределения переменной $\e$ задается как  

\begin{equation} 
\label{GrindEQ__14_21_} 
f(\e) = e^{-\e} \exp (-e^{-\e}), -\infty < \e <\infty,   
\end{equation} 
а функция распределения --- $F(\e) = \exp (-e^{-\e})$. Распределения экстремальных значений, редко используемые в эконометрике,  получаются как предел  при $N\to \infty $ распределения максимума из $N$ одинаково распределенных случайных величин. Распределение экстремальных величин первого типа -- это частный случай,  для которого коэффициент асимметрии положителен на $(-\infty, \infty)$ и основная масса значений находится между $-2$ и 5. Медиана этого распределения равна $-\ln (-\ln(0.5)) \simeq 0.36651$, среднее --- $\Gamma'(1)\simeq 0.57722$,  где $\Gamma'(x)$ обозначает производную гамма-функции,  и дисперсия $\pi^6/6 \simeq 1.28255^2$. Это распределение хорошо приближается лог-нормальным распределением.

логит-модель возникает,  если величины $\e_0$ и $\e_1$ полагаются независимыми и имеют распределение экстремальных величин первого типа. Тогда можно показать,  что разница $(\e_0 - \e_1)$ распределена логистически (см. работу Джонсона и Котца, 1970),  тогда $F(\cdot)$ --- функция логистического распределения.

Альтернативный вывод этого результата,  полученный при непосредственном применении распределения экстремальных величин,  приведен в разделе 14.8. Этот вывод указывает на сложность получения аналитического решения для вероятностей,  когда модель ARUM обобщается на случай выбора между тремя и более альтернативами (см. раздел 15.5). Современные вычислительные методы позволяют оценивать такие модели даже при отсутствии явных аналитических решений.

\subsection{Регрессоры,  изменяющиеся в зависимости от выбранной альтернативы}

В большинстве приложений моделей бинарного выбора некоторые регрессоры варьируются в зависимости от индивидов,  но не обязательно,  чтобы регрессоры варьировались в зависимости от альтернатив.

Одна крайность заключается в том,  что регрессоры не изменяются в зависимости от альтернатив. Например,  в моделях предложения труда (решение работать) социально-экономические факторы такие,  как доход и пол не изменяются в зависимости от альтернатив. Возможный регрессор,  такой как ставка заработной платы,  не изменяется в зависимости от выбора альтернативы работать или не работать,  но этот регрессор обычно не включается в модель,  поскольку он наблюдаем только среди тех,  кто решил работать.

Другая крайность состоит в том,  что все регрессоры могут меняться в зависимости от альтернативы. Например,  в модели выбора способа транспортировки регрессорами могут выступать затраты времени и денег в двух моделях транспортировки.

Общая гибридная модель ARUM определяет детерминированные компоненты полезности в выражении \eqref{GrindEQ__14_19_} как  

\begin{equation} 
\label{GrindEQ__14_22_} 
V_{ij} = z'_{ij} \alpha_j + w'_i\gamma_j, \hspace{0.3cm} j=0, 1,  
\end{equation} 
где $z_{ij}$ --- независимые переменные,  которые принимают разные значения в зависимости от выбранной альтернативы,  тогда как $w_i$ --- индивидуальные характеристики,  которые не изменяются в зависимости от сделанного выбора. Тогда из \eqref{GrindEQ__14_20_} получаем 

\[
\Pr[y_i=1] = F(z'_{i1} \alpha_1 - z'_{i0} \alpha_0 + w'_i(\gamma_1 - \gamma_0)).
\] 
Для \textbf{регрессоров,  постоянных для альтернатив},  только разница параметров $(\gamma_1 - \gamma_0)$ может быть определена. Для \textbf{регрессоров,  изменяющихся в зависимости от альтернатив}, которые изменяются также в зависимости от индивида,  коэффициенты могут изменяться в зависимости от альтернатив,  но обычно их считают, что $\alpha_1 = \alpha_0 = \alpha$. Например,  ожидается,  что потери в полезности при увеличении транспортных расходов на одну единицу скорее всего будут одинаковыми независимо от способа транспортировки. Таким образом, модель ARUM приводит к выражению

\begin{equation} 
\label{GrindEQ__14_23_} 
\Pr[y_i = 1] = F((z_{i1} - z_{i0})'\alpha + w'_i(\gamma_1 - \gamma_0)),  
\end{equation} 
которое является начальной моделью бинарного выбора \eqref{GrindEQ__14_1_},  где регрессорами являются: регрессоры $w$, не зависящие от альтернатив, и разницы регрессорами $z$, зависящих от альтернатив, $(z_{i1}-z_{i0})$. 

\section{ Выборки с самоотбором}

\textbf{Самоотбор выборки} возникает всякий раз,  когда данные в выборку попадают в зависимости от значений объясняемой  переменной $y$,  а не абсолютно случайно,  или частично детерминировано значениями,  которые принимает независимая переменная $x.$

В модели дискретных данных часто возникает самоотбор выборки,  поскольку при проведении опросов  часто сознательно отбирают случаи,  которые в реальности случаются редко. Например,  автобусом может пользоваться малое количество людей, а в выборке может оказаться  излишнее количество пассажиров автобусов. В медицинской литературе аналогичная проблема возникает при использовании \textbf{метода случай-контроль},  когда,  например,  бинарный анализ данных может быть основан на полной выборке тех,  у кого случился сердечный приступ,  и подвыборке тех людей,  у которых наблюдались аналогичные симптомы,  но не случился сердечный приступ. Стандартный термин --- отбор при построении выборки (choice based sampling) --- может ввести в некоторое заблуждение,  поскольку выборка строится не на основе индивидуального выбора испытуемых.

Чтобы увидеть несостоятельность стандартных методов бинарного выбора,  рассмотрим логит-модель с одной независимой переменной. Тогда $\Lambda (x'_i \beta) = \Lambda (\beta)$,  а условие первого порядка максимизации функции правдоподобия логит-модели примет вид $N^{-1}\sum_i (y_i-\Lambda (\beta)) = 0. $ Таким образом,  $\widehat\beta = \ln (\overline{y} / (1-\overline{y}))$. Состоятельность оценки $\widehat\beta$ определенно требует,  чтобы выборка была случайной,  поскольку,  например, излишнее предпочтение исхода $y=1$ приводит к неправильной оценке $\overline{y}$, и,  следовательно,  $\widehat\beta.$

Методы достижения состоятельности оценок модели для эндогенной выборки,  возникающей, например, при отборе при построении выборки,  подробно изложены в разделе 24.4. Анализ является довольно прост,  если известна степень завышения или занижения доли исходов в выборке. Допустим,  $Q_1$ обозначает долю населения,  для которой $y=1$,  и $H_1 = \overline{y}$ обозначает долю выборки,  для которой $y=1.$ По аналогии определим $Q_0 = 1-Q_1$ и $H_0 = 1-H_1.$ Тогда состоятельное оценивание возможно при использовании \textbf{взвешенного метода максимального правдоподобия},  предложенного Мански и Лерманом  (1977). Для моделей бинарного выбора максимизируется взвешенная логарифмическая функция правдоподобия 

\[
\mathcal{L}^W_N (\beta) = \sum^N_{i=1} \left\{ \left(\frac{Q_1}{H_1}\right)y_i \ln F(x'_i\beta) + \left(\frac{Q_0}{H_0}\right) (1-y_i) \ln (1-F(x'_i\beta)) \right\}.
\] 
Например,  если доля исхода $y=1$ в выборке завышена,  тогда $Q_1/H_1 < 1$,  и излишние наблюдения с исходом $y=1$ взвешиваются с меньшим весом. Такая оценка может быть легко получена при использовании программ для моделей бинарного выбора,  которые позволяют взвешивать наблюдения. Тогда наблюдениям с исходом $y=1$ будет добавлен вес $Q_1/H_1$,  а  наблюдениям с исходом $y=0$, будет добавлен вес $Q_0/H_0.$

Подробный обзор   методов максимального правдоподобия в случаях отбора при построении выборки для бинарных и множественных данных,  включая методы,  когда неизвестны $Q_1$ и $Q_0$,  приведен в работе Амэмии (1985,  раздел 9.5). Взвешенный метод максимального правдоподобия не является эффективным,  однако прост в использовании,  и потеря в эффективности может быть незначительной. В работах Мански и МакФаддена (1981а) предлагается более эффективный метод (см. работы Амэмии и Вуонга,  1987). Косслетт (1981a, b) предлагает дальнейшее улучшение,  которое является полностью эффективным,  но непрактичным для реализации. В работах Имбенса  (1992)  и Ланкастера и Имбенса  (1996)  предлагается оценка обобщенным методом моментов как альтернативный метод,  который возможно реализовать и который является полностью эффективным. Кинг и Ценг  (2001)  приводят обзор для бинарной логит-модели. Дополнительно они предлагают поправки для малых выборок, которые,  помимо учета завышения выборочной доли исхода, полезны  в случае малой вероятности исхода. Для более подробной информации обратитесь к разделу 24.4.

Литература по эпидемиологии сосредотачивается на логит-модели для исследований с помощью метода случай-контроль. Этот метод приписывают Прентису и Пайку  (1979). Можно обратиться к работе Бреслоу  (1996),  особенно к её разделу 4.3,  где обсуждается связь между эконометрикой и литературой по эпидемиологии.

\section{ Группировка и агрегирование данных}

В некоторых случаях могут быть доступны только сгруппированные или агрегированные данные,  несмотря на это индивидуальное поведение лучше всего моделируется с помощью моделей бинарного выбора. Группировка данных не создает проблем,  когда она основана на уникальных значениях регрессоров,  а на каждое уникальное значение регрессора приходится много наблюдений.  Начнем с простого примера,  прежде чем перейти к более реалистичному.

\subsection{Метод Берксона минимизации хи-квадрат}

Предположим,  независимая переменная $x_i$, $i=1, \ldots, N$ принимает только $T$ уникальных значений,  где $T\ll N$. Тогда для каждого значения регрессора имеются множественные наблюдения $y$. Такая группировка называется \textbf{множеством наблюдений на одну точку}. Такая выборка может возникнуть,  в частности,  для экспериментальных данных,  когда $x$ имеет небольшую размерность и принимает лишь несколько значений. Пусть $x_t$,  $t=1, \ldots,  T$ --- это  $T$ уникальных значений. $N_t$ --- число наблюдений за $y_t$ для $t$-ого уникального значения $x$,  тогда $\sum^T_{t=1} N_t=N$, а $\overline{p}_t$ является долей наблюдений $y_i=1$ когда $x_i=x_t$. Обратите внимание,  что индекс $t$ используется,  чтобы обозначить группировку,  и необязательно обозначает время.

Для каждого $i$,  для которого $x_i=x_t$,  формула вероятности Бернулли принимает вид  

\begin{equation} 
\label{GrindEQ__14_24_} 
p_t= \Pr[y_i = 1| x_i = x_t] = F(x'_t\beta),  
\end{equation} 
как и раньше. Обратив выражение \eqref{GrindEQ__14_24_},  получим

\[
F^{-1}(p_t) = x'_t\beta.
\] 
Сейчас величина $p_t$ неизвестна,  но может быть оценена с помощью $\overline{p}_t$. Поэтому Берксон предложил построить регрессию $F^{-1}(\overline{p}_t)$ на $x_t$. Таким образом,  мы будем оценивать с помощью МНК преобразованную модель  

\begin{equation} 
\label{GrindEQ__14_25_} 
F^{-1}(\overline{p}_t)  = x'_t\beta + v_t, \ \ t=1, \dots,  \ T. 
\end{equation} 
Ошибка $v_t = F^{-1}(\overline{p}_t) - F^{-1}(p_t)$ гетероскедастична.  Дисперсия будет снижаться при увеличении $N_t$,  поскольку ${\overline{p}}_t$ точнее оценивает $p_t$,  а также будет зависеть от формы $F(\cdot )$. Используя метод разложения в ряд Тейлора (см. работы Амэмии (1981,  стр. 1498) или Маддалы (1983,  стр. 31)),  получим состоятельную оценку дисперсии ошибки $v_t$ 

\begin{equation} 
\label{GrindEQ__14_26_} 
\overline{\sigma}^2_t = \frac{\overline{p}_t (1 - \overline{p}_t) }{N_t [F'(F^{-1}(\overline{p}_t))]^2}. 
\end{equation} 
\textbf{Оценка} $\widehat{\mathbf{\beta}}_{\mathbf{MC}}$, \textbf{полученная методом Берксона}, минимизирует взвешенную сумму остатков $\sum^T_{t=1} (F^{-1} (\overline{p}_t) - x'_t\beta) / \overline{\sigma}^2_t$ по $\beta$. Метод легко реализовать с помощью МНК,  построив регрессию $F^{-1}(\overline{p}_t)/
\overline{\sigma}_t$ на $x_t/\overline{\sigma}_t.$

Этот метод прост в использовании,  поскольку требует только использование МНК. Несмотря на это,  он полностью эффективен,  поскольку,  можно показать,  что оценка имеет тоже асимптотическое распределение,  что и оценка,  полученная методом максимального правдоподобия,  при котором каждое наблюдение берется в отдельности,  а не группируется вместе с наблюдениями с тем же значением $x_t$. Для логит-модели этот метод особенно прост,  поскольку $F^{-1}(\overline{p}_t) = \ln (\overline{p}_t / (1 - \overline{p}_t))$ и $\overline{\sigma}^2_t = 1/[N_t \overline{p}_t (1 - \overline{p}_t)].$

Преимуществом метода Берксона является простота расчетов,  хотя растущая  производительность компьютеров делает этот пункт спорным. Для сгруппированных экономических данных редко бывает ситуация,  когда есть несколько наблюдений  на одно уникальное значение регрессоров,  за исключением случаев,  когда регрессоры является совокупностью нескольких индикаторов. Метод Берксона помогает лучше понять агрегирование данных. Далее мы рассмотрим эту тему.

\subsection{Моделирование агрегированных данных}

Примером \textbf{агрегирования данных} в эконометрике может служить моделирование зависимости доли занятых людей или доли тех,  кто пользуется автобусными перевозками в разных регионах, в зависимости от  средних характеристик людей по регионам.

Приведем конкретный пример. Обозначим $\overline{p}_t$ уровень безработицы в регионе $t$,  а $\overline{x}_t$ --- средний уровень образования в регионе $t$. Одной из возможных моделей может быть линейная регрессия $\overline{p}_t$ на $\overline{x}_t$. Поскольку $0 < \overline{p}_t < 1, $ многие исследования,  вместо этого преобразовывают  $\overline{p}_t$ в неограниченную зависимую переменную и оценивают модель

\begin{equation} 
\label{GrindEQ__14_27_} 
\ln \left(\frac{\overline{p}_t}{1 - \overline{p}_t}\right) =\overline{x}'_t \beta +u_t,  
\end{equation} 
где $u_t$ -- ошибка.

Эта модель очень похожа на модель в методе Берксона для логит-модели,  когда $F^{-1}(\overline{p}_t) = \ln  (\overline{p}_t/(1-\overline{p}_t))$. Однако,  это не потому,  что метод Берксона приемлем, только если все регрессоры в $t$-ой ячейке принимают одинаковое значение. Здесь,  наоборот,  регрессоры могут принимать различные значения, у разных людей в регионе $t$ может быть разный уровень образования.

Чтобы увидеть последствия агрегирования,  когда имеет место \textbf{неоднородность регрессора в одной ячейке},  предположим,  что модель поведения индивида является индексной моделью (см. подраздел 14.4.1),  для которой 

\[
y^*_i=x'_i\beta +u_i, 
\] 

\[
u_i \sim \mathcal{N}[0, 1].
\] 
Будем считать,  что ошибка имеет нормальное распределение,  как в  пробит,  а не в логит-модели,  поскольку тогда возможно получение аналитических результатов. 

Смоделируем неоднородность как

\[
x_i \sim \mathcal{N}[\mu_t, \Sigma_t], 
\] 
для индивидов в ячейке $t$. Это действительно допускает вариацию между ячеек,  а сложность заключается в том,  что $\Sigma_t \ne 0$, т.е. присутствует неоднородность регрессора в одной ячейке. Тогда для региона $t$ при фиксированных $\beta$, $\mu_t$ и $\Sigma_t$, 

\begin{multline*}
\Pr[y_i = 1] = \Pr[x'_i\beta + u_i > 0] \\
=\Pr\left[\frac{x'_i\beta + u_i - \mu'_t\beta}{\sqrt{1+\beta'\Sigma_t\beta}} > \frac{-\mu'_t\beta}{\sqrt{1+\beta'\Sigma_t\beta}}\right] \\
=\Phi \left(\frac{\mu'_t\beta}{\sqrt{1+\beta'\Sigma_t\beta}}\right),
\end{multline*} 
где мы использовали полученное из предпосылок распределение суммы $x'_i \beta + u_i \sim \mathcal{N}[\mu'_t\beta,  (1+\beta'\Sigma_t \beta)]$. Чтобы величина имела стандартное нормальное распределение мы вычли среднее и разделили на стандартное отклонение.

Используя те же аргументы,  которые привели к выражению \eqref{GrindEQ__14_25_} от \eqref{GrindEQ__14_24_},   параметр $\beta$ индивидуального бинарного выбора может быть состоятельно оценен с помощью нелинейного МНК в регрессии

\begin{equation} 
\label{GrindEQ__14_28_} 
\Phi^{-1}(\overline{y}_t) = \frac{\overline{x}'_t\beta}{\sqrt{1+\beta'S_t \beta}} + w_t,  
\end{equation} 
где $\overline{y}_t$ и $\overline{x}_t$ --- средние значения,  а $S_t$ --- выборочная дисперсия $x_i$ в ячейке $t$. Метод минимизации хи-квадрат Берксона,  строит регрессию $\Phi^{-1}(\overline{y}_t)$ на $\overline{x}_t$ и даёт состоятельные оценки для $\beta$ только если $\Sigma_t=0.$

\subsection{Обсуждение}

Проблема агрегированных данных намного сложнее в нелинейных моделях. Если изначально модель индивидуального выбора была линейной $y_i = x'_i\beta + u_i$ с $x_i \sim \mathcal{N}\left[\mu_t, \Sigma_t\right]$ в $t$-ой ячейке,  тогда соответствующая линейная регрессия $\overline{y}_t$ на $\overline{x}_t$ даст состоятельную оценку $\beta $. Для нелинейных моделей аналогичная агрегация приводит к несостоятельности оценки параметра индивидуального выбора,  если не будет предпринята корректировка,  как в выражении \eqref{GrindEQ__14_28_}. Более того,  пример,  приведенный в параграфе 14.6.2 из работы МакФаддена и Рейда  (1975) ,  нетипичен,  поскольку в нем агрегирование  приводит к явным результатам, что нетипично для нелинейных моделей. Данный пример очень подробно рассмотрен в работе Камерона  (1990),  который изучал его в более широком контексте \textbf{агрегирования данных в нелинейных моделях}.

Активно проблема агрегирования данных дискретного выбора,  обычно множественного,  обсуждается в литературе по маркетингу в теме \textbf{рыночной доли брендов}. В работе Олленбая и Росса  (1991)  представлен пример,  когда смещение агрегированной логит-модели оказывается небольшим. Что более важно,  современные вычислительные алгоритмы позволяют оценить параметры индивидуального выбора в случае агрегированных данных,  даже если агрегирование приводит к неаналитическому решению. С примером можно ознакомиться в работе Бэрри  (1994)  и Нэво  (2001),  в которой оцениваются модели,  качественно  аналогичные  логит-модели со случайными параметрами,  описанной в разделе 15.7.

И наконец,  обратите внимание,  что для многих случаев агрегированных показателей таких,  как уровень безработицы по региону,  исследователя не интересуют параметры индивидуального выбора. Единственной задачей становится,  построение разумной модели для зависимой переменной $\overline{p}_t$,  которая принимает значения между нулем и единицей. Тогда линейная регрессия \eqref{GrindEQ__14_27_} может подходить. Ошибка $u_t$ в выражении \eqref{GrindEQ__14_27_} больше не будет иметь дисперсию,  приведенную в \eqref{GrindEQ__14_26_}. Эта ошибка будет гетероскедастичной,  поэтому статистические выводы должны быть основаны на робастной к гетероскедастичности стандартной ошибке Уайта.

\section{Полупараметрические методы}

Модель бинарного выбора,  возможно,  является главным примером полупараметрической регрессии. Большинство эконометрических исследований предполагают одноиндексную форму $F(x'_i\beta )$,  когда функциональная форма $F$ не определена. Целью исследования является нахождение состоятельной оценки параметра $\beta$,  в идеальном случаем $\sqrt{N}$-состоятельной и асимптотически нормальной,  в то время как $F(\cdot )$ рассматривается как мешающая функция. Здесь может применяться одноиндексная полупараметрическая модель из параграфа 9.7.4. Дополнительные методы оценки интерпретируют модель индексной функции для ситуаций бинарного исхода. 
Кроме того,  возможно использование полупараметрического метода максимального правдоподобия,  который достигает границы эффективности полупараметрических методов. При этом не приходится прибегать к  дополнительным предположениям,  поскольку ясно,  что применяется распределение Бернулли,  и только $F(x'_i\beta )$ неизвестна.

\subsection{Полупараметрические методы оценки условного среднего}

В общей задаче оценивания зависимая переменная $y_i$ принимает значения,  равные 0 или 1,  с условным средним

\[
\E[y_i |x_i] = m(x_i), 
\] 
где $m(\cdot )$ --- неизвестна. Обратите внимание,  что $m(x_i)$ также равно условной вероятности наступления события $y_i=1$.

Непараметрические регрессионные методы,  описанные в разделах 9.4 --- 9.6,  могут быть использованы,  несмотря на бинарную природу зависимой переменной. Это хорошо видно на рисунке 14.1,  на графике рассеивания бинарной переменной $y$, зависимой от скалярной переменной $x$. Естественно рассмотреть ядерную регрессии $y$ на $x$. Предсказанные  значения будут лежать между 0 и 1,  за исключением особых случаев таких,  как использование ядерных функций более высокого порядка,  когда предсказанные значения могут быть отрицательными.

Для многих микроэкономических задач переменная $x$ имеет слишком много измерений,  чтобы непараметрические методы работали хорошо (проклятие размерности). Полупараметрические регрессионные модели,  которые частично определяют $m(\cdot)$,  приведены в разделе 9.7. Аддитивные модели довольно популярны для решения статистических задач. В эконометрике,  наоборот,  используется одноиндексная модель,  поскольку популярным начальным пунктом является индексная модель из параграфа 14.4.1. Мы получаем \textbf{одноиндексную модель} со скрытой переменной $y^*=x'\beta +u.$ Тогда

\[
\E[y_i| x_i] = F(x'_i\beta), 
\] 
где мы используем обозначения из этой главы, в частности $F(\cdot)$ вместо $g(\cdot)$,  чтобы обозначить неизвестную функцию. 

Из параграфа 9.7.4,  параметр $\beta$ может быть определен только с точностью до сдвига и масштабирования. Это также видно из параграфа 14.4.1,  где ошибка $u$ в индексной модели была нормирована,  чтобы ее среднее равнялось нулю (сдвиг),  а дисперсия была фиксирована (масштабирование). Теперь ограничения на ошибку $u$ не накладываются,  поэтому параметр $\beta$ не может быть полностью идентифицирован,  однако отношение коэффициентов при независимых переменных идентифицируемо. Для  более подробного анализа проблемы идентификации в моделях бинарного выбора можно ознакомиться с работой Мански (1988b).

$\sqrt{N}$-состоятельная асимптотически нормальная оценка $\beta$ может быть получена путем оценки средней производной  или полупараметрическим МНК (см. параграф 9.7.4). Тем не менее,  чаще используются альтернативные модели,  специфические для ситуаций бинарного выбора.

\subsection{Оценивание по методу максимального счета}

Полупараметрические методы для бинарного выбора часто основываются на индексной модели $y^*=x'\beta + u$. В этом случае удобнее записать модель следующим образом 

\[
y_i = 1(x'_i\beta + u_i > 0), 
\] 
где $1(A)=1$,  если событие $A$ происходит.

Мански  (1975)  отмечает,  что прогнозным значением $y_i$ является $1(x'_i\beta >0)$. Если считать, что $u_i=0$,  поскольку $u_i$ неизвестно,  то количество  верных прогнозов будет равно

\begin{equation} 
\label{GrindEQ__14_29_} 
S_N(\beta)=\sum^N_{i=1} \{y_i 1(x'_i\beta > 0) + (1-y_i) 1(x'_i\beta \le 0)\},  
\end{equation} 
поскольку верные прогнозы случаются, если $y_i=1$ и $1(x'_i\beta >0)$ или $y_i=0$ и $1(x'_i\beta \le 0).$ Оценка $\widehat\beta_{MS}$, полученная по \textbf{методу максимального счета} Мански,  максимизирует функцию $S_N(\beta)$. Это нестандартная задача,  поскольку $1(x'_i\beta > 0)$ является недиффиренцируемой по $\beta.$ Мански (1975,  1985) доказал состоятельность в предположении что $F(0) = 0.5$ или,  что эквивалентно,  $\mathrm{Median}[u_i|x_i]=0.$ В дальнейшем было доказано,  что $N^{1/3}(\widehat\beta_{MS} - \beta)$ имеет ненормальное предельное распределение,  поэтому статистические выводы можно делать,  используя бутстрэп (см. работу Мански и Томпсона (1986)).

Метод Мански можно рассмотреть как метод абсолютных отклонений. Из параграфа 4.6.2,  в методе абсолютных отклонений минимизируется сумма разниц между $y_i$ и медианой $\mathrm{Median}[y_i|x_i]$. Этот менее знакомый метод аналогичен МНК,  в котором минимизируется сумма квадратов разниц между $y_i$ и $\E[y_i|x_i]$. % в английском оригинале ошибка
Чтобы использовать метод абсолютных отклонений,  необходимо получить $\mathrm{Median}[y_i|x_i]$. Если $\mathrm{Median}[u_i|x_i] = 0$,  то $\mathrm{Median}[y^*_i|x_i] = x_i'\beta$, тогда $\mathrm{Median}[y_i|x_i] = 1(x'_i\beta > 0).$ Тогда метод абсолютных отклонений в модели бинарного выбора минимизирует функцию 

\begin{equation} 
\label{GrindEQ__14_30_} 
Q_N(\beta) = \sum^N_{i=1} |y_i-1(x'_i\beta > 0)|. 
\end{equation} 
Из упражнения 14.4 $Q_N(\beta) = N - S_N(\beta)$, поэтому оценка по методу максимального счета эквивалентна оценке,  полученной методом абсолютных отклонений. Чтобы ознакомиться с другими способами интерпретации метода максимального счета как метода наименьших отклонений, обратитесь к работе Мански (1985,  стр. 320).

Целевая функция $S_N(\beta)$ по методу максимального счета, приведенная в выражении \eqref{GrindEQ__14_29_},  недифференцируема. Ее можно переписать в виде

\[
S_N(\beta) = \sum^N_{i=1} (2y_i-1) 1(x'_i\beta > 0) + N - \sum^N_{i=1} y_i,
\] 
(см. упражнение 14.4). Вторая сумма в выражении может быть проигнорирована, поскольку не содержит $\beta$.

Метод, использующий дифференцируемую целевую функцию, называется \textbf{сглаженным методом максимального счета} Хоровица, в нём максимизируется  функция

\[
Q^S_N(\beta) = \sum^N_{i=1} (2y_i-1) K (x'_i\beta/h_N),
\] 
где $K(x'\beta/h_N)$ --- сглаженная версия $1(x'\beta > 0).$ Поскольку $1(x'\beta > 0)$ принимает значение,  равное нулю,  при отрицательных значениях $x'\beta $,  и равное единице,  при положительных значениях $x'\beta $, естественно выбрать в качестве $K(\cdot)$ функцию распределения,  для которой выполняется $K(0)=0.5$,  и небольшое значение $h_N$. Сглаживание облегчает  расчет оценки,  но анализ осложнён необходимостью сходимости $h_N \to 0$ с подходящей скоростью при  $N \to \infty $. Оценка асимптотически нормальна, состоятельна со скоростью сходимости близкой к $\sqrt{N}$. Для дополнительной информации ознакомьтесь с работой Хоровица,  который предлагает алгоритм бутстрэпа,  снижающий вероятность ошибки первого рода в тестах на малых выборках.

Метод абсолютных отклонений может быть применен к цензурированным регрессионным моделям (см. параграф 16.9.2). 

\subsection{Метод максимальной ранговой корреляции}

Начнем с одноиндексной модели с $\E[y_i| x_i] = F(x'_i\beta)$. Если $F(x'_i\beta)$ монотонно возрастает по $x'_i\beta$,  то $\E[y_i| x_i] > \E[y_j| x_j]$ при $x'_i\beta > x'_j\beta $. 
Таким образом,  вполне вероятно,  хотя и не гарантированно,  что наблюдаемая величина $y_i>y_j$,  когда $x'_i\beta > x'_j\beta $. Это наводит на мысль, что имеет смысл подобрать такое $\beta$,  при котором с большой частотой $y_i > y_j$, если $x'_i\beta > x'_j\beta $.

\textbf{Метод максимальной ранговой корреляции} (Maximum Rank Correlation, MRC) Хана (1987) выбирает $\beta$,  которое максимизирует функцию

\[
Q^{MRC}_N(\beta) = \sum^N_{i=1} \sum^N_{\begin{array}{c} j=1 \\ j < i \end{array}} 
1(y_i > y_j) 1(x'_i\beta > x'_j\beta) + 1(y_i < y_j) 1(x'_i\beta < x'_j\beta).
\] 
В этой сумме $ij$-ый элемент равняется единице,  если $y_i>y_j$,  когда $x'_i\beta > x'_j\beta $,  или $y_i < y_j$,  когда $x'_i\beta < x'_j\beta $.  Слагаемое равняется нулю,  если наоборот имеет место $y_i < y_j$,  когда $x'_i\beta > x'_j\beta $,  или $y_i > y_j$,  когда $x'_i\beta < x'_j\beta $. Метод называется методом максимальной ранговой корреляции,  потому что $Q^{MRC}_N(\beta)$ пропорционально коэффициенту ранговой корреляции Кендалла между $y_i$ и $x'_i\beta $.

Оценка, полученная этим методом, является $\sqrt{N}$-состоятельной и асимптотически нормальной (см. работу Шермана, 1993). 

\subsection{Полупараметрический метод максимального правдоподобия}

Для моделей бинарного  функция правдоподобия обязательно имеет вид \eqref{GrindEQ__14_4_} при условии  независимости наблюдений. Единственная сложность заключается в том,  что форма $F\left(\cdot \right)$ неизвестна. Кляйн и Спэйди (1993) предложили \textbf{полупараметрический метод макисмального правдоподобия},  который максимизирует функцию 

\[
\mathcal{L}_N(\beta) = \sum^N_{i=1} \left\{y_i \ln \hat{F}(x'_i\beta) + (1-y_i) \ln (1-\hat{F}(x'_i\beta)) \right\},
\] 
где $\hat{F}(x'_i\beta)$ -- непараметрическая оценка $F(x'_i\beta)$.

Этот метода в плане идеи аналогичен взвешенному полупараметрическому МНК Ишимуры (1993),  разобранному в параграфе 9.7.4. Поэтому при вычислении этих оценок возникают сходные вопросы. Точно также алгоритм поочередно  вычисляет то $\widehat\beta$ при заданном $\hat{F}$, то $\hat{F}$ при заданном $\widehat\beta.$ Исходя из условия первого порядка максимизации функции правдоподобия \eqref{GrindEQ__14_5_} оценка полупараметрическим методом правдоподобия может быть вычислена как решение уравнения 

\[
\sum^N_{i=1} \frac{\widehat{F'}(x'_i\beta)}{\hat{F}(x'_i\beta)(1-\hat{F}(x'_i\beta))} (y_i-\hat{F}(x'_i\beta))x_i=0, 
\] 
которое аналогично выражению для взвешенного полупараметрического МНК с весами $w_i=\hat{F}'_i/[\hat{F}_i (1-\hat{F}_i)].$

Привлекательность метода Кляйна и Спэйди заключается в том,  что он полностью эффективен в том смысле,  что он достигает границы эффективности полупараметрических методов. Тем не менее,  процесс вычисления достаточно сложен. Более подробно проблемы вычисления оценки методом Ишимуры рассматривается в параграфе 9.7.4,  а также в работах Кляйна и Спэйди (1993) и Пагана и Уллаха (1999, стр. 283 --- 285).  

\subsection{Cравнение полупараметрических методов}

Внимание эконометристов обычно сосредоточено на одноиндексных моделях,  и даже несмотря на это существует масса полупараметрических методов для оценки моделей бинарного выбора. Ни один из этих методов на практике не оказывается существенно проще других для использования. Целевые функции могут иметь множество оптимальных точек и могут не быть гладкими. К примеру,  Хоровиц  (1992)  использует алгоритм имитации отжига для сглаженного метода максимального счета,  а Дорси и Майер  (1995)  применяют генетические алгоритмы для метода максимального счета.

Интерпретация коэффициентов также сложна. Например,  метод максимального счета,  примененный к данным по рыбалке,  приводит к оценке свободного члена 0.776 и оценке наклона $-0.631$ (с бутстрэп стандартной ошибкой 0.103),  но эти коэффициенты невозможно напрямую сравнить с коэффициентами из таблицы 14.2. Действительно,  поскольку оценки параметов при независимых переменных определены с точностью до масштаба,  полупараметрические оценки являются полезными,  если в регрессию включено несколько регрессоров. В этом случае оценки  коэффициентов можно сравнивать с оценкой коэффициента, выбранного за  базу сравнения.

Методы максимального счета и максимизации ранговой корреляции нетипичны среди полупараметрических методов тем,  что не требуют сглаживания параметров,  таких как ширина окна сглаживания,  что является их привлекательной чертой. Результаты таких методов $\sqrt{N}$-состоятельны.

В недавней работе Бланделла и Пауэлла  (2004)  был предложен полупараметрический метод оценки с \textbf{эндогенными регрессорами}.

\section{От распределения экстремальных значений к логит-модели}

При переходе к логит-модели от модели ARUM в разделе 14.4.2 использовалось утверждение,  что разница $(\e_0 - \e_1)$ случайных величин имеющих распределение экстремальных значений имеет логистическое распределение. Для полноты изложения приведем доказательство,  основанное на распределении $\e_0$ и  $\e_1.$

Переписав вторую строку выражения \eqref{GrindEQ__14_20_},  получим 

\begin{equation}
\label{GrindEQ__14_31_}
\begin{split}
\Pr[y=1] = \Pr[\e_0 < \e_1 + V_1 - V_0] \\
&= \int^{\infty}_{-\infty} \int^{\e_1 + V_1 - V_0}_{-\infty} f(\e_0, \e_1) d\e_0 d\e_1 \\
&= \int^{\infty}_{-\infty} f(\e_1) \left\{ \int^{\e_1 + V_1 - V_0}_{-\infty} f(\e_0) d\e_0 \right\} d\e_1, 
\end{split}
\end{equation} 
в последней строке предполагается,  что величины $\e_0$ и $\e_1$ --- независимы. Пусть $f(\e_0)$ --- плотность распределения экстремальных значений первого типа,  тогда из \eqref{GrindEQ__14_31_} получим 

\begin{equation} 
\label{GrindEQ__14_32_} 
\begin{split}
\Pr[y=1] = \int^{\infty}_{-\infty} f(\e_1) \left\{\int^{\e_1 + V_1 - V_0}_{-\infty} e^{-\e_0} \exp (e^{-\e_0)} d\e_0 \right\} d\e_1 \\
& = \int^{\infty}_{-\infty} f(\e_1) [\exp (-e^{-\e_0})]^{\e_1 + V_1 - V_0}_{-\infty} d\e_1 \\
& = \int^{\infty}_{-\infty} f(\e_1) \exp (-e^{-(\e_1 + V_1 - V_0)}) d\e_1.
\end{split}
\end{equation} 

Используя плотность распределения экстремальных значений для $\e_1$,  из \eqref{GrindEQ__14_32_} получим 

\begin{equation} 
\label{GrindEQ__14_33_} 
\begin{split}
\Pr[y=1] = \int^{\infty}_{-\infty} e^{-\e_1} \exp (-e^{-\e_1}) \exp (-e^{-(\e_1 + V_1 - V_0)}) d\e_1 \\
& = \int^{\infty}_{-\infty} e^{-\e_1} \left\{ \exp (-e^{-\e_1} - e^{-(\e_1 + V_1 - V_0)} \right\} d\e_1 \\
& = \int^{\infty}_{-\infty} e^{-\e_1} \left\{ \exp (-e^{-\e_1} - e^{-\e_1} e^{-(V_1 - V_0}) \right\}  d\e_1 \\
& = \int^{\infty}_{-\infty} e^{-\e_1} \exp  \left\{ -e^{-\e_1} (1+e^{-(V_1 - V_0)}) \right\} d\e_1.
\end{split}
\end{equation} 
Из $\int^{\infty}_{-\infty} ae^{-\e} \exp (-ae^{-\e}) d\e = 1$ следует,  что $\int^{\infty}_{-\infty} e^{-\e} \exp (-ae^{-\e}) d\e = 1/a.$ Используя это и $a = 1+e^{-(V_1 - V_0)}$,  из выражения \eqref{GrindEQ__14_33_} получим 

\begin{equation} 
\label{GrindEQ__14_34_}
\begin{split} 
\Pr[y=1] = (1+e^{-(V_1 - V_0)})^{-1} \\
& = e^{V_1}/(e^{V_0} + e^{V_1}) \\
& = e^{V_1 - V_0}/(1 + e^{V_1 - V_0}). 
\end{split}
\end{equation} 

Используя равенство  $V_1 - V_0 = x'\beta $ получаем логит-модель. 

\section{Практические соображения}

Логит и пробит-модели встроены в большинство статистических пакетов. Основной вопрос состоит в выборе модели. На практике разница между предельными эффектами,  предсказанными этими моделями,  получается небольшой,  за исключением случаев, когда большинство исходов либо равно нулю,  либо равно единице.

Полупараметрические методы обычно требуют написания дополнительного кода на языках программирования,  таких как GAUSS,  хотя на языке Lindep осуществлены методы Мански,  Кляйна и Спэди.

\section{Библиографические заметки}

Логит и пробит-модели являются часто используемыми и относительно простыми нелинейными регрессионными моделями,  которые изложены во многих стандартных учебниках,  например, у Грина (2003). Обзоры Амэмии (1981)  и МакФаддена  (1984)  содержат все основные результаты. Маддала  (1983)  и Амэмия приводят много деталей. Книги Трейна (1986) и Бен-Акивы и Лермана (1985) хороши для практического применения. Эти источники охватывают как модели бинарного,  так и множественного выбора.

\begin{enumerate}
\item [$14.3$] Блисс  (1934)  предложил пробит преобразование для графика кривой \hl{доза-смертность}. Берксон  (1951)  популяризировал использование простейшей логит-модели.
\item [$14.4$] Модели скрытых переменных особенно популярны в литературе по \hl{физиометрии}.
\item [$14.5$] В работе Амэмии (1985,  раздел 9.5) приведено блестящий обзор вопросов самоотбора выборки в моделях бинарного выбора (см. также раздел 24.4). 
\item [$14.6$] Камерон  (1990)  изучал проблему агрегирования данных в моделях бинарного выбора и обобщил результаты исследований Келияна  (1980)  и Стокера  (1984)  о возможности оценивания индивидуальных параметров  в нелинейных моделях,   используя агрегированные данные.
\item [$14.7$] Метод максимального счета Мански  (1975)  --- это один из основных примеров ранних исследований полупараметрических регрессий. Полупараметрические методы для моделей бинарного выбора описаны в работах М.-Дж. Ли  (1996),  Хоровица  (1997)  и Пагана и Уллаха  (1999). Особенно много методов описывается в последней работе.
\end{enumerate}

\section*{Упражнения}

\begin{enumerate}
\item [$14 - 1$] Рассмотрим скрытую перемененную заданную уравнение $y^*_i = x'_i\beta +\e_i$,  где $\e_i \sim \mathcal{N} [0, 1].$ Предположим, что мы наблюдаем только $y_i=1$, если $y^*_i < U_i$ и $y_i = 0$,  если $y^*_i\ge U_i$,  где верхняя граница $U_i$ --- известная для каждого индивида константа,  которая может изменяться в зависимости от индивида.
\begin{enumerate}
\item  Найдите $\Pr [y_i=1 | x_i]$. Подсказка: Обратите внимание,  что предлагаемый случай отличается от стандартного,  во-первых,  потому что присутствует $U_i$, а во-вторых,  неравенства изменило знак, теперь $y_i = 1$,  если $y^*_i < U_i$.
\item  Опишите подробные шаги получения состоятельной оценки параметра $\beta$.
\item  Допустим,  вы оценили параметры модели и обнаружили,  что оценка параметра для третьего регрессора $x_{3i}$ принимает значение $\widehat\beta_3 = 0.2.$ Приведите содержательную интерпретацию оценки $\widehat\beta_3.$
\end{enumerate}

\item [$14 - 2$] Рассмотрим логит-модель $\Pr[y=1|x_1, x_2] = \Lambda (\beta_0 + \beta_1 x_{1i} + \beta_2x_{2i})$, где $\Lambda (\rm{z}) = e^z/(1+e^z)x.$
\begin{enumerate}
\item  Выпишите производную функции правдоподобия и информационную матрицу в развернутом виде.
\item Используйте их чтобы провести тест Вальда и тест множителей Лагранжа для гипотезы $H_0: \beta_2 = 0$.
\item  Объясните, как реализовать тесты вычислительными методами
\item  В каком смысле логит-модель по своей сути гетероскедастична?
\end{enumerate}

\item [$14 - 3$] Предположим,  мы используем индексную форму для модели дискретного выбора,  но скрытая переменная принимает строго положительные значения. Поэтому мы используем предположение о том,  что скрытая переменная $y^*$ имеет экспоненциальную функцию плотности с параметром $\gamma $,  тогда плотность распределения $f(y^*)$ принимает вид $f(y^*) = \gamma^{-1} \exp (-y^*/\gamma)$,  с параметром $\gamma = \exp (x'\beta).$ Мы наблюдаем $y = 1$,  если $y^* > z'\alpha$,  и $y = 0,$ если $y^* \le z'\alpha$.
\begin{enumerate}
\item  Постройте логарифмическую функцию правдоподобия для наблюдаемых данных.
\item Какой эффект произведет изменение на одну единицу переменной $x_{ji}$ на вероятность $\Pr[y_i = 1]?$
\item  Предположим,  что $y = 1$,  если $y^* > \exp (z'\alpha)$ и $x = z.$ Существуют ли какие-либо сложности с идентификацией $\alpha$ или $\beta$? Объясните свой ответ.
\end{enumerate}

\item [$14 - 4$] Рассмотрим оценивание по методу максимального счета с целевыми функциями $S_N(\beta)$ \eqref{GrindEQ__14_29_} и $Q_N(\beta)$ \eqref{GrindEQ__14_30_}.
\begin{enumerate}
\item  Покажите,  что $S_N(\beta) = \sum_i [1(y_i = 1) \times 1(x'_i\beta > 0) + 1(y_i = 0) \times 1(x'_i\beta \le 0)].$
\item  Покажите,  что $Q_N(\beta) = \sum_i [1(y_i = 1) \times 1(x'_i\beta \le 0) + 1(y_i = 0) \times 1(x'_i\beta > 0)].$
\item  Используя $1(y_i = 1) = 1 - 1(y_i = 0)$, покажите, что $Q_N(\beta) = N - S_N(\beta).$
\item  Используя $1(x'_i\beta \le 0) = 1 - 1(x'_i\beta > 0)$, покажите, что выражение \eqref{GrindEQ__14_29_} может быть записано как $S_N(\beta) = \sum_i (2y_i - 1) 1(x'_i\beta > 0) + N - \sum_i y_i.$
\end{enumerate}

\item [$14 - 5$] Воспользуйтесь данными о расходах на здравоохранение из раздела 16.6. Рассмотрим пробит регрессию зависимой переменной DMED, индикатора положительности расходов на здравоохранение,  для простоты только от одной независимой переменной NDISEASE,  количества хронических заболеваний.
\begin{enumerate}
\item  Оцените коэффициент при независимой переменной методом наименьших квадратов.
\item  Найдите пробит оценку коэффициента при независимой переменной.
\item  Используя результаты из пункта (b),  определите предельный эффект от роста количества хронических заболеваний двумя путями: средний по выборке и оцененный с помощью среднего по выборке значения переменной NDISEASE.
\item  Найдите логит оценку коэффициента при независимой переменной.
\item  Используя результаты из пункта (d),  определите предельный эффект от роста количества хронических заболеваний тремя путями: средний по выборке,  оцененный с помощью среднего по выборке переменной NDISEASE,  оцененный при $\Lambda (x'\beta) = \overline{y}.$
\item  Для логит-модели рассчитайте во сколько раз изменится отношения шансов,  когда изменяется переменная NDISEASE.
\end{enumerate}

\item [$14 - 6$] Продолжим анализ ситуации из упражнения 14.5.
\begin{enumerate}
\item  Сравните три модели бинарного выбора на основе статистической значимости независимой переменной NDISEASE.
\item  Сравните три модели бинарного выбора на основе рассчитанного предельного эффекта.
\item  Сравните три модели бинарного выбора на основе спрогнозированных вероятностей.
\item  Сравните логит и  пробит-модели на основе логарифмической функции правдоподобия.
\end{enumerate}
\end{enumerate}


