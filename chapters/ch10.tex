
\chapter {Методы численной оптимизации}
\section{Введение}
Теоретическое вопросы  состоятельности и асимптотического распределения оценок были рассмотрены в качестве решения проблемы оптимизации в главах 5 и 6. В этой главе рассматриваются практические аспекты применения вычислительных методов для решения задач оптимизации, а именно, описаны методы, которые применяются для определения оценок параметров при отсутствии явно заданной формулы.


С точки зрения прикладных исследований оценка параметров нелинейных моделей, таких как логит, пробит, тобит-моделей, моделей пропорционального риска и Пуассона, не отличается от обычного МНК. Статистические пакеты позволяют определить коэффициенты регрессии, стандартные ошибки, t-статистики и p-значения. Вычислительные проблемы могут появиться по причинам сходным невозможности применить МНК:  мультиколлинеарность, ошибки в исходных данных.

Для оценки параметров в нестандартных моделях и в некоторых вариантах стандартных моделей, может потребоваться специальная программа. В случае если возможности стандартного статистического пакета не позволяют написать такую программу, то возможно использовать язык программирования. При этом необходимо знакомство с методами оптимизации.


Общие методы оптимизации рассмотрены в разделе 10.2., а ряд итерационных методов, например, градиентные методы Ньютона-Рафсона и Гаусса-Ньютона, в разделе 10.3. Особенности практического применения данных методов, в том числе типичные ошибки, рассмотрены в разделе 10.4. Данные особенности становятся особенно значимыми в том случае, если методы оптимизации не дают оценок параметров.

\section{Обзор методов численной оптимизации}

Зачастую в основе микроэкономического анализа лежит оценка параметра $\hat{\theta}$, которая максимизирует значение стохастически-заданной целевой функции $Q_{N}(\theta)$ и, как правило, значения $\hat{\theta}$ являются решением условий первого порядка $\partial{Q_{N}(\theta)}/\partial\theta=0$. Задачу минимизации можно привести к задаче максимизации путем умножения целевой функции на минус единицу. В случае нелинейно заданной целевой функции условия первого порядка, как правило, не будут иметь явного решения. Нелинейно заданная функция представляет собой систему из $q$ уравнений с $q$ неизвестными параметрами $\theta$.

Метод поиска на сетке, рассмотренный далее, редко применяется на практике. Вместо него применяются итерационные методы, например, градиентные.

\subsection{Метод поиска на сетке}

Процедура поиска на сетке включает в себя перебор множества значений параметра $\theta$ вдоль сетки, расчет значений функции $Q_N(\theta)$ для каждого параметра и выбор в качестве оценки того значения параметра $\hat{\theta}$, которое является локальным или глобальным (в зависимости от приложения) максимумом функции $Q_N(\theta)$. 

Данный метод всегда даст результат, если выбран достаточно мелкий шаг сетки. Однако на практике применение данного метода может сопровождаться рядом трудностей, поскольку выбор мелкого шага сетки осложнен. Например, если нам необходимо оценить 10 параметров и на сетке расположено 10 значений для каждого параметра, то получается что нам необходимо сделать $10^{10}$, т.е. 10 миллиардов расчетов. Кроме того данная сетка является довольно редкой.

Тем не менее, методы поиска на сетке могут использоваться при необходимости найти оптимальные значения только для некоторого подмножества параметров. Кроме того данные методы позволяют изучить поверхность отклика, чтобы убедиться в отсутствии множественности максимумов. По данному принципу работают многие статистические пакеты при оценки AR(1) коэффициента в регрессии с $\AR(1)$ ошибками. Кроме того, поиск на сетке позволяет найти оптимальные значения для скалярного параметра (inclusive value) во вложенной логит-модели (см. раздел 15.6). Поиск на сетке может быть использован в случае, если все остальные методы невозможно применить.

\subsection{Итерационные методы}

На практике наибольшее применение в микроэкономическом анализе получили итерационные методы. В данных методах оценка параметра $\theta$ пересчитывается согласно определенным правилам. На основе  $s$-ой оценки $\hat{\theta}_s$, итерационные методы строят $(s+1)$-ую оценку $\hat{\theta}_{s+1}$, здесь $\hat{\theta}_s$ --- оценка параметра, полученная на $s$-том шаге, а не $s$-тый компонент вектора оценки $\hat{\theta}$. Теоретически, новая оценка параметра должна быть быть более оптимальное, т.е. $Q_N(\hat{\theta}_{s+1})>Q_N(\hat{\theta}_{s})$, однако это не всегда выполняется. Следует отметить, что результатом оценивания градиентным методом может стать нахождение локального, а не глобального максимума.

\subsection{Градиентные методы}

Наибольшее количество итерационных методов являются градиентными. Они предполагают изменение оценки параметра $\hat{\theta}_s$ в соответствии с направлением градиента. Формула пересчета основана на взвешенном с помощью матрице градиенте

\begin{equation}
\hat{\theta}_{s+1}=\hat{\theta}_{s}+A_{s}g_{s}, s=1,\ldots ,S,
\end{equation}
где $A_s$ --- матрица размерностью $q \times q$ значения которой зависят от $\hat{\theta}_s$ и

\begin{equation}
g_s=\left. \dfrac{\partial{Q_N}{(\theta)}}{\partial\theta}\right|_{\hat{\theta}_{s}}
\end{equation}
где $g_s$ --- вектор градиента размерностью $q \times 1$, значения которого получены в точке $\hat{\theta}_s$. Применение различных градиентных методов предполагает использование различных матриц $A_s$, подробно данный вопрос рассматривается в разделе 10.3. Показательным примером является метод Ньютона-Рафсона, согласно которому матрица $A_s=-{H_s}^{-1}$, где $H_s$ --- это Гессиан (определение матрицы Гессе дано в разделе 10.6). Следует отметить, что в  этой главе обозначения $A$ и $g$ обозначают не то, что в остальных главах.  В остальных главах учебника матрица $A$ --- матрица, используемая для описания предельного распределения оценок параметров, а $g$ --- условное среднее  $y$ в модели нелинейной регрессии.

Теоретически,  матрицу $A_s$ следует взять положительно определенную для нахождения максимума (отрицательно определенную для нахождения минимума). При выполнение данного условия часто будет выполнено неравенство: $Q_N(\hat{\theta}_{s+1})>Q_N({\hat{\theta}}_s)$. Это следует из разложения целевой функции в ряд Тейлора, $Q_N(\hat{\theta}_{s+1})=Q_N(\hat{\theta}_s)+g'_s(\hat{\theta}_{s+1}-\hat{\theta}_s)+R$  где $R$ --- остаточный член. Подставляя данное выражение в формулу пересчета (10.1) получим, что

\[
Q_N(\hat{\theta}_{s+1})-Q_N(\hat{\theta}_s)=g'_sA_sg_s+R.
\]
Данное выражение больше нуля, если матрица $A_s$ положительно определена и остаток $R$ является малой величиной, потому как для положительно определенной квадратной матрицы $A$ выполнено неравенство $x'Ax>0$ для всех вектор-столбцов $x\neq0$. Слишком маленькие значения матрицы $A_s$ приводят к замедлению итерационных процессов; в тоже время слишком большие значения матрицы $A_s$ могут привести к <<перелёту>>, даже если матрица $A_s$ положительна определена. Связано это с тем, что при больших изменениях нельзя игнорировать остаточный член.

Стандартным способом предотвращения <<перелёта>> или слишком медленной скорости  градиентных методов является изменение размера шага:

\begin{equation}
\hat{\theta}_{s+1}=\hat{\theta}_s+\hat{\lambda}_sA_sg_s
\end{equation}
где скаляр $\hat{\lambda}_s$ --- размер шага, значения которого выбраны таким образом, чтобы максимизировать значение функции $Q_N(\hat{\theta}_{s+1})$. В первую очередь при итерации $s$ необходимо рассчитать $A_s g_s$, что может потребовать большого количества вычислений. Далее, необходимо определить $Q_N(\hat{\theta})$, где $\hat{\theta} = \hat{\theta}_s + \lambda A_s g_s$ для ряда значений $\lambda$ (так называемый, линейный поиск) и выбрать такое значение $\hat{\lambda}_s$, которое максимизирует значение функции $Q_N(\hat{\theta})$. Возможна существенная экономия времени вычислений, поскольку значения вектора градиента и матрицы $A_s$ не пересчитываются в ходе процесса линейного поиска.

Альтернативный способ корректировки применяется в случае, если матрица $A_s$ является обратной к матрице $B_s$, т.е $A_s=B_s^{-1}$. Тогда, если матрица $B_s$ близка к вырожденной, в качестве корректировки можно прибавлять или вычитать некую матрицу констант $C$, чтобы разрешить проблему вырожденности матрицы, т.е. $A_s = ({B_s + C})^{-1}$. Аналогичную корректировку можно применить для  матрицы $A_s$, не являющейся положительно определенной. Более подробно расчет матрицы $A_s$ представлен в разделе 10.3.

Как правило, градиентные методы позволяют найти локальный максимум функции в диапазоне близком к начальному значению. В случае если целевая функция имеет множество локальных максимумов, следует использовать множество начальных значений с целью увеличения вероятности определения глобального максимума.

\subsection{Пример градиентного метода}

Рассмотрим пример расчета МНК-оценки в экспоненциальной регрессионной модели, где единственным независимым параметром является константа. Тогда математическое ожидание $y$ будет равно $\E[y]=e^{\beta}$ и значение градиента будет равно $g=N^{-1}\Sigma_{i}(y_i-e^\beta)e^{\beta}$. Предположим, что в формуле (10.1) мы использовали матрицу $A_s=e^{-2\hat{\beta}_s}$, что является скоринговой вариацией алгоритма метода Ньютона-Рафсона. Данный метод будет рассмотрен подробнее в разделе 10.3.2. Итерационная формула для $\hat{\beta}_{s+1}$ упрощается до $\hat{\beta}_s = \hat{\beta} + (\bar{y} --- e^{\hat{\beta}_s})/e^{\hat{\beta}_s}$. 

Для иллюстрации работы данного алгоритма предположим, что $\bar{y}=2$ и начальное значение параметра рано единице, $\hat{\beta}_{1}=0$. Результаты итераций представлены в таблице 10.1. Как можно видеть существует очень быстрая сходимость к нелинейной МНК оценке и для приведенного примера оценка может быть получена аналитически поскольку $\hat{\beta} = \ln \bar{y} = \ln 2 = 0.693147$. Значения целевой функции растут с ростом числа итераций, из-за использования алгоритма Ньютона-Рафсона для глобально вогнутой функции. Отметим, что <<перелёт>> оценок происходит при первой итерации, от $\hat{\beta}_1 = 0.0$ до $\hat{\beta}_2 = 1.0$, что превышает значение $\hat{\beta} = 0.693$.

\begin{table}[h]
\begin{center}
\caption{\label{tab:gradres} Результаты градиентного метода}
\begin{tabular}{cccc}
\hline 
\hline
Итерация & Оценка & Градиент & Целевая функция \\ 
\hline 
s & $\hat{\beta}_s$& $g_s$ & $Q_N(\hat{\beta}_s)=-\frac{1}{2N}\sum_i(y_i-e^{\beta})^2$ \\ 
1 & 0.000000& 1.000000& 1.500000 -- $\sum_i{y_i}^2/2N$ \\ 
2 & 1.000000 & -1.952492 & 1.742036 -- $\sum_i{y_i}^2/2N$ \\ 
3 & 0.735758 & -0.181711 & 1.996210 -- $\sum_i{y_i}^2/2N$ \\ 
4 & 0.694042 & -0.003585 & 1.999998 -- $\sum_i{y_i}^2/2N$ \\ 
5 & 0.693147 & -0.000002 & 2.000000 -- $\sum_i{y_i}^2/2N$ \\ 
\hline 
\hline
\end{tabular} 
\end{center}
\end{table}

Быстрая сходимость, как правило, возникает при использовании алгоритма Ньютона-Рафсона и при условии, что целевая функция является глобально вогнутой. На практике проблема может возникнуть из-за того, что в нестандартных нелинейных моделях целевая функция может не быть глобально вогнутой.

\subsection{Метод моментов. Оценка параметра обобщенным методом моментов}

Для М-оценок значение функции и значение градиента равны соответственно $Q_N(\theta)=N^{-1}\sum_iq_i(\theta)$ и $g(\theta)=N^{-1}\sum_{i}\partial{q_i}(\theta)/\partial{\theta}$.

Для обобщенного метода моментов (GMM) функция $Q_N({\theta})$ имеет квадратичный вид (см. раздел 6.3.2) и значение градиента вычисляется по более сложной формуле

\[
g{(\theta)}=\left[N^{-1}\sum_{i}\partial{h_i}(\theta)'/\partial{\theta}\right] \times W_N \times \left[N^{-1}\sum_{i}h_{i}(\theta)\right].
\]
Следовательно, градиентные методы, работающие для среднего не могут быть применены. В тоже время, методы, которые будут рассмотрены в разделе 10.3, такие как метод Ньютона-Рафсона, наискорейшего подъема, DFP, BFG и метод имитации отжига могут быть применены.

Метод моментов и оценка оценивающих уравнений по сути представляют собой решение системы уравнений, но в тоже время может быть переформулированы как проблемы численной оптимизации аналогично обобщенному методу моментов. Оценка параметра $\hat{\theta}$, которая является решением системы $q$ уравнений вида $N^{-1}\sum_{i}h_{i}(\theta)=0$ может быть получена путем минимизации функции $Q_N(\theta)=[N^{-1}\sum_{i}h_{i}(\theta)]'\times$ $[N^{-1}\sum_{i}h_{i}(\theta)]$.

\subsection{Критерий сходимости}

Итерационный процесс продолжается до тех пор, пока изменения не прекратятся. Программа завершает цикл когда: (1) происходят незначительные изменения целевой функции $Q_N(\hat{\theta}_s)$; (2) незначительно меняются значения вектора градиента $g_s$, относительно Гессиана; (3) происходят относительно небольшие изменения в оценка параметра $\hat{\theta}_s)$. Как правило, статистические пакеты выбирают стандартное пороговое значение относительно которого определяется изменения вышеперечисленных пунктов ((1)-(3)). Это пороговое значение получило название критерий сходимости. Значение критерия зачастую может быть изменено исследователем. В качестве консервативного порогового значения  принято брать $10^{-6}$.

Следует отметить, что, как правило, максимальное количество итераций определено заранее. После проведения максимального количества итераций выводятся результаты оценивания. Однако, полученные результаты не могут быть использованы, если не выполняется условие сходимости.

Напротив, если сходимость есть, это говорит о том, что был получен локальный максимум. В тоже время, если целевая функция не является глобально вогнутой, локальный максимум не обязательно будет глобальным максимумом.

\subsection{Исходные значения}

Количество итераций значительно сокращается в случае, если исходные значения $\hat{\theta}_1$ близки к значениям $\hat{\theta}$. Естественно, что использование состоятельных оценок  параметров  в качестве исходных значений хорошо. Неудачный выбор начальных значений может привести к тому, что  итерационный метод не сработает. В частности, для некоторых методов оценивания и градиентных методов невозможно рассчитать $g_1$ или $A_1$, если исходные значения равны нулю, $\hat{\theta}_1=0$.

В случае, если целевая функция не является вогнутой глобально необходимо использовать более множество стартовых значений для того, чтобы увеличить вероятность получения глобального максимума.

\subsection{Численная и аналитическая производные}

Любой градиентный метод по определению предполагает вычисление производных целевой функции. Как численные, так и аналитические производные могут быть использованы.

Численные производные вычисляются по формуле 

\begin{equation}
\dfrac{\Delta{Q_N}(\hat{\theta}_s)}{\Delta\theta_j} = \dfrac{Q_N(\hat{\theta}_s + he_j) --- Q_N(\hat{\theta}_s --- he_j)}{2h}, j = 1,\ldots,q
\end{equation}
где $h$ мало и $e_j = \begin{pmatrix} 0 &\ldots & 0 & 1 & 0 &\ldots & 0 \end{pmatrix}'$ вектор с 1 в $j$-ой строке и нулями во всех остальных строках.

В теории $h$ должно быть мало, поскольку теоретически $\partial{Q_N}(\theta)/\partial{\theta_j}$ равно пределу $\Delta{Q_N}(\theta)/\Delta\theta_j$ при $h \rightarrow 0$. На практике слишком малые значения $h$ приводят к ошибкам округления. В связи с этим, расчеты, в которых используется численная производная, должны быть сделаны с двойной или с четверной точностью, а не с одинарной. Хотя в программе может быть заложено начальное значение, к примеру, $h=10^{-6}$, для конкретной задачи лучше использовать свои исходные значения. Например, малые значения $h$ могут быть использованы, если переменная $y$ в нелинейной МНК регрессии измеряется не в долларах, а в тысячах долларов (при неизменности масштаба остальных переменных), тогда оценка параметра $\theta$ в тысячных.

Недостаток использования численных производных заключается в том, что производные необходимо считать много раз --- для всех $q$ параметров, $N$ наблюдений и $S$ итераций. Следовательно, необходимо оценить целевую функцию $2qNS$ раз, где каждое вычисление целевой функции может быть вычислительно трудным.

Альтернативой численным производным являются аналитические. Расчет аналитических производных сопровождается меньшим количеством вычислительных ошибок и его быстрее сделать, особенно, если производные заданы более простыми функциями, чем целевая функция. Более того, необходимо произвести расчеты только $qNS$ раз.

В методах, где требуется расчет вторых производных для построения матрицы $A_s$, использование аналитических производных является хорошей альтернативой. Даже если дана только первая аналитическая производная, вторая производная может быть посчитана быстрее и с меньшей вероятностью ошибок как численная производная от аналитической производной. В статических пакетах заложена функция расчета аналитических производных первого и второго порядка.

Расчет численных производных имеет преимущество в том, что не требует кодирования, кроме как записи целевой функции. Это сохраняет время и исключает один из возможных источников ошибки пользователей, хотя в некоторых статистических пакетах заложено вычисление аналитических производных.

Если время на проведение расчетов является критичным фактором или существуют опасения насчет точности вычислений, то стоит использовать аналитические производные. Считается хорошей практикой проверить правильность кода для аналитических производных, путем расчета оценок параметров с помощью численных производных, при этом исходные значения берутся те же, что используются при расчете аналитических производных.

\subsection{Неградиентные методы}

Применение градиентных  методов предполагает, что целевая функция должна быть достаточно гладкой, иначе градиента функции может не существовать. В некоторых случаях, таких как метод наименьших абсолютных отклонений, оценивание квантильной регрессии, метод максимального скоринга, невозможно вычислить градиент и следует применить иные итерационные методы.

Например, для оценки недифференцируемой целевой функции, такой как $Q_N(\theta_s)=N^{-1}\sum_i|y_i-x_i\beta|$ в случае наименьших абсолютных отклонений (LAD), можно использовать методы линейного программирования. Поскольку подобные примеры достаточно редко встречаются в микроэконометрике, основное внимание мы уделим градиентным методам.

Для целевых функций, задача максимизации которых может быть затруднена, например наличием нескольких локальных оптимумов, возможно применение неградиентных методов, таких как метод иммитации отжига (см. раздел 10.3.8) и генетические алгоритмы (смотри Дорси и Майер, 1995).

\section{Специальные методы}

Основным методом поиска глобального минимума вогнутой функции является итерационный метод Ньютона-Рафсона. Иные методы, такие как метод наискорейшего спуска и DFP, как правило, используются, если невозможно применить метод Ньютона-Рафсона. Для нелинейного МНК широкое распространение получил метод Гаусса-Ньютона. Однако, данный метод не такой универсальный  как  метод Ньютона-Рафсона, поскольку с помощью метода Гаусса-Ньютона можно решить только задачи наименьших квадратов и, кроме того, данный метод можно получить небольшим изменением метода Ньютона-Рафсона. Вышеперечисленные методы направлены на нахождение локального оптимума на основе стартовых значений параметров модели.

В данном разделе описан метод ожиданий, который хорошо применим при наличии пропусков в данных, а также метод имитации отжига, Последний является неградиентным методом и, как правило, позволяет найти глобальный, а не локальный максимум.


\subsection{Метод Ньютона-Рафсона}

Метод Ньютона-Рафсона (NR) один из наиболее частоприменяемых градиентных методов особенно, если целевая функция глобально вогнутая по $\theta$. В  методе Ньютона-Рафсона

\begin{equation}
\hat{\theta}_{s+1} = \hat{\theta}_s --- H^{-1}_sg_s,
\end{equation}
где $g_s$ определено уравнением (10.2) и

\begin{equation}
H_s = \left. \dfrac{\partial^2Q_N(\theta)}{\partial\theta\partial\theta'}\right|_{\hat{\theta}_s}
\end{equation}
является матрицей Гессе размера $q{\times}q$ оцененной в точке $\hat{\theta}_s$. Вышеприведенные формулы используются как для задач максимизации, так и для задач минимизации функции $Q_N (\theta)$, для решения задачи минимизации целевая функция $Q_N (\theta)$ домножается на минус единицу, что меняет знак перед $H^{-1}_s$ и $g_s$.

Чтобы объяснить метод Ньютона-Рафсона, начнем  с оценки параметра $\theta$ на $s$-ой итерации, т.е. с $\hat{\theta}_s$. Тогда, согласно согласно разложению в ряд Тейлора в окрестности точки $\hat{\theta}_s$, получим

\[
Q_N(\theta) = \left. Q_N(\hat{\theta}_s)+\dfrac{\partial{Q_N(\theta)}}{\partial{\theta}'}\right|_{\hat{\theta}_s}(\theta --- \hat{\theta}_s)+\left. \dfrac{1}{2}(\theta --- \hat{\theta}_s)'
\dfrac{\partial^2{Q_N(\theta)}}{\partial{\theta}\partial{\theta}'}\right|_{\hat{\theta}_s}(\theta --- \hat{\theta}_s)+R.
\]
Опуская остаточный член $R$ и используя более краткие обозначения, получим следующее выражение для приближенного значения $Q_N(\theta)$

\[
Q^*_N(\theta) = Q_N(\hat{\theta}_s)+g'_s(\theta --- \hat{\theta}_s)+\dfrac{1}{2}(\theta --- \hat{\theta}_s)'H_s(\theta --- \hat{\theta}_s).
\]
где $g_s$ и $H_s$ определены выражениями (10.2) и (10.6), соответственно. Для максимизации $Q^*_N(\theta)$ по $\theta$ приравниваем производную к нулю. Таким образом, $g_s+H_s(\theta --- \hat{\theta}_s) = 0$, и решая уравнение для $\theta$ получим $\hat{\theta}_{s+1} = \hat{\theta}_s-H^{-1}_sg_s$, что эквивалентно выражению (10.5). Таким образом, обновленный метод Ньютона-Рафсона решает задачу максимизации для функции $Q_N(\theta)$ разложенную в ряд Тейлора второго порядка в точке $\hat{\theta}_s$.

Для того, чтобы проверить увеличивают ли итерации Ньютона-Рафсона значения функции $Q_N(\theta)$ подставим значение оценки параметра на $(s+1)$-м шаге в разложение в ряд Тейлора, тогда

\[
Q_N(\hat{\theta}_{s+1}) = Q_N(\hat{\theta}_s) --- \dfrac{1}{2}(\hat{\theta}_{s+1} --- \hat{\theta}_s)'H_s(\hat{\theta}_{s+1} --- \hat{\theta}_s)+R.
\]
Опустив остаточный член, увидим, что значение функции будет возрастать (убывать), если $H_s$ положительно определена (отрицательно определена). В точке локального максимума матрица Гессе отрицательно полуопределена, однако вдалеке от точки максимума, это не всегда верно даже для корректно поставленных задач. Если метод Ньютона-Рафсона попадает в такую область, то необязательно, что он движется в направлении максимума. Кроме того, это приводит к вырожденности матрицы Гессе, следовательно, невозможно посчитать $H^{-1}_s$ в (10.5). Таким образом, метод Ньютона-Рафсона лучше всего работает при решении задач максимизации (минимизации), при условии, что целевая функция глобально вогнута (выпукла), поскольку $H_s$ всегда отрицательно-(положительно-) определена. В этом случае сходимости часто можно достигнуть уже после 10 итераций.

Дополнительное преимущество метода Ньютона-Рафсона обнаруживается, если исходное значение параметра $\hat{\theta}_1$ $\sqrt{N}$-состоятельная оценка, т.е. если выражение $\sqrt{N}(\hat{\theta}_1 --- \theta_0)$ имеет соответствующее предельное распределение. Тогда можно продемонстрировать, что оценка после второй итерации $\hat{\theta}_2$ имеет такое же асимптотическое распределение как и оценка, полученный при итерировании до достижения сходимости. Следовательно, не существует теоретической выгоды от продолжения итераций. Примером является  доступный обобщенный метод наименьших квадратов (ДОМНК), где начальные значения МНК приводят к состоятельным оценкам параметров регрессии, и в дальнейшем, эти значения используются для получения состоятельных оценок дисперсий параметров, а те, в свою очередь, --- для расчета эффективных оценок ОМНК. Вторым примером является использование легко получаемых состоятельных оценок в качестве исходных значений перед тем как максимизировать сложную функцию максимального правдоподобия. Несмотря на то что необходимость дальнейшего итерирования отсутствует, на практике большинство исследователей предпочитают итерировать до сходимости, если это не занимает существенно больше времени. Преимуществом итерирования до сходимости является то, что разные исследователи должны получить при этом одинаковые оценки параметров, в то время как различные начальные значения $\sqrt{N}$-состоятельных оценок приводят к разным значениям оценок после второй итерации, несмотря на то что последние асимптотически эквивалентны.

\subsection{Метод скоринга}

Наиболее часто используемая модификация Ньютона-Рафсона метода --- это метод скоринга (method of scoring, MS). В методе скоринга матрица Гессе заменяется на свое ожидаемое значение

\begin{equation}
H_{MS,s} =\left. \E \left[\dfrac{\partial^2 Q_N(\theta)}{\partial{\theta}\partial{\theta}'}\right] \right|_{\hat{\theta}_s}. 
\end{equation}
Такая замена особенно выгодна, когда применяется метод максимального правдоподобия, т.е. $Q_N(\theta) = N^{-1}\mathcal{L}_N(\theta)$, поскольку математическое ожидание  матрицы должно быть отрицательно определено, что следует из равенства информационных матриц (см. раздел 5.6.3), $-H_{MS,s} = \E [\partial{\mathcal{L}_N}/\partial{\theta} \times \partial{\mathcal{L}_N}/\partial{\theta}']$. % похоже в английском тексте пропущен минус
Эта матрица положительно определена, так как она является ковариационной матрицей. Получить значение математического ожидания в (10.7) возможно только для М-оценок и даже в этом случае при расчете могут возникнуть аналитеческие затруднения.

Метод скоринга для оценки методом максимального правдоподобия обобщенных линейных моделей, таких как модель Пуассона, пробит и логит-модели может быть реализован с использованием итерационного взвешенного МНК (см. МакКуллах и Нелдер, 1989). Ранее, когда исследователи имели доступ только к программам оценивающим МНК, этот способ имел  существенное достоинство.

Метод скоринга также может быть применен для оценки другим М-оценкам, а  не только к оценкам ММП, в этом случае матрица $H_{MS,s}$ может уже не быть отрицательно определенной.


\subsection{BHHH метод}

BHHH метод (Берндт, Холл, Холл и Хаусман, Berndt, Hall, Hall и Hausman, 1974) используют (10.1) с взвешивающей матрицей $A_s = -H^{-1}_{BHHH,s}$, где 

\begin{equation}
H_{BHHH,s} = \left. -\sum^N_{i=1}\dfrac{\partial{q_{i}}(\theta)}{\partial\theta}\dfrac{\partial{q_{i}}(\theta)}{\partial{\theta}'} \right|_{\hat{\theta}_s}
\end{equation}
и $Q_N(\theta) = \sum_{i}q_{i}(\theta)$. В сравнении с методом Ньютона-Рафсона, BHHH метод имеет преимущество в том, что необходимо считать производные только первого порядка, что значительно уменьшает количество вычислений.

Для обоснования использования данного метода, начнем с метода скоринга для ММП. Тогда $Q_N(\theta) = \sum_{i} \ln f_{i}(\theta)$, где $f_i(\theta)$ является логарифмом плотности. Информационное матричное равенство можно записать следующим образом

\[
\E\left[ \dfrac{\partial^2\mathcal{L}_N(\theta)}{\partial{\theta}\partial{\theta}'}\right] = -\E\left[ \sum^N_{i=1}\dfrac{\partial{\ln f_i(\theta)}}{\partial{\theta}}\sum^N_{i=1}\dfrac{\partial{\ln f_j(\theta)}}{\partial{\theta}'}\right] 
\]
и независимость по $i$ приводит к
\[
\E\left[ \dfrac{\partial^2{\mathcal{L}_N(\theta)}}{\partial{\theta}\partial{\theta}'}\right] = -\sum^N_{i=1} \E\left[ \dfrac{\partial{\ln f_i(\theta)}}{\partial{\theta}} \dfrac{\partial {\ln f_i(\theta)}}{\partial{\theta}'}\right]. 
\]
Отбрасывание математического ожидания приводит к выражению (10.8).

Можно также применять BHHH метод к оценкам, отличным от оценок ММП. В этом случае его можно рассматривать как метод, который предлагает другой вариант матрицы $A_s$ в (10.1), отличный от оценки матрицы Гессе $H_s$.

BHHH метод часто применяют для М-оценок пространственных данных, так как они обладают хорошими свойствами и требуют расчета только первых производных.

\subsection{Метод скорейшего подъема}

Метод скорейшего подъема предполагает использование матрицы $A_s = I_q$, использование единичной матрицы является самым простым вариантом взвешивающей матрицы. Далее выполняется линейный поиск (см. раздел 10.3) чтобы отмасштабировать единичную матрицу $I_q$ на константу $\lambda_s$.

Линейный поиск может быть сделан вручную. На практике принято использовать оптимальное значение $\lambda$, которое определяется как $\lambda_s= -g'_s g_s / g'_s H_s g_s$, где $H_s$ --- матрица Гессе. Для определения оптимального значения $\lambda_s$ необходимо вычисление Гессиана, что может вызвать затруднения. В таком случае, метод наискорейшего спуска можно заменить методом Ньютона-Рафсона. Однако, преимущество метода скорейшего подъема состоит в том, что $H_s$ может быть вырожденной матрицей, тем не менее необходимо, чтобы $H_s$ была отрицательно определена чтобы $\lambda_s<0$, и матрица  $\lambda_s I_s$ была отрицательно определена.

\subsection{DFP метод и BFGS метод}

Алгоритм DFP (Дэвидсон, Флетчер и Пауэлл, Davidson, Fletcher и Powell) --- градиентный метод с положительно-определенной взвешивающей матрицей $A_s$. Также, требует расчета только первых производных, в отличии от NR, который предполагает расчет Гессиана. В данном пункте метод DFP описан без доказательств.

Взвешивающая матрица $A_S$ рассчитывается рекурсивным способом

\begin{equation}
A_s = A_{s-1} + \dfrac{\delta_{s-1}\delta'_{s-1}}{\delta'_{s-1}\gamma_{s-1}} + \dfrac{A_{s-1}\gamma_{s-1}\gamma'_{s-1}A_{s-1}}{\gamma'_{s-1}A_{s-1}\gamma_{s-1}},
\end{equation}
где $\delta_{s-1} = A_{s-1}g_{s-1}$ и $\gamma_{s-1} = g_s --- g_{s-1}$. Если посмотреть на правую часть выражения (10.9), можно увидеть, что матрица $A_s$ будет положительно-определена в случае, если начальная матрица $A_0$ будет положительно-определена (например, $A_0 = I_q$).

Процедура сходится быстро во многих статистических приложениях. В результате матрица $A_s$ сходится к матрице Гессе $- H^{-1}_s$ --- более предпочтительной с точки зрения теории. В принципе данный метод может позволять получить приближенную оценку обратной матрицы к матрице Гессе для расчета стандартных ошибок, без расчета второй производной или обратной матрицы. Однако, полученная оценка может быть довольно плохой на практике.

Уточненным алгоритмом DFP является алгоритм BFGS (Бойден, Флетчер, Голдфарб и Шеннон, Boyden, Fletcher, Goldfarb и Shannon), с

\begin{equation}
A_s = A_{s-1}+\dfrac{\delta_{s-1}\delta'_{s-1}}{\delta'_{s-1}\gamma_{s-1}}+\dfrac{A_{s-1}\gamma_{s-1}\gamma'_{s-1}A_{s-1}}{\gamma'_{s-1}A_{s-1}\gamma_{s-1}}
-(\gamma'_{s-1}A_{s-1}\gamma_{s-1})\eta_{s-1}\eta'_{s-1},
\end{equation}
где $\eta_{s-1} = (\delta_{s-1}/\delta'_{s-1}\gamma_{s-1})-(A_{s-1}\gamma_{s-1}/\gamma'_{s-1}A_{s-1}\gamma_{s-1})$.


\subsection{Метод Гаусса-Ньютона}

Метод Гаусса-Ньютона --- итерационный метод для получения оценок нелинейного МНК (НМНК), в котором оценки получаются путем нескольких итераций с помощью обычного МНК. 

Для нелинейного МНК с функцией условного среднего $g({x_i},\beta)$, метод Гаусса-Ньютона берёт в качестве вектора разностей оценок параметров $(\hat{\beta}_{s+1}-\hat{\beta}_s)$ оценки коэффициентов, полученные путем оценки МНК вспомогательной регрессии

\begin{equation}
y_{i}-g(x_{i},\hat{\beta_s})= \left. \frac{\partial{g_i}}{\partial{\beta}'} \right|_{\hat{\beta}_s} \beta+v_{i}
\end{equation}
Также оценку коэффициента $\hat{\beta}_{s+1}$, можно получить применив МНК для вспомогательной регрессии

\begin{equation}
\left. y_{i}-g(x_{i},\hat{\beta}_s)-\dfrac{\partial{g_i}}{\partial{\beta}'} \right|_{\hat{\beta_s}}\hat{\beta}_s= \left. \frac{\partial{g_i}}{\partial{\beta}'} \right|_{\hat{\beta}_s} \beta+v_{i}
\end{equation}

Для объяснения данного метода, предположим, что $\hat{\beta}_s$ является начальным значением и разложим функцию $g(x_{i},\beta)$ в ряд Тейлора первого порядка в окрестности данной точки. Получим, что

\[
g(x_{i},\beta) = \left. g(x_i,\hat{\beta}_s)+\dfrac{\partial{g_i}}{\partial{\beta}'} \right|_{\hat{\beta}_s}(\beta-\hat{\beta}_s).
\]
Подставим данное значение в целевую функцию $Q_N (\beta)$ и получим приближенное значение функции

\[
Q^*_N(\beta) =  \sum^N_{i=1} \left(y_{i}-g(x_{i},\hat{\beta}_s) --- \left. \dfrac{\partial{g_i}}{\partial{\beta}'} \right|_{\hat{\beta}_s} (\beta-\hat{\beta}_s) \right)^2.
\]
Данное выражение эквивалентно сумме квадратов остатков, полученных с помощью МНК при  регрессии $y_{i}-g(x_{i},\hat{\beta}_s)$ на $\left. \dfrac{\partial{g_i}}{\partial{\beta}'} \right|_{\hat{\beta}_s}$ с вектором параметров $(\beta-\hat{\beta}_s)$, что в результате дает выражение (10.11). Более точно,

\begin{equation}
\hat{\beta}_{s+1} = \hat{\beta}+\left[ \sum_i \left. \dfrac{\partial{g_i}}{\partial{\beta}} \right|_{\hat{\beta}_s} \left. \dfrac{\partial{g_i}}{\partial{\beta}'} \right|_{\hat{\beta}_s} \right] ^{-1} \left. \sum_i \dfrac{\partial{g_i}}{\partial{\beta}} \right|_{\hat{\beta}_s} (y_i-g(x_i,\hat{\beta}_s)).
\end{equation}
Данное выражение есть ни что иное как градиентный метод (10.1), где вектор $g_s$ задан выражением $g_s=\sum_i \partial{g_i} / \partial{\beta}|_{\hat{\beta}_s} (y_i-g(x_i,\hat{\beta}_s))$, а матрица $A_s$ равна $A_s = [\sum_i \partial{g_i} / \partial{\beta} \times \partial{g_i} / \partial{\beta}'|_{\hat{\beta}_s}]^{-1}$.

Оценка (10.13), рассчитанная итерационным методом эквивалента оценке, вычисленной по скоринговому варианту метода Ньютона-Рафсона для нелинейного МНК (см. раздел 5.8). В правой части выражения вторая сумма есть вектор градиента, а первая сумма равна  ожидаемому значению матрицы Гессе, домноженному на -1 (см. раздел 10.3.9). Таким образом, алгоритм Гаусса-Ньютона является частным случаем алгоритма Ньютона-Рафсона. В этой главе наибольшее внимание уделено методу Ньютона-Рафсона, поскольку он более универсален, чем метод Гаусса-Ньютона.

\subsection{Метод максимизации ожидания}

В этой книге определенный класс данных и моделей можно представить с помощью пропущенных или неполных данных. Например, зависимая переменная (издержки или промежуток времени) может быть цензурирована справа. Следовательно, точные значения переменных в определенный момент времени известно лишь частино, в остальных случаях нам известно, что результат не превысит заданного значения, к примеру, $c^{*}$. Также, примером неполных данных может служить множественная модель для которой матрица данных имеет вид:

\[
\begin{bmatrix} y_{i}&X_{1} \\ ?&X_{2} \end{bmatrix},
\]
где знак вопроса обозначает пропущенные данные. Далее предположим, что мы хотим оценить линейную регрессионную модель $y=X\beta+u$, где $y'= \begin{bmatrix} y_1 & ? \end{bmatrix}$, $X'= \begin{bmatrix} X_1 & X_2 \end{bmatrix}$, и часть данных зависимой переменной ненаблюдаемы. Также, примером проблемы ненаблюдаемых переменных может быть оценка параметров $(\theta_1,\theta_2,\ldots ,\theta_c,\pi_1,\ldots ,\pi_C)$ смеси $C$ распределений, так называемая модель со скрытыми или латентными классами, $h(y|X)=\sum_{j=1}^{C}\pi_{j}f_{j}(y_i|X_{j},\theta_j)$, где $f_{j}(y_{j}|X_{j},\theta_{j})$ --- функция плотности. Переменная $\pi_{j}$ $(j=1,\ldots ,C)$ обозначает неизвестную долю с которой в выборке встречается $j$-ый класс из всех $C$ возможных классов. Эта проблема может также быть отнесена к проблеме скрытых данных, в том смысле, что если бы были заданы $\pi_{j}$, то оценку модели было бы проще произвести.

Метод максимизации ожидания (EM, expectation maximization) рассматривает все задачи с ненаблюдаемыми переменными в рамках универсального подхода. Частные случаи моделей ненаблюдаемых переменных изложены в литературе достаточно давно, а Демпстер, Лэйрд и Рубин (1977) приводят систематическое изложение.

Обозначим за $y$ вектор зависимых переменных, а за $y^{*}$ скрытые переменные. Пусть $f^{*}(y^{*}|X,\theta)$ условная плотность совместного распределения ненаблюдаемых переменных, при  заданном $X$ и $f(y|X,\theta)$ обозначает условную совместную плотность наблюдаемых переменных. Допустим, что между $y$ и $y^{*}$ отношения много к одному, т.е. для каждого $y$ существует уникальное значение $y^{*}$, но обратное не верно. Согласно правилу Байеса условная плотность $f(y^{*}|y)=f(y, y^{*})/f(y)=f^{*}(y^{*})/f(y)$, где последнее равенство получается из равенства $f(y^{*},y)=f^{*}(y^{*})$, поскольку каждому $y$ соответствует уникальное значение $y^{*}$, и, следовательно, $f(y|X,\theta)=f^{*}(y^{*}|X,\theta)/f(y^{*}|y,X,\theta)$. В результате приведения, получим выражение $f(y)=f^{*}(y^{*})/f(y^{*}|y)$.

ММП максимизирует значение функции

\begin{equation}
Q_{N}(\theta)=\dfrac{1}{N}\mathcal{L}_{N}(\theta)=\dfrac{1}{N} \ln (f^{*}y^{*}|X,\theta)-\dfrac{1}{N} \ln f(y^{*}|y,X,\theta).
\end{equation}
Поскольку значения $y^{*}$ неизвестны, первое слагаемое опускается, от второго члена берется математическое ожидание. В выражении для математического ожидания отсутствует $y^{*}$ и значение выражения рассчитывается на $s$-той итерации в точке $\theta=\hat{\theta}_s$.

На <<Е>>-шаге EM алгоритма, ожидание $\E$ рассчитывается по формуле:

\begin{equation}
Q_{N}(\theta)=-\E\left[\dfrac{1}{N} \ln f(y^{*}|y,X,\theta)|y,X,\hat{\theta}_s\right],
\end{equation}
где ожидание берется по плотности $f(y^{*}|y,X,\hat{\theta}_s)$. На <<М>>-шаге максимизируется значение функции $Q_{N}(\theta|\hat{\theta}_s)$, чтобы получить $\hat{\theta}_{s+1}$.

EM --- это итерационный алгоритм. Максимизируется функции правдоподобия при заданных значениях ненаблюдаемых (скрытых) переменных; далее вновь оцениваются ожидаемые значения при заданных значениях $\theta$. Итерирование продолжается до наступления сходимости. Преимущество EM алгоритма заключается в том, что в результате значения функции $Q_{N}(\theta)$ увеличиваются или становятся менее изменчивыми, см. Амэмия (1985, стр. 376). Применение EM алгоритма к моделям с латентными классами рассмотрено в разделе 18.5.3 и к моделям с пропущенным данным данными в разделе 27.5.

В литературе широко представлено применение EM алгоритма к решению задач оптимизации, хотя и не ко всем задачам он применим. EM алгоритм можно легко запрограммировать для многих случаев, и его использование было подкреплено идеей ограниченной возможности расчетов, что в наше время уже не является актуальным. Тем не менее, для моделей с цензурированными данными и моделей со скрытыми переменными наиболее быстрым и эффективным, с точки зрения объема вычислений, считается итерационный метод Ньютона-Рафсона.

\subsection{Метод имитации отжига}

Метод имитации отжига относится к неградиентным итерационным методам, которые были рассмотрены Гоффе, Феррье и Роджерс (1994). В отличие от градиентных методов метод имитации отжига допускает снижение целевой функции, а не только её рост. Таким образом метод не попадает в ловушку постепенного движения в сторону ближайшего локального экстремума.

При заданных значениях $\hat{\theta}_s$ на $s$-том шаге меняем значение $j$-того компонента вектора $\hat{\theta}_s$ для получения новых пробных значений $\theta^{*}$

\begin{equation}
\theta^{*}_{s}=\hat{\theta}_s+ \begin{bmatrix} 0 \cdots 0 & (\lambda_{j}r_{j}) & 0 \cdot 0 \end{bmatrix}',
\end{equation}
где $\lambda_j$ это зафиксированная длина шага, а $r_j$ значение, взятое из равномерного распределения $(-1;1)$. Далее используется новое значение $\hat{\theta}_{s+1}=\theta_s^{*}$, если происходит увеличение целевой функции или, при отсутствии увеличения, проверяется  критерий Метрополиса

\begin{equation}
\exp \left( (Q_{N}(\theta^{*}_s)-Q_{N}(\hat{\theta}_s))/T_s \right) >u,
\end{equation} 
где $u$ генерируется из равномерного распределения $(0,1)$ и $T_s$ --- коэффициент масштабирования, называемый температурой. Следовательно, допустимо не только увеличение, но и уменьшение функции, с вероятностью которая падает с ростом разницы $Q_{N}(\theta^{*}_s)$ и $Q_{N}(\hat{\theta}_s)$, и растёт с ростом температуры. Понятия имитации отжига и температуры взяты из физики, по аналогии с понятием минимизации расходования тепловой энергии за счет медленного охлаждения (отжига) расплавленного металла. 

Тестирующему необходимо установить значение параметра $\lambda_{j}$. Гоффе и др. (1994) предложили периодически корректировать значения $\lambda_{j}$ так, чтобы $50\%$ всех перестановок были приняты. Значение температуры тоже нужно выбирать, и понижать температуру в ходе всего процесса итерирования. Таким образом, алгоритм заключается в поиске решения из широкого диапазона параметров, прежде чем сосредоточиться в узком диапазоне.

Метод ускоренного отжига (fast simulated annealing, FSA), предложен Сзу и Хартли (1987). Согласно этому методу случайная переменная $r_j$, значение которой равномерно и одинаково распределено на отрезке $(-1,1)$, заменяется на случайную переменную с распределение Коши $r_j$, домноженную на температуру; длину шага, $v_j$ можно фиксировать. Значение температуры $T_s$ равно значению начальной температуры, деленному на количество итераций алгоритма, где одна итерация подразумевает полный цикл по $q$ компонентам вектора $\theta$.

Кэмерон и Йоханссон (1997) исследовали и применяли метод имитации отжига в соответствии с методикой Хоровица (1992). Авторы начинали с метода ускоренного отжига и из соображений экономии времени переходили к градиентным методам (BFGS), когда незначительно меняется значение функции $Q_{N}(\cdot)$ при нескольких итерациях отжига подряд, или при большом (250) количестве итераций. В результате исследования авторы сделали вывод, что метод Ньютона-Рафсона с разными начальными значениями дает лучшие результаты, чем Ньютона-Рафсона с одним начальным значением,  а ускоренный отжиг  с разными начальными значениями --- еще лучше.

\subsection{Пример экспоненциальной регрессии}

Рассмотрим нелинейную регрессионную модель с экспоненциальным условным средним

\begin{equation}
\E[y_i|x_i] = \exp(x'_i\beta),
\end{equation}
где $x_i$ и $\beta$ --- векторы размерностью $K \times 1$. Оценка $\hat{\beta}$ нелинейного МНК минимизирует

\begin{equation}
Q_N(\beta) = \sum_i(y_i --- \exp(x'_i\beta))^2,
\end{equation}
где для упрощения обозначений умножение на $2/N$ опускается. Условия первого порядка нелинейны относительно параметра $\beta$ и нет явного решения для $\beta$. Следовательно, можно использовать градиентный метод.

Получим, что градиент и гессиан соответственно равны:

\begin{equation}
g = -2\sum_i(y_i --- e^{x'_i\beta})e^{x'_i\beta}x_i
\end{equation}
и
\begin{equation}
H = 2\sum_i\lbrace{e^{x'_i\beta} e^{x'_i\beta} x_{i}x'_{i} --- 2(y_i --- e^{x'_i \beta})e^{x'_i\beta} x_{i}x'_{i}} \rbrace.
\end{equation}
Значения $g_s$ и $H_s$, которые заданы выражениями (10.20) и (10.21), соответственно, в итерационном методе Ньютона-Рафсона (10.5) оцениваются в точке $\hat{\beta}_s$.

Более простой вариант метода Ньютона-Рафсона --- метод скоринга основан на том, что из выражения (10.18) следует что

\begin{equation}
\E[H] = 2\sum_{i} e^{x'_i\beta}e ^{x'_i\beta} x_{i}x'_{i}.
\end{equation} 

Используя $\E[H_s]$ вместо $H_s$, получим

\[
\hat{\beta}_{s+1} --- \hat{\beta}_s =\left[\sum_{i}e^{x'_i \hat{\beta}_s} e^{x'_i \hat{\beta}_s} x_{i}x'_{i} \right]^{-1} \sum_{i} e^{x'_{i}\hat{\beta}_s} x_{i} (y_i --- e^{x'_{i}\hat{\beta}_s}).
\]
Из этого следует, что $\hat{\beta}_{s+1} --- \hat{\beta}_s$ может быть посчитана с помощью МНК регрессии $(y_i --- e^{x'_i\hat{\beta}_s})$ на $e^{x'_i\hat{\beta}_s}x_i$. Что также эквивалентно регрессии Гаусса-Ньютона (10.11), поскольку $\partial{g(x_{i},\beta)}/\partial{\beta} = \exp(x'_i\hat{\beta}_s)x_i$ для экспоненциального условного среднего (10.18). Если взять $\exp(x'_i\beta) = \exp(\beta)$, то результат будет  таким же, как и в разделе 10.2.4. 

\section{Практические рекомендации}

Некоторые аспекты применения методов на практике были рассмотрены в разделе (10.2), например, критерий сходимости, модификации в виде адаптации размера шага $h$ и замена аналитической производной численной. В данном разделе представлен краткий обзор статистических пакетов, а также обсуждаются наиболее часто встречающиеся ошибки при расчете нелинейных оценок. 

\subsection{Пакеты статистических данных}

Во всех стандартных микроэконометрических пакетах, таких как Limdep, Stata, PCTSP, и SAS, заложены алгоритмы оценки стандартных нелинейных моделей, например, логит и пробит. Данные пакеты достаточно просты в применении и не требуют специальных знаний об итерационных методах или даже о модели, которая используется. Например, для логит модели может использоваться команда <<logit y x>> (по аналогии как для МНК <<ols y x>>). При записи нелинейного МНК необходимо задать функциональную форму $g(y,x)$. Оценивание должно быть быстрым и точном, для этого программа должна использовать особенности структуры модели. Например, для оценки вогнутой функции можно использовать метод скоринга.

В случае, если в статистическом пакете не предусмотрена функция для оценки отдельной модели, то необходимо писать дополнительный программный код. Необходимость в написании программы может возникнуть даже при малейших изменениях стандартной модели. Например, при наложении ограничений на параметры или использовании многоиндексных функциональных форм. Код можно написать, используя любой удобный статистический пакет или более специализированный язык программирования. Возможные варианты включают $(1)$ встроенные в статистический пакет процедуры оптимизации, которые требуют спецификации целевой функции и, возможно, ее производных; $(2)$ встроенные в статистический пакет матричные команды для расчета $A_s$, $g_s$ и итераций; $(3)$ матричный язык программирования такой, как Gauss, Matlab, OX, SAS/IML или S-Plus, и, возможно, дополнительные пакеты для оптимизации; (4) язык программирования такой, как  Fortran или C++; и $(5)$ пакет для оптимизации такой, как GAMS, GQOPT, or NAGLIB.

Первый и второй методы привлекательны, потому что они не вынуждают пользователя изучать новую программу. Первый метод особенно прост для М-оценивания, так как он требует только спецификацию подфункции $q_i(\theta)$ для $i$-того наблюдения, а не спецификации $Q_N(\theta)$. Однако на практике процедуры оптимизации для функций, которые задаются пользователем, в стандартных пакетах скорее столкнутся с проблемами расчетов, чем в случае применения специализированных программ. Более того, для некоторых пакетов второй метод может требовать изучения сложных форм матричных команд.

Для нелинейных задач третий метод является наилучшим, хотя это может требовать, чтобы пользователь изучил язык программирования с азов. В таком случае можно решить почти любую эконометрическую задачу, а методы оптимизации, которые используются в языках программирования с помощью матриц, обычно хорошие. Более того, многие авторы делают доступным код, который используется в своих работах.

Четвертный и пятый методы обычно требуют более высокого уровня сложности программ, чем третий метод. Четвертый метод может привести к более быстрым расчетам, в то время как пятый может решить большинство сложных с точки зрения расчетов оптимизационных задач.

Другие практические вопросы касаются стоимости программного обеспечения, также программного обеспечения, которым пользуются коллеги, и того факта, есть ли у этого программного обеспечения четкие сообщения об ошибках и полезные инструменты, которые позволяют бороться с ошибками, такие, как инструмент, который отслеживает пошаговое исполнение команд. Также не стоит недооценивать важность того, каким программным обеспечением пользуются коллеги.

\begin{table}[h]
\begin{center}
\caption{\label{tab:troubles} Сложности при расчетах: перечень}
\begin{tabular}{ll}
\hline 
\hline
Проблема & Проверка \\ 
\hline 
Неверно загружены данные & Посмотрите на все описательные статистики полностью. \\
Неточность расчета & Используйте аналитические производные или численные \\
& производные с другим размером шага $h$. \\
Мультиколлинеарность & Проверьте собственные значения матрицы $X'X$. \\
& Попробуйте использовать подмножества регрессоров. \\ 
Вырожденная матрица при итерациях & Попробуйте метод, который не требует обращения \\
& матрицы (например, DFP). \\
Плохие начальные значения & Попробуйте различные начальные значения. \\
Модель не идентифицируема & Тяжело проверить. Очевидная ловушка --- излишняя \\
& дамми-переменная. \\
Странные значения параметров & Включена ли константа? Сошелся ли алгоритм \\
& после интераций? \\
Разные стандартные ошибки & Какой метод был применен для расчета \\
& ковариационной матрицы? \\
\hline 
\hline
\end{tabular} 
\end{center}
\end{table}

\subsection{Вычислительные трудности}

Вычислительные трудности на практике проявляются в невозможности получения оценок параметров. Например, в сообщении об ошибке может быть сказано, что расчет невозможно произвести из-за вырожденности матрицы Гессе. Существует множество возможных причин вырожденности матрицы Гессе, информация представлена в таблице 10.2. Эти причины могут также выступать объяснением для аналогичных ситуаций, когда параметр оценен, но оценка явно является ошибочной. 

Во-первых, данные могут быть неверно прочитаны в память. Это достаточно распространенная ошибка. При обработке большого массива данных, не целесообразно выводить все данные на печать. Тем не менее, следует внимательно посмотреть описательные статистики и проверить правильность определения диапазона значений --- наличие крайне больших или маленьких значений среднего, а также очень большого или малого стандартного отклонения (в т.ч. равенство стандартного отклонения нулю, что будет означать отсутствие дисперсии). Более подробно этот вопрос рассмотрен в разделе 3.5.4.

Во-вторых, возможны ошибки вычислений. Для минимизации ошибок вычислений все расчеты должны производиться с двойной или даже с четверной точностью. В некоторых случаях следует изменить масштаб данных так, чтобы среднее и дисперсия независимых переменных были одного порядка. Например, может иметь смысл рассчитывать ежегодный доход в тысячах долларов, а не в долларах. При использовании численных производных может понадобиться изменить значение $h$ в (10.4). Следует обращать внимание какой метод применялся для вычисления функции. Например, функцию $\ln \Gamma(y)$, где $\Gamma(\cdot)$ --- гамма-функция, лучше считать с помощью специальной лог-гамма функции. Если сначала посчитать обычную гамма-функцию, а затем взять логарифм, то можно получить значительные вычислительные ошибки даже при небольшом  $y$.

В-третьих, может возникнуть проблема мультиколлинеарности. В одноиндексных моделях (см. раздел 5.2.4) мультиколлинеарность проверяется по стандартной процедуре. Можно посмотреть на корреляционную матрицу регрессоров, но она учитывает только попарные корреляции. Лучше всего использовать индекс обусловленности матрицы $X'X$,  равный корню из отношения наибольшего и наименьшего собственных значений матрицы $X'X$. Если отношение больше 100, тогда существует большая вычислительных трудностей. Для более сложных, чем одноиндексные,  нелинейных моделей, проблемы могут проявиться даже при небольшом значении индекса обусловленности. Если предполагается что мультиколлинеарность может привести к проблемам  вычислений, тогда необходимо рассмотреть возможность оценить модель используя только часть переменных, для которых ниже вероятность мультиколлинеарности. 

В-четвертых, из необратимости Гессиана во время итерацией не следует его сингулярность в точке экстремума. Для решения проблемы, наряду с методом Ньютона-Рафсона, возможно произвести расчет различными итерационными методами, например, методом наискорейшего подъема с линейным поиском или методом DFP. Отсутствие единственности максимума может быть вызвано мультиколлинеарностью.

В-пятых, возможно менять начальные значения. Итерационные градиентные методы ориентированы на расчет локального, а не глобального максимума. Для борьбы с этим возможно проводить итерации  при различных начальных значениях. Вторым способом является поиск на сетке. Теоретически оба подхода предполагают оценивание целевой функции в большом количестве точек, если  размерность вектора $\theta$ велика, однако в некоторых случаях достаточно провести детальный анализ упрощенной модели, где рассматриваются только несколько наиболее важных регрессоров.

Вместе с тем может возникнуть проблема идентифицируемости модели. Необходимым условием идентифицируемости модели является обратимость матрицы Гессе. Как и в случае линейной модели, нужно проверить, не столкнулись ли мы с ловушкой дамми-переменных, а при использовании части выборки также убедиться, что каждая из переменных используемого набора непостоянна.  Допустим, что данные отсортированы по полу, возрасту или региону, тогда проблема идентификации может возникнуть, если перечисленные переменные используются в виде дамми, а выборка состоит из данных по индивидам определенного пола, возраста или региона. Иногда для нелинейных моделей трудно определить, является ли модель идентифицируемой теоретически. Как правило в такой ситуации сначала пытаются исключить все другие потенциальные проблемы, а затем уже проводить теоретический анализ модели на идентифицируемость.

Даже после получения оценок параметров, возможно проявление проблем, поскольку в некоторых случаях невозможно рассчитать ковариационную матрицу, $A^{-1}BA'^{-1}$. Оценка ковариационной матрицы, $A^{-1}BA'^{-1}$ может не получаться, если в итерационном методе матрица Гессе $A^{-1}$ не используется в качестве взвешивающей матрицы при итерировании, как, например, в алгоритме DFP. Во-первых, необходимо проверить, что итерационный процесс сходится, а не останавливается из-за превышения количества допустимых итераций. Если итерационный процесс сходится, то следует рассчитать альтернативную оценку матрицы $A$, например, используя ожидаемый гессиан или более точные способы вычислений, можно попробовать использовать аналитическую производную вместо численной. Если и эти решения не помогают, то вычислительные трудности могут свидетельствовать о неидентифицируемости модели, бывает что неидентифицируемость проявляется на этапе вычисления оценки при использовании итерационного метода, не использующего матрицу Гессе.

Вычислительной трудностью может также восприниматься несовпадение оценок параметров и дисперсий с априорным мнением. Анализ полученной оценки параметра подразумевает проверку правильности выбора модели (включение или исключение свободного члена, в зависимости от ситуации), проверку сходимости и проверку того, что был достигнут глобальный, а не локальный экстремум (это можно сделать выбрать различные стартовые значения). Стандартные ошибки, рассчитанные в нескольких статистических пакетах могут отличаться, даже если оценки параметров совпадают, поскольку существует отличие в построении вариационной матрицы (см. раздел 5.5.2).

Хорошей методологией расчетов считается начать с выборки небольшого размера и количества регрессоров, например, 1 регрессор и 100 наблюдений. Это упрощает трассировку программы вручную, например программа может печатать ключевые показатели на каждом шаге, или с помощью встроенной функции пошагового исполнения, если статистический пакет это позволяет. Если программа проходит такой тест, то велика вероятность, что вычислительные трудности с полной моделью на полном наборе данных вызваны не ошибками при чтении данных или ошибками в коде, а являются истинными вычислительными трудностями, вызванными мультиколлинеарностью или плохим выбором стартовых значений.

Программу возможно протестировать построив ряд симуляционных данных, где истинные значения параметров известны. Для выборки большого размера, где $N=10,000$, оцененные значения параметров должны быть близки к истинным значениям. 

В заключении следует отметить, что правдоподобная оценка нелинейной модели еще не говорит о правильности расчета. Например, во многих ранее опубликованных работах представлен правдоподобный результат оценки пробит-модели множественного выбора, однако, позже было установлено, что модель не идентифицируема (см. раздел 15.8.1).


\section{Библиографические заметки}

Проблемы с расчетами могут возникнуть даже в линейных моделях, и очень полезно ознакомиться с работами Дэвидсона и МакКиннона (1993, раздел 1.5) и Грина (2003, приложение E). Стандартные ссылки на работы о статистических вычислениях --- работы Кеннеди и Джентла (1980) и особенно Пресса и других (1993), а также другие книги Пресса в соавторстве. У Абрамовица и Стегуна (1971) изложены вопросы вычисления функций. Квандт (1983) описывает много вопросов, связанных с вычислениями, включая оптимизацию.

\begin{enumerate}
\item [$5.3$] Описание итерационных методов приведено у Амэмия (1985, раздел 4.4), Дэвидсона и МакКиннона (1993, раздел 6.7), Маддалы (1977, раздел 9.8) и особенно Грина (2003, приложение E.6). Харви (1990) приводит много применений алгоритма Гаусса-Ньютона, который, благодаря своей простоте, является стандартным итерационным методом при оценивании с помощью нелинейного МНК. Чтобы изучить EM алгоритм, можно обратиться к работе Амэмия (1985, с. 375–378). Алгоритм имитации отжига хорошо описан у Гоффе и других (1994).
\end{enumerate}

\begin{center}
Упражнения
\end{center}

\begin{enumerate}
\item [$10 --- 1$] Найдите оценку коэффициента регрессии в логит-модели по методу максимального правдоподобия, где единственной независимой переменной в модели является константа. Тогда $\E[y]=1/(1+e^{-\beta})$ и градиент масштабированной логарифмической функции правдоподобия будет вычисляться по формуле $g(\beta)=(y-1/(1+e^{-\beta}))$. Предположим, что выборочное среднее значение $\bar{y}$ равно 0.8 и начальное значение $\beta=0.0$.
\begin{enumerate}
\item Расчитайте значение коэффициента $\beta$ для шести первых итераций по алгоритму Ньютона-Рафсона.
\item Рассчитайте шесть первых итераций с использованием метода градиента, предполагая, что $A_s=1$ (10.1) и $\hat{\beta}_{s+1}=\hat{\beta}_s+g_s$.
\item Сравните результаты, полученные в пунктах $(a)$ и $(b)$.
\end{enumerate}


\item [$10 --- 2$] Рассмотрим нелинейную регрессионную модель $y = \alpha{x_1}+\gamma/(x_2-\delta)+u$, где $x_1$ и $x_2$ экзогенно-заданные величины с нормально-распределенными независимыми ошибками $u \sim \mathcal{N}[0,\sigma^2]$.
\begin{enumerate}
\item Выведите уравнение для вычисления параметров $(\alpha, \gamma, \delta)$  алгоритмом Гаусса-Ньютона.
\item Выведите уравнение для вычисления параметров $(\alpha, \gamma, \delta)$ алгоритмом Ньютона-Рафсона.
\item Объясните, почему важно аккуратно выбирать начальные значения для параметров?
\end{enumerate}

\item [$10 --- 3$] Предположим, что функция плотности  $y$ является смесью распределений, $f(y|\pi) = \sum_{j=1}^C \pi_j f_j(y)$, где $\pi = (\pi_1, \dots, \pi_C)$, $\pi_j > 0$, $\sum_{j=1}^C \pi_j = 1$. $\pi_j$ --- это неизвестные веса, в то время как предполагается, что параметры плотностей $f_j(y)$ известны.
\begin{enumerate}
\item Если дана случайная выборка $y_i$, $i = 1, \dots, N$ выпишите общий вид логарифма функции правдоподобия и выпишите условие первого порядка $\hat{\pi}_{ML}$. Проверьте, что для $\hat{\pi}_{ML}$ нет решения в явном виде.
\item Пусть $z_i$ --- это вектор скрытых качественных переменных размера $C \times 1$ $i = 1, \dots, N$ таких, что $z_{ji} = 1$, если $y$ получен из $j$-той компоненты, и $z_{ji} = 0$ в противном случае. Выпишите функцию правдоподобия с помощью наблюдаемых и скрытых переменных, предполагая, будто скрытые переменные являются наблюдаемыми.
\item Предложите EM алгоритм для оценивания $\pi$. [Подсказка: если $z_{ji}$ были бы наблюдаемы, то ММП-оценка $\hat{\pi}_j = N^{-1} \sum_i z_{ji}$. На шаге $E$ необходимо также рассчитать $\E[z_{ji}|y_i]$, а на шаге $M$ надо заменить $z_{ji}$ на $\E[z_{ji}|y_i]$ и потом решить это уравнение относительно $\pi$.]
\end{enumerate}


\item [$10 --- 4$] Предположим, что $(y_{i1}, y_{i2})$, для $i = 1,\dots,N$ имеют двумерное нормальное распределение с заданными средними значениями $(\mu_1, \mu_2)$, параметрами ковариации $(\sigma_{11}, \sigma_{12}, \sigma_{22})$ и коэффициентом корреляции $\rho$. Предположим, что для $y_1$ доступны все $N$ наблюдений, в то время как для $y_2$ доступно только $m$ наблюдений, где $m<N$. При условии, что безусловное частное распределение $y_i$ является нормальным, а условное распределение задано как $y_j \sim \mathcal{N} [\mu_j, \sigma_{jj}]$, $y_2|y_1 \sim \mathcal{N}[\mu_{2.1}, \sigma_{22.1}]$, где $\mu_{2.1}=\mu_2+\sigma_{12}/\sigma_{22}(y_1-\mu_1)$, $\sigma_{22.1}=(1-\rho^2)\sigma_{22}$, разработайте алгоритм нахождения пропущенных значений $y_1$ методом максимизации ожиданий (EM).
\end{enumerate}

