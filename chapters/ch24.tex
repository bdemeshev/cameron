
\part{Дальнейшие темы}

\noindent В эмпирической работе часто приходится сталкиваться не с одной проблемой с данными, а с несколькими, и работать с ними надо одновременно. К примерам таких проблем можно отнести неслучайность выборки, кластеризацию наблюдений, ошибки измерения и пропущенные данные. Когда они случаются, по отдельности или одновременно, в контексте моделей, обсуждавшихся в частях 4 и 5, могут возникнуть проблемы с оценкой интересующих нас параметров. Три главы в части 6 --- главы 24, 26 и 27 --- анализируют последствия таких проблем и представляют методы борьбы с ними. Методы проиллюстрированы и использованием примеров из более ранних частей книги. Это позволяет связать часть 6 с другими частями книги. 

Глава 24, которая рассматривает особенности данных из сложных опросов, в особенности стратифицированные выборки и кластеризацию, дополняет темы, рассмотренные в главах 3, 5 и 16. Глава 26 посвящена ошибкам измерения в моделях, изученных в главах 4, 14 и 20. Глава 27 является в достаточной степени автономной. Она посвящена проблеме пропущенных данных и восстановлению данных, но использование EM-алгоритма и семплирования по Гиббсу создает точки соприкосновения с главами 10 и 13 соответственно. 

Глава 25 посвящена оценке воздействия. Это широкий термин, который относится к воздействию одной переменной, к примеру образования, на результирующую переменную --- к примеру, на доход. Переменные воздействия могут быть выбраны экзогенно или определены эндогенно. Тема оценки воздействия затрагивает такую проблему, как идентифицируемость влияния на результирующую переменную. Влияние может измеряться предельными эффектами или функциями предельных эффектов. Здесь используются различные методы, включая инструментальные переменные и метод подбора контрольной группы по индексу соответствия. Данная проблема может возникать в контексте любой модели из рассмотренных в частях 4 и 5. Данная глава делает акцент на линейной регрессионной модели, и может быть изучена на раннем этапе знакомства с книгой. Однако, она предполагает, что читатель будет знаком со многими другими темами, рассмотренными в книге, включая инструментальные переменные и модели выбора, поэтому данный вопрос рассматривается только в в последней части книги. 


\chapter{Стратифицированные и кластеризованные выборки}

\section{Введение}

Исследования в области микроэконометрики обычно проводятся на данных, собранных путём опроса выборки из интересующей нас генеральной совокупности. Самое простое статистическое предположение, используемое по отношению к данным опросов --- это \bfseries простой случайный отбор (simple random sampling, SRS) \mdseries, согласно которому все элементы генеральной совокупности имеют равные вероятности попадания в выборку. В таком случае разумно базировать выводы на предположении, что переменные ($y_i,x_i$) не зависят от $i$ и одинаково распределены. Это предположение лежит в основе свойств рассмотренных в этой книге оценок, которые они имеют на малых выборках и в асимптотике, за важным исключением моделей с самоотбором выборки в главе 16. 

На практике, однако, условия простого случайного отбора практически никогда не выполняются для данных опросов. Вместо этого используются другие способы формирования выборки, позволяющие снизить расходы на проведение опроса и повысить точность оценок для тех подгрупп из генеральной совокупности, которые представляют особый интерес. 
К примеру, при проведении опроса домохозяйств генеральная совокупности может быть сперва разделена по географическому признаку на подгруппы, к примеру, отдельные деревни или города, с разными долями в выборке для разных подгрупп. При проведении интервью могут опрашиваться домохозяйства, сконцентрированные, к примеру, в одном квартале. Очевидно, что данные  ($y_i,x_i$) теперь не являются независимыми и одинаково распределенными. Во-первых, распределение  ($y_i,x_i$) может изменяться в зависимости от подгруппы, что противоречит предположению об одинаковом распределении. Во-вторых, так как показатели могут коррелировать для домохозяйств из одной местности, предположение о независимости  ($y_i,x_i$) также нарушается. 

Отсюда следует необходимость адаптации стандартных методов получения распределений оценок, а свойства оценок могут отличаться от полученных в предположении простой случайной выборки. Именно это и является предметом изучения в данной главе. 

Можно выделить следующие последствия для регрессионных моделей. Во-первых, если цель работы --- изучение генеральной совокупности, а не её подгрупп, могут понадобиться взвешенные оценки, чтобы скорректировать коэффициенты на доли подгрупп в выборке. Во-вторых, взвешивание может быть не нужно, если изучается регрессия $y$ на $x$, при условии, что зависимость $y$ от заданного $x$ правильно специфицирована и стратификация проводилась не по зависимой переменной. 
В-третьих, если выборка хотя бы частично определяется значениями зависимой переменной, к примеру, если доля людей с низкими доходами в ней завышена, и доход является зависимой переменной, необходимо использовать взвешенную регрессию. Здесь возможно использование разных процедур оценки, часть из которых была рассмотрена в главе 16 в контексте смещения самоотбора выборки. В-четвертых, кластеризация как минимум приводит к серьезным занижениям в оценках стандартных ошибок, и может даже оказаться причиной несостоятельности оценок параметров, если не учитывать её влияние при помощи методов, похожих на представленные в главе 21 для анализа панельных данных. 

Самый важный вывод для большинства микроэконометрических приложений заключается в том, что, при использовании данных опросов, необходимо учитывать кластеризацию. Кластеризация наблюдений часто встречается как в пространственных, так и в панельных данных и является следствием $(1)$ устройства выборки, $(2)$ устройства эксперимента или $(3)$ метода сбора данных. Примером $(1)$ является комплексный крупномасштабный опрос, в котором используется выборка из географических кластеров с целью уменьшения стоимости проведения исследования. Примером $(2)$ может служить случайный эксперимент, в котором к индивидам из одного места (к примеру, школы или завода) применяется одинаковое воздействие. К примерам $(3)$ можно отнести регрессии по структурным данным, где в число регрессоров входят групповые средние (такие как безработица или налоги на уровне государства), панельные данные и данные по близнецам, даже если в них нет кластеризации домохозяйств. 

Часть 24.2 представляет некоторые концепции и терминологию. Части 24.3 --- 24.5 рассматривают три основных свойства опросных данных: веса в выборке, стратификацию и кластеризацию. В части 24.6 рассматриваются иерархические линейные модели со стратификацией и кластеризацией. Приложение приводится в части 24.7. Комплексные опросы рассматриваются более подробно в части 24.8. 

\section{Формирование выборки}

Формирование выборки для опросов --- хорошо изученная в статистической литературе тема, потому что данные должны быть собраны до проведения анализа, а сам сбор данных может быть очень затратным. Литература на эту тему, как правило, концентрируется на способах получить с минимальными затратами выборку, по которой можно получить несмещенные и достаточно точные оценки параметров генеральной совокупности, особенно средних. 

Структура многоэтапного опроса была описана в разделе 3.2. Текущее обследование населения (Current Population Survey, CPS) США --- отличный пример такого устройства выборки. 

\subsection{Текущее обследование населения}

Текущее обследование населения, CPS --- ежемесячный опрос с охватом в приблизительно 56 тысяч домохозяйств, нацеленный на репрезентативное представление гражданского неинституционального населения в возрасте от 16 лет. Домохозяйства из небольших штатов перепредставлены, чтобы обеспечить надёжность данных на уровне штата. Внутри штатов домохозяйства кластеризованы, чтобы уменьшить расходы на проведение интервью. Они опрашиваются в течение четырех месяцев подряд, не опрашиваются следующие 8 месяцев, и затем опрашиваются ещё 4 месяца. Повторное интервьюирование позволяет снизить издержки, а схема 4-8-4 позволяет проводить анализ во временном разрезе, в том числе исследовать годовые разности. Есть 8 ротационных групп одинакового размера, каждый месяц одна из них вводится в исследование. Рассмотрим устройство одной группы. 

Выделяется 792 страты, каждая из которых соответствует части штата или, в некоторых случаях, всему штату. Все 792 страты делятся на 2007 первичных единиц выборки (Primary Sampling Units, PSU), которые могут представлять собой городской статистический регион (Metropolitan Statistical Area, MSU), пересечение штата и MSU, если MSU покрывает больше одного штата, отдельное графство или несколько смежных графств. Отклонения от этой схемы возможны, когда в PSU попадает мало населения или очень большая территория. В среднем в одной страте 2.5 PSU. Из 792 страт, 432 содержат только одно PSU, в таком случае PSU называют само-преставленным (self-representing) и его всегда включают в опрос. Остальные 360 страт содержат больше одного PSU, и в этом случае выбирается только один PSU из страты с вероятностью, пропорциональной населению по данным на 1990 год. 

Внутри PSU нет промежуточных вторичных единиц выборки. При проведении опроса напрямую отбираются конечные единицы выборки (Ultimate Sampling Units, USU), которые представляют собой географически компактные группы из примерно четырех точек. Вероятность попадания в выборку возрастает, если вероятность выбора данного PSU из своей страты была низкой и, как правило, возрастает, если PSU находится в маленьком штате, чтобы обеспечить перепредставленность штатов с небольшим населением. В этих расчётах Нью-Йорк и Лос-Анджелес рассматриваются как отдельные штаты. Все домохозяйства в USU опрашиваются, кроме случаев, когда в USU входит нетипично большое количество домохозяйств --- тогда случайным образом выбирается подмножество из домохозяйств. 

Текущее обследование населения CPS, устроено таким образом, чтобы обеспечивать само-взвешивание по штатам, то есть, несмотря на использование неслучайной выборки, CPS сохраняет репрезентативность выборок для каждого штата. Однако, невзвешенная выборка не репрезентативна в в рамках всей страны из-за перепредставленности штатов с маленьким населением и из-за того, что не все PSU входят в выборку. 

\subsection{Организация выборки}

Перед тем, как перейти к более детальному рассмотрению устройства выборок для опросов, мы приводим краткий обзор основ организации выборки в отсутствии таких осложнений, как стратификация. 

Обозначим как $z$ вектор переменных, без разделения на зависимые переменные и регрессоры. Мы предполагаем, что $z$ независимы и одинаково распределены с плотностью $f(z)$. Размер генеральной совокупности $N^*$, размер выборки $N$. Выборка --- это $\{ z_i,i=1,\ldots,N \}$, где $i$ обозначает $i$-ый элемент выборки. Стандартное обозначение в литературе, посвященной формированию выборок --- $n$ для размера выборки и $N$ для размера генеральной совокупности. Мы, однако, продолжим использовать $N$ для обозначения размера выборки, потому что необходимость использовать размер генеральной совокупности $N^*$ возникает редко. 

\subsection*{Исчерпывающий отбор}

При \bfseries исчерпывающем отборе\mdseries каждый элемент из генеральной совокупности входит в выборку, соответственно, выборка совпадает с генеральной совокупностью. Такой отбор встречается очень редко при использовании данных на уровне индивидов. Исчерпывающий отбор может иметь место при использовании данных переписей населения, таких, как перепись, проводимая в США каждые 10 лет. Но даже для переписей, более длинные опросники используются при опросе только части населения, исследователи могут предпочесть работы с более удобной для них подвыборкой, да и покрытие переписи на практике не бывает полным. Исчерпывающий отбор более распространен при использовании данных уровня фирм, когда, к примеру, можно выделить и изучить все фирмы отрасли. 

При использовании исчерпывающего отбора может возникнуть дискуссия о том, оправданно ли использование стандартных методов, если выборочные моменты совпадают с моментами по генеральной совокупности. Как правило, методы используются те же самые, просто конечная генеральная совокупность рассматриваются, в свою очередь, как выборка из бесконечной суперсовокупности (superpopulation).

К примеру, предположим, что мы изучаем гендерные различия в оплате труда на рабочем месте, где вся генеральная совокупность состоит из 20 мужчин и 12 женщин, выполняющих сходные задачи. Взяв заработные платы всех мужчин и женщин, так, что выборка совпадает с генеральной совокупностью, мы получили, что средняя заработная плата для мужчин выше, чем для женщин. В таких ситуациях мы обычно проводим стандартные тесты на значимость различий в средней заработной плате вместо того, чтобы со $100\%$ уверенностью заключить, что мужчины получают больше. Это объясняется тем, что мы рассматриваем генеральную совокупность людей, работающих в этом месте, как выборку из суперсовокупности всех рабочих мест или суперсовокупности из этого места в разные моменты времени. 

Исчерпывающий отбор --- дорогая и зачастую ненужная для больших совокупностей процедура, кроме случаев, когда необходимо определить непосредственно размер генеральной совокупности. Поэтому, как правило, используются выборки.  

\subsection*{Простой случайный отбор}

\bfseries Простой случайный отбор\mdseries  --- такой отбор, при котором наблюдения извлекаются из генеральной совокупности случайно и с равной вероятностью. Каждое наблюдение попадает в выборку с вероятностью, равной размеру выборки делённому на размер совокупности, и в пределе имеет такую же плотность $f(z)$. Он называется <<простым>>, потому что более сложные методы как правило также сохраняют элемент случайности. 

\subsection*{Коррекция на конечность выборки}

В эконометрическом анализе обычно предполагается, что при простом случайном отборе отдельные $z$ независимы, поэтому совместная плотность в выборке равна произведению индивидуальных плотностей $f(z_i)$. Это оправданно, если отбор производится из бесконечной совокупности, как в случае, когда мы рассматриваем выборку из суперсовокупности, или если отбор производится из конечной генеральной совокупности с возвращением.

На практике для конечных генеральных совокупностей используется \bfseries выборка без возвращения\mdseries, чтобы одно и то же наблюдение не попадало в выборку дважды. Тогда наблюдения больше не являются независимыми, даже при простом случайном отборе. Чтобы убедиться в этом, заметим, что при простом случайном отборе для любого элемента генеральной совокупности вероятность попасть в выборку равна $N/N^*$. Однако, зная, что данный элемент попал в выборку, вероятность попасть в выборку для любого другого элемента падает до $(N-1)/(N^*-1)$. Условная вероятность отличается от безусловной вероятности. Более формально, можно ввести переменные-индикаторы, показывающие для каждого элемента генеральной совокупности, вошёл ли он в выборку. Эти переменные имеют совместное мультиномиальное распределение со средними $\pi$, дисперсиями $\pi(1-\pi)$ и ковариациями $-\pi(1-\pi)/(N^*-1)$, где $\pi=N/N^*$.

Корреляция между наблюдениями в выборке $\rho = -1/(N^*-1)$, где $\rho$ называют \bfseries межклассовой корреляцией\mdseries. Полагая $z$ скаляром, получаем, что выборочное среднее $\overline{z} = N^{-1} \sum_i z_i$ имеет дисперсию $\V[\overline{z}] = N^{-2} \V[\sum_i z_i]$, которая не упрощается до $N^{-2} \sum_i \V[z_i]$ из-за корреляции между $z_i$. Вычисления, приведённые, к примеру, у Кохрана (1977, c. 23 --- 24) показывают, что 
$$\V[\overline{z}] = (1-f) \frac{S^2}{N},$$
где $f = N/N^*$ --- доля выборки. Результаты, полученные здесь, обычно проще представить в терминах $S^2 = (N^*-1)^{-1}\sum(z_i --- \overline{z})^2$, чем через обычную дисперсию  $\sigma^2 = N^{*-1}\sum(z_i --- \overline{z})^2$. 

Таким образом, для выборки без возвращения из конечной совокупности, дисперсия выборочного среднего равна стандартному $S^2/N$, умноженному на \bfseries коэффициент коррекции на конечность выборки \mdseries $1-f$. Этот коэффициент коррекции присутствует в статистических пакетах, ориентированных на данные опросов. Неучет коэффициента коррекции приводит к переоценке $\V[\overline{z}]$. Для регрессий при использовании данных с возвращением, коррекция на конечность выборки также необходима, однако величина и направление смещения в оценке дисперсии, получаемой МНК, теперь дополнительно зависит от матрицы независимых переменных. 

Коррекция на конечность выборки, как правило, игнорируется в микроэконометрике, и часто это оказывается разумным. К примеру, для опросов домохозяйств размер выборки настолько мал по сравнению с размером генеральной совокупности, что $f = N/N^* \to 0$.

\section{Взвешивание}

Опросы домохозяйств, такие как Текущее обследование населения, CPS, обычно конструируются так, что разные домохозяйства в итоге попадают в выборку с разными вероятностями. Чтобы скорректировать этот эффект, каждому наблюдению в выборке присваивается свой вес. 

Как показано ниже, при экзогенной стратификации веса нужно использовать, если регрессия используется для описания генеральной совокупности и не нужно использовать, если предполагается, что регрессионная модель соответствует истинной структурной модели. 

\subsection{Веса в выборке}

Пусть каждое домохозяйство в генеральной совокупности имеет вероятность $\pi_i$ попадания в выборку и предположим, что (в отличие от простого случайного отбора) эта вероятность не является одинаковой для всех домохозяйств. 

Тогда статистики, такие как средние по всей выборке, придающие одинаковый вес всем наблюдениям, будут завышать вес тех домохозяйств, которые попадают в выборку с большей вероятностью. Это может быть скорректировано взвешиванием с использованием \bfseries выборочных весов\mdseries, обратно пропорциональных вероятности включения в выборку:

\begin{equation}
\label{eq24.1}
w_i \propto 1/\pi_i.
\end{equation}
К примеру, вместо $\overline{z} = N^{-1} \sum_i z_i$ мы можем использовать взвешенное среднее:

$$\overline{z}_W = N^{-1} \sum_i w_iz_i/\sum_iw_i$$
Заметим, что в~(\ref{eq24.1}) важна только пропорциональность. Сумма весов не обязательно должна равняться единице, если мы делим на сумму весов. Для удобства масштабирования часто используется $\sum_iw_i = N^*$. В этом случае вес $w_i$ означает, что данное наблюдение представляет $w_i$ наблюдений из генеральной совокупности. Важно отметить, что при использовании весов нужно соблюдать осторожность. Иногда $w_i$  определяются как $w_i \propto \pi_i$, а некоторые компьютерные пакеты рассчитывают взвешенное среднее как $\sum_i w_iz_i/\sum_i(1/w_i)$. При использовании обратных выборочных весов легко ошибиться и взвесить неправильно. 

При использовании простой случайной выборки размера $N$ из конечной генеральной совокупности размера $N^*$ получаем $\pi_i = 1/N^*$, $w_i$ --- константы и $\overline{z}_W = \overline{z}$. 

Для \bfseries простой стратифицированной выборки \mdseries с простым случайным отбором  внутри страт, предположим, что в страту $s$ входит доля $H_s$ генеральной совокупности размера $N^*$, а в выборку входит $N_s$ наблюдений из этой страты. Тогда  $\pi_i = N_s/H_sN^*$. Соответственно, выборочные веса $w_i \propto H_s/N_s$. 

При \bfseries двухшаговом отборе без стратификации \mdseries пусть $\pi_c$ --- вероятность, что выбран $c$-ый PSU и $\pi_{jc}$ --- вероятность, что в PSU $c$ было выбрано домохозяйство $j$. Тогда выборочные веса $w_i \propto 1/(\pi_c N_c \pi_{jc} N)$, где $N_c$ --- количество опрошенных домохозяйство в PSU $c$ и $N = \sum_c N_c$. Двухшаговый отбор является \bfseries самовзвешивающим \mdseries, если выборочные вероятности на каждом шаге пропорциональны долям в генеральной совокупности, поэтому $\pi_c = N^*_c/N^*$ и $\pi_{jc} = 1/N^*_c$, где $N^*_c$ --- размер генеральной совокупности в $c$-ом PSU. Тогда веса $w_{jc}$ оказываются равными, как и в случае простого случайного отбора, но стандартные ошибки по-прежнему могут нуждаться в коррекции, как будет показано в части 24.8. 

Для Текущего обследования населения, CPS, где перепредставлены домохозяйства из маленьких штатов, может оказаться достаточным использовать $w_i \propto H_s / N_s$, где $s$ обозначает штат. В Текущем обследовании населения это используется в качестве базового веса, после чего ещё проводится коррекция на уровне USU если в USU входит слишком много домохозяйств. Следующая трудность заключается в том, что в страте опрашиваются не все PSU, а опрошенные домохозяйства могут быть нерепрезентативными для своей страты, если изучаемые PSU значительно отличаются от страты в целом. Поэтому осуществляются две дополнительные корректировки. Во-первых, это коррекция на нерепрезентативность расового состава на уровне страты. Во-вторых, веса корректируются так, чтобы выборочные оценки основных подгрупп (сформированных по штату, расе, полу и возрасту) совпадали с независимыми данными о составе населения. Более детальную информацию можно получить с помощью Бюро переписи населения США (U.S. Bureau of Census, 2002). Веса в Текущем обследовании населения, CPS, учитывают отличия состава выборки от состава генеральной совокупности по географическому расположению (штату), расе, полу и возрасту и составлены так, чтобы опрос был репрезентативен на национальном уровне. 

На практике вычисление выборочных весов для многоэтапных опросов может быть очень сложным процессом. Оценка весов может быть неправильной, но даже если они оценены корректно, они могут не принимать во внимание часть показателей, по которым выборка оказывается нерепрезентативной. 

\subsection{Взвешенная регрессия}

Нужно ли использовать взвешенную регрессию в случае, когда известны выборочные веса? Рассмотрим этот вопрос для случая, когда стратификация проводится не по зависимой переменной. Случай, когда стратификация проводится по зависимой переменной, рассмотрен в разделе 24.4. 

Рассмотрим оценку линейной регрессии

\begin{equation}
\label{eq24.2}
y_i = x'_i\beta + u_i.
\end{equation}
по данным опроса с известными выборочными весами $w_i$. В этом случае возможны две оценки: МНК

\begin{equation}
\label{eq24.3}
\hat \beta_{OLS} = (X'X)^{-1}X'y,
\end{equation}
и взвешенного МНК с использованием выборочных весов

\begin{equation}
\label{eq24.4}
\hat \beta_{WLS} = (X'WX)^{-1}X'Wy,
\end{equation}
где $W = \Diag[w_i]$. 

\subsection*{Правильно специфицированное условное математическое ожидание}

Оценка МНК работает, если предполагается, что $\E[u|x] = 0$. Тогда условное математическое ожидание линейно по $x$:

\begin{equation}
\label{eq24.5}
\E[y_i|x_i] = x'_i\beta.
\end{equation}
В этом случае оценка $\beta$ методом наименьших квадратов является состоятельной. Более того, она является эффективной по теореме Гаусса-Маркова, если ошибки $u_i$ гомоскедастичны. Оценка взвешенного МНК $\beta$ также состоятельна, но неэффективна, если ошибки гомоскедастичны (в силу того, что взвешивание в~(\ref{eq24.5}) учитывает нерепрезентативность выборки, но не гетероскедастичность). 

\subsection*{Неправильно специфицированное условное математическое ожидание}

Во многих приложениях~(\ref{eq24.5}) не выполняется. В качестве примера можно привести такие случаи, как пропущенные переменные, ситуации, где $\E[y|x]$ нелинейно по $x$ или где $\E[y_i|x_i] = x'_i \beta_i$ но некоторые компоненты в $\beta_i$ коррелируют с $x_i$. Линейная регрессия по-прежнему может интерпретироваться как наилучший линейный прогноз $y$ для заданного $x$ при квадратичной функции потерь, но требует адаптации для случая нерепрезентативной выборки. 

В выборке $(y_i, x_i)$ являются независимыми и одинаково распределенными. Мы можем записать (см. раздел 4.2)

$$y_i = X'_i \beta^* + u_i,$$
где $\E[u]=0$, $\Cov[x,u] = 0$ и
$$\beta^* = \left( \E[xx'] \right) ^{-1} \E[xy]. $$
Заметим, что мы больше не предполагаем $\E[u|x] = 0$, поэтому возможно, что $\E[y|x] \ne x'\beta$. 

Параметр $\beta^*$ называется \bfseries коэффициентом ценза, \mdseries он был предложен в работе Дюмушеля и Дункана (1983). Это предел по вероятности коэффициента из регрессии $y$ на $x$, который был бы получен при оценке модели на всей генеральной совокупности, а не на нерепрезентативной выборке. 

Если условное математическое ожидание нелинейно по $x$ и выборка непрепрезентативна, оценка метода наименьших квадратов в общем случае не сходится к $\beta^*$, потому что полученные по нерепрезентативной выборке $N^{-1}X'X$ не сходятся к истинным моментам $\E[x'x]$ и, аналогично, нет сходимости для $N^{-1}X'y$. Интуитивно понятно, что если условное среднее нелинейно по $x$, нет оснований верить, что линейные регрессии, оцененные по разным выборкам из одной генеральной совокупности, дадут одинаковые оценки. 

Однако взвешенного МНК с использованием выборочных весов может дать состоятельную оценку $\beta^*$. Если матрица весов W такая, что:

\begin{align}
\label{eq24.6}
&N^{-1}X'WX \overset{p}{\to}  \E[xx'], \nonumber \\
&N^{-1}X'Wy \overset{p}{\to}  \E[xy],
\end{align}
тогда $\hat \beta _{WLS} $ из~(\ref{eq24.4}) сходится к $\beta^*$. 

\subsection*{Простые стратифицированные выборки}

Значимая часть анализа для взвешенного метода наименьших квадратов представлена для случая простых стратифицированных выборок с простым случайным отбором внутри страты. Тогда становится ясным, что~(\ref{eq24.6}) выполняется при $w_i \propto H_s / N_s$, если $i$-ое исследованное домохозяйство находится в $s$-ой страте. 

В литературе также рассматривается возможность наличия разных параметров регрессии внутри страты. Предполагается, что $\E[y_i | x_i]  = x'_i \beta_s$ для домохозяйства $i$ в страте $s$. Целью может быть оценк среднего взвешенного по генеральной совокупности параметра $\beta_W = N^{-1} \sum_s N^*_s \beta_s$. Тогда в общем случае ни МНК, ни взвешенный МНК не сходятся к $\beta_W$, кроме ситуаций, где $\beta_s$ одинаковы для всех страт или независимы и одинаково распределены с постоянным средним по стратам. Важным исключением из этого случая является оценка среднего $y$ (регрессия на константу $x = 1$), когда взвешенное среднее из выборочных средних по стратам является несмещенным относительно среднего по генеральной совокупности. Подробнее см. в разделе 24.4.1 и работы Дюмушель, Дункан (1983), Дитон (1997) или Уллах, Бройниг (1998). 

\subsection*{Нужно ли использовать выборочные веса?}

Предшествующий анализ может быть использован для ответа на вопрос, нужно ли использовать выборочные веса при оценке моделей при \bfseries отсутствии эндогенной стратификации \mdseries. Рассматривается оценка (возможно нелинейных) моделей $\E[y|x]$, но те же рассуждения пременимы и для моделей любого другого показателя, связанного с условным распределением $y$ при условии $x$, к примеру, медианы или плотности. 

Если исследователь использует \bfseries структурный \mdseries или \bfseries аналитический \mdseries подход и предполагает, что модель $\E[y|x]$ правильно специфицирована, то нет необходимости использовать выборочные веса. Результаты анализа могут использоваться для исследования эффектов изменения $x$ на $\E[y|x]$. 

Если же используется \bfseries описательный \mdseries подход или подход, отталкивающийся от данных, нужно использовать выборочные веса. Параметры регрессии в таком случае интерпретируются как коэффициенты ценза. Стоит, однако, помнить, что в для опросов со сложной структурой невозможно получить веса, которые будут соответствовать~(\ref{eq24.6}) столь же точно, как в случае стратифицированных выборок с простым случайным отбором внутри страт. На практике выборочные веса строятся в соответствии с пропорциями отдельных подргупп (по возрасту, полу и расе) в генеральной совокупности. Нет гарантии, что такие веса будут отвечать~(\ref{eq24.6}). 

Некоторые опросы, такие как относительно небольшие лонгитюдные опросы нескольких тысяч домохозяйств, разрабатываются с расчётом на структурное моделирование. Однако, они обычно стараются обеспечить репрезентативность выборки, используя при этом кластеризованный отбор для снижения издержек проведения опроса. Другие опросы, такие как Текущее обследование населения, CPS, делают упор на точность описательных статистик, таких как национальные и региональные оценки уровней безработицы. Здесь разработчики используют подход, близкий к переписям, и явно предпочли бы проводить опросы каждый месяц, если бы это не было так дорого. 

Для любого вида данных микроэконометристы обычно стараются применять \bfseries структурный подход к моделированию. \mdseries В качестве примера, рассмотрим регрессию доходов на уровень образования и социоэкономические характеристики, такие как возраст, пол и раса, но без показателей, характеризующих врожденные способности. 

Большинство эконометристов ограничатся описательной интерпретацией коэффициента при образовании в МНК регрессии из-за эндогенности образования. Интерпретироваться это будет следующим образом: если прочие регрессоры неизменны, один дополнительный год образования связан, но не обазятельно является причиной, с ростом дохода на, скажем, 6\%. Здесь использование выборочных весов в МНК регрессии нужно, чтобы трактовать полученные оценки как характеристики всей генеральной совокупности, а не просто одной, возможно нерепрезентативной, выборки. Даже при том, что никакая интерпретация с точки зрения причинности невозможна, эта оценка может быть полезна для понимания того, как доход меняется с изменением образования при фиксации некоторых основных социоэкономических переменных. В конце концов, суммирование и описание данных --- одна из целей статистики. 

Состоятельная оценка коэффициента при образовании может быть получена при использовании более продвинутых процедур оценивания, таких как инструментальные переменные или методы для панельных данных. В этом случае коэффициенту можно давать интерпретацию с точки зрения причинности. Взвешивание с использованием выборочных весов больше не нужно, тогда как обычное взвешивание для повышения эффективности, если, к примеру, ошибки гетероскедастичны, может быть полезным. 

Может ли модель считаться корректно специфицированной или нет --- важный вопрос. Если она специфирована корректно, взвешенные и невзвешенные оценки, полученные по выборке, будут сходиться по вероятности к одному и тому же пределу, потому что обе являются состоятельными. Это даёт возможность тестировать корректность спецификации тестом Хаусмана, рассматривая разницу между оценками для взвешенной и невзвешенной регрессий. Тест для линейной регрессии предложен в работе Дюмушель, Дункан (1983). 

\subsection{Прогнозирование}

Рассмотрим нелинейную регрессию с правильно специфицированным условным средним, $g(x, \beta)$ и отсутствием эндогенности. Невзвешенная оценка нелинейного МНК даёт состоятельную оценку $\beta$ и может трактоваться с точки зрения причинности. В частности, мы можем использовать $\partial g(x, \hat \beta)/\partial x$ для вычисления эффекта изменения $x$ на единицу на условное среднее. 

Этот эффект изменяется в зависимости от $x$, потому что $g(\cdot)$ нелинейна. Оценка среднего по генеральной совокупности эффекта:
$$
\hat \E\left[ \frac{\partial y}{\partial x}\right] = \sum_{i=1}^N w_i \frac{\partial g(x_i, \hat\beta)}{\partial x_i},
$$
где $w_i$ --- выборочные веса. Аналогично, если оценивать эффект для средних значений регрессоров, лучше использовать среднее взвешенное значение $x$, чем невзвешенное выборочное среднее $x$. 

Даже если полученные невзвешенные оценки параметров являются состоятельными, взвешивание может быть использовано в дальнейшем для вычисления предельных эффектов, если целью является получение эффектов для генеральной совокупности, а не для  выборки. 

\section{Эндогенная стратификация}

Стратификация широко используется, потому что она может повысить точность оценивание, или эквивалентно уменьшить расходы на проведение опроса при заданном уровне точности. К примеру, более точные оценки среднего уровня безработицы в штатах с маленьким населением может быть получено путём увеличения доли бедных штатов в выборке. По тем же причинам в выборках могут быть перепредставлены меньшинства. 

Одно из затруднений, уже рассмотренное в разделе 24.3, заключается в том, что параметры могут изменяться между стратами. К примеру, средний уровень безработицы может быть разным для разных страт. В таком случае используется описательный подход и взвешенные оценки. 

Микроэконометристы часто предпочитают структурный подход и предполагают, что параметры не изменяются от страты к страте. Тогда (см. раздел 24.3) стратификация не вызывает дополнительных затруднений и можно использовать невзвешенную регрессию. Важная оговорка заключается в том, что проблемы всё-таки возникают, если стратификация основывается на значении зависимой переменной. К примеру, если люди с низким доходом перепредставлены и доход является зависимой переменной, оценки коэффициентов становятся несостоятельными. Заметим, что если стратификация проводится по регрессорам, таким как раса, и это приводит к перепредставленности людей с низким непрямым образом, проблем не возникают. Они есть только если стратификация проводится по доходу прямым образом. 

В данном разделе мы определим эндогенную стратификацию и проанализируем возникающие при этом трудности. Потом мы представим оценки, которые будут состоятельными в такой ситуации. Самая простая из них --- это взвешенная оценка, которая может быть использована, если известны вероятности страт как в выборке, так и в генеральной совокупности. Метод представлен в разделе 24.4.5. 

\subsection{Схемы стратификации}

Для данных $z \in \mathcal Z$ страты --- это подмножества $\mathcal Z$. При проведении эконометрического анализа данные обычно разделяются на зависимую переменную $y \in \mathcal Y$, которую, в целях сохранения общности, можно считать вектором, и регроссор, или независимую переменную, $x \in \mathcal X$. Тогда страта $C_s$, $s=1, \dots ,S$ определяется как подмножество $ \mathcal Y \times \mathcal X$. Использованная здесь нотация предложена в работе Имбенс, Ланкастер (1996), где представлены замечательные примеры, воспроизведенные в таблице 24.1. 

Отбор внутри страты предполагается случайным, но некоторые страты могут быть перепредставлены. Из таблицы 24.1 становится ясно, что страты могут суммироваться во множество, большее или меньшее, чем выборочное. Для четвертой и пятой схем стратификация может проводиться только по эндогенным переменным, только по экзогенным или по смеси из них. 

Эконометрическая литература фокусируется на схемах отбора с эндогенным компонентом, потому что в этом случае обычные условные оценки метода максимального правдоподобия оказываются несостоятельными. 

Эндогенная стратификация уже рассматривалась в главе 16. В качестве примера, рассмотрим \bfseries усечённую регрессию\mdseries, где мы наблюдаем $y$ только если $y>0$, поэтому стратификация проводится только по $y$. Тогда для выборочных данных условная плотность $y$ при условии $x$ --- это усеченная в нуле плотность, которая разделяет неусеченную плотность в $\Pr[y > 0|x]$ и тогда:

$$
f^s(y|x,\theta) = \frac{f(y|x,\theta)}{1-F(0|x,\theta)},
$$
где индекс $s$ используется, чтобы отличить \bfseries выборочную плотность \mdseries, от истинной $f(y|x,\theta)$. Как отмечено в главе 16, такая схема отбора имеет тенденцию выбрасывать наблюдения с низкими значениями $y$ при заданном $x$. Предположим $\E[y|x] = \beta_1 + \beta_2 x$ и $\beta_2 > 0$. Тогда для низких значений $x$ будет слишком много относительно высоких значений $y$. Регрессия будет завышать прогнозы $\E[y|x]$ дли низких значений $x$, приводя тем самым к смещению вверх оценки свободного члена $\beta_1$ и занижению коэффициента наклона $\beta_2$. 
 
\begin{table}[h]
\caption{\label{tab:pred} Стратификация со случайным отбором внутри страты}
\begin{center}
\begin{tabular}{lll}
\hline
\hline
 Схема стратификации & Определение & Вид стратификации \\
\hline
Простая случайная & $S = 1, C_1 = \mathcal Y \times \mathcal X$ & Одна страта покрывает все выборочное пространство \\
Чистая экзогенная & $C_s = \mathcal Y \times \mathcal X_s$, где $\mathcal X_s \subset \mathcal X$ &  Стратификация только по регрессорам, \\
& & не по зависимой переменной \\
Чистая эндогенная & $C_s = \mathcal Y_s \times \mathcal X$, где $\mathcal Y_s \subset \mathcal Y$ &  Стратификация только по зависимой переменной, \\
& & не по регрессорам \\
Пополненная выборка & $S = 2, C_1 = \mathcal Y \times \mathcal X,$ & Случайная выборка, дополненная наблюдениями \\
& $C_2 \subset \mathcal Y \times \mathcal X \nonumber$ & из части выборочного пространства \\
Разделенная & $C_s \subset \mathcal Y \times \mathcal X, C_s \cap C_1 = \emptyset,$ & Выборочное пространство разбивается на \\
& $\bigcup_{s=1}^S C_s =  \mathcal Y_s \times \mathcal X.$ & непересекающиеся страты, которые покрывают \\
& & все выборочное пространство \\
\hline
\hline
\end{tabular}
\end{center}
\end{table}

Второй пример --- это \bfseries отбор, основанный на выборе \mdseries для бинарных или мультиномиальных данных, где выборки создаются на основе дискретной переменной $y$. К примеру, если выбор осуществляется между поездкой на работу на автобусе или на машине мы можем перепредставить тех, кто ездит на автобусе, если им пользуется мало людей. Этот пример рассматривается ниже. Он схож на \bfseries исследования случай-контроль \mdseries в медицинской литературе, где, к примеру, полная выборка людей, умерших от болезни ($y=1$) сравнивается с подвыборкой того же размера из всего множества людей, которые не умерли от болезни ($y=0$). Цель --- определить, может один или несколько регрессоров предсказать $y=1$. 

Близкий пример --- это счётные данные о количестве посещений, собираемые путём \bfseries отбора на месте\mdseries, к примеру, в местах отдыха, торговых центрах или в кабинетах врачей. Такие данные усечены, потому что индивиды с $y=0$ не входят в выборку, а посетители, приходящие часто, перепредставлены. Shaw (1998) показывает, что выборочное распределение данных, $f^s(y|x,\theta)$ связано с распределением по генеральной совокупности следующим образом:

\[
f^s(y|x,\theta) = f(y|x,\theta) \frac{y}{\E[y|x,\theta]}.
\]

В этом случае схема отбора очевидно становится эндогенной, несмотря на то, что она не является стратифицированной. 

\subsection{Эндогенность, вызванная стратификацией}

Схемы отбора, такие как схемы со стратификацией, ведут к тому, что функция плотности исследуемой величины в выборке отличается от плотности в генеральной совокупности. При чисто эндогенной стратификации оценке метода максимально правдоподобия остаются состоятельными, потому что условная плотность $y$ при заданном $x$ в выборке не отличается от истинной. Однако, если в стратификации есть эндогенный компонент, эти условные плотности отличаются, что было показано в предыдущих примерах. Теперь мы обсудим этот вопрос более подробно. 

Цель метода максимального правдоподобия --- это получение состоятельных оценок параметров $\theta$ в $f(y|x, \theta)$. В общем, оценки ММП базируются на на вероятности, полученной на основе совместного распределения данных $(y, x)$. На практике часто оказывается достаточно просто сформировать условную вероятность на основе условного распределения $y$ при условии $x$. Это более простой подход может дать состоятельные оценки при предположении, что $x$ экзогенен по отношению к $y$. Тогда совместная плотность представима как:

\begin{equation}
\label{eq24.7}
g(y, x|\theta) = f (y| x, \theta) \times h(x). 
\end{equation}
где параметры плотности $x$ опущено, потому что нет никакой необходимости их оценивать. 

Мы всегда можем написать $g(y, x) = f (y| x) \times h(x)$. Предположение, сделанное в~(\ref{eq24.7}) заключается в том, что параметры $\theta$ появляются в $f(y | x, \theta)$, но не появляются в $h(x)$. В общем случае, вместо~(\ref{eq24.7}) мы могли бы получить:

\begin{equation}
\label{eq24.8}
g(y, x|\theta) = f (y| x, \theta) \times h(x|\theta). 
\end{equation}
Тогда один или больше компонентов $x$ становятся эндогенными по отношению к $y$, потому что теперь появляется обратная связь --- $y$ зависит от $x$, но $x$, в свою очередь, зависит от $y$ через присутствие $\theta$ в $h(x|\theta)$. Классический пример --- это линейные одновременные уравнения. В таких случаях оценка ММП должна базироваться на \bfseries совместном правдоподобии \mdseries: 

\begin{equation}
\label{eq24.9}
\ln \mathrm{L}_{JOINT}(\theta) = \sum_{i=1}^n \ln{f(y_i|x_i, \theta)} + \sum_{i=1}^n \ln h(x_i|\theta). 
\end{equation}
Это даёт состоятельную оценку $\theta$ если, из главы 5:

\begin{equation}
\label{eq24.10}
0 = \E \left[\frac{\partial \ln{g(y, x|\theta)}}{\partial \theta} \right] = \E \left[\frac{\partial \ln{f(y | x,\theta)}}{\partial \theta} \right] + \E \left[ \frac{\partial \ln{h(x|\theta)}}{\partial \theta} \right]
\end{equation}
Условие~(\ref{eq24.10}) выполнено, если плотность $g(y, x|\theta)$ правильно специфицирована и диапазон данных не зависит от $\theta$. Условная оценка метода максимального правдоподобия максимизирует \bfseries условное правдоподобие \mdseries : 
$$
\ln \mathrm{L}_{COND}(\theta) = \sum_{i}\ln f(y_i|x_i, \theta).
$$
Оценка условного ММП состоятельна, если $\E[ \partial \ln f(y|x,\theta) / \partial \theta] = 0$. Это необходимое условие следует из~(\ref{eq24.10}) если $x$ эндогенный, так как~(\ref{eq24.10}) упрощается из-за того, что в этом случае $\partial \ln h(x) / \partial \theta = 0$. Если же $x$ эндогенный, этого упрощения не происходит, так как второй член правой части~(\ref{eq24.10}) не исчезает. Поэтому оценка условного ММП несостоятельна при эндогенном $x$. 

Проблема, которая возникает при стратификации и других схожих схемах отбора заключается в том, что даже если совместная плотность в генеральной совокупности удовлетворяет~(\ref{eq24.7}) и не изменяется по стратам, схемы отбора могут быть устроены так, что что совместная плотность $(y,x)$ в выборке принимает более общую форму:

\begin{equation}
\label{eq24.11}
g^s(y,x|\theta) = f^s(y|x,\theta) \times h^s(x|\theta),
\end{equation}
где индекс $s$ используется для того, чтобы обозначить использование определенной схемы отбора. Тогда условная оценка ММП может быть несостоятельной, даже при том, что она была бы состоятельной в случае простого случайного отбора. 

При \bfseries чистом экзогенном отборе \mdseries единственное отличие между выборочным и истинным распределениями проявляется в частном распределении $x$. Предполагая, что в генеральной совокупности выполнено~(\ref{eq24.7}), получаем, что в выборке:

$$
g^s(y,x|\theta) = f(y|x,\theta) \times h^s(x).
$$
Ясно, что условные оценки ММП будут состоятельными, так как условная плотность по-прежнему $f(y|x,\theta)$ и $\theta$ не присутствует в $h^s(x)$. 

При \bfseries эндогенном отборе \mdseries в выборке выполняется более общий результат~(\ref{eq24.11}), даже если~(\ref{eq24.7}) выполняется в генеральной совокупности. Выборочное и истинное распределения $y$ при условии $x$ могут различаться, с $f^s(y|x,\theta) \ne f(y|x,\theta)$ и возможной зависимостью $h^s(x|\theta)$ от $\theta$.  

\subsection{Эндогенный отбор}

При чистом эндогенном отборе частное распределение $y$ в выборке отличается от распределения в генеральной совокупности. Обозначим как $h(y)$ истинное распределение $y$ и как $h^s(y)$ --- выборочное распределение (совместное, условное и частное распределение мы обозначаем, соответственно, как $g$, $f$, и $h$. Читатель должен понимать, что $h(y)$ отличается от $h(x)$.)

Совместное распределение $x$ и $y$ при чистом эндогенном отборе проще получить, беря условное распределение $x$, чем $y$. Тогда:

\begin{equation}
\label{eq24.12}
g^s(y,x) = f(x|y) h^s(y).
\end{equation}
Упрощение произошло, потому что условное распределение $x$ при условии $y$ неизменно при чистом эндогенном отборе, так что $f^s (x|y) = f(x|y)$. Теперь нам надо выразить $f(x|y)$ в терминах $f(y|x)$. Теперь

\begin{equation}
\label{eq24.13}
f(x|y) = \frac{g(y,x)}{h(y)} = \frac{f(y|x)h(x)}{h(y)}.
\end{equation}
Подставляя~(\ref{eq24.13}) в~(\ref{eq24.12}) получаем

$$
g^s(y,x|\theta) = f(y|x, \theta) \times \frac{h^s(y)}{h(y|\theta)} \times h(x),
$$
где

$$
h(y|\theta) = \int g(y,x|\theta) dx = \int f(y|x,\theta) h(x) dx. 
$$
Условная оценка ММП, использующая только $f(y|x,\theta)$ будет несостоятельной, потому что член $h(y|\theta)$ будет проигнорирован. Вместо этого нужно максимизировать совместное правдоподобие, которое дополнительно включает $h(y|\theta)$. 

\subsection{Эндогенно стратифицированные выборки}

Рассмотрим теперь схемы стратификации, представленные в разделе 24.4.1. Плотность в генеральной совокупности:

$$
g(y, x| \theta) = f(y|x, \theta) h(x). 
$$
Всего есть $S$ страт, где $s$-ая страта --- подмножество $C_s$ множества $\mathcal Y \times \mathcal X$. 

Есть важное различие между вероятностью для наблюдения в генеральной совокупности попасть в $C_s$ и вероятностью попадания в выборку наблюдения из $C_s$. Определим:

\begin{align}
 &H_s = \Pr[\text{Выбрать наблюдение из} \ C_s], \nonumber \\
 &Q_s(\theta) = \Pr[ \text{Случайно выбранное наблюдение из совокупность находится в} \ C_s].
\label{eq24.14}
\end{align}
Здесь $H_s$ определяется устройством выборки, тогда как

\begin{equation}
\label{eq24.15}
Q_s(\theta) = \int_{C_s} f(y|x, \theta) h(x) dy dx. 
\end{equation}
Вероятности страт могут быть известны или неизвестны. Страта считается перепредставленной, если $H_s > Q_s$. 

Мы начнём с получения совместной плотности $s$, $y$ и $x$, где $s$ --- это индикатор для страты, из которой берётся наблюдение. В генеральной совокупности

$$
g(s,y,x|\theta) = Q_s(\theta) g(y,x|s, \theta). 
$$
В выборке, частное распределение индикатора страты отличается от $Q_s$ и

$$
g^s(s,y,x|\theta) = H_s g(y,x|s,\theta) = H_s \frac{f(y|x,\theta)h(x)}{Q_s(\theta)},
$$
где второе равенство выполняется в силу того, что $g(y,x|s)$ равно плотности $g(y,x) = f(y|x) h(x)$, делённой на вероятность попадания в страту $s$ в генеральной совокупности, так что плотность интегрируется по $C_s$ к единице. 

Следовательно, совместная плотность

\begin{equation}
\label{eq24.16}
g^s(s,y,x|\theta) = \frac{H_s}{Q_s(\theta)} f(y|x, \theta) h(x),
\end{equation}
где $Q_s(\theta)$ определяется из~(\ref{eq24.15}). Условная оценка ММП, базирующаяся на истинной условной плотности $f(y|x,\theta)$, будет несостоятельной для $\theta$, потому что она игнорирует член $Q_s(\theta)$, который зависит от $\theta$. 

Можно предложить ряд состоятельных оценок. Здесь мы рассмотрим оценки методом максимального правдоподобия, оценки обобщённого метода моментов и более простые взвешенные оценки, которые могут быть получены при знании вероятностей попадания в страту и для выборки $H_s$ и для генеральной совокупности $Q_s(\theta)$. 

\subsection*{Оценки метода максимального правдоподобия}

Построение ММП-оценки на основе совместной плотности $g^s(s,y,x|\theta)$ в~(\ref{eq24.16}) может быть затруднено, потому что, как следует из~(\ref{eq24.15}), распределение $Q_s(\theta)$ зависит от $h(x)$. Одно из возможных решений заключается в спецификации плотности $h(x)$. Такой подход не используется, потому что эконометристы стараются избегать спецификации распределений регрессоров, даже когда хотят специфицировать условное распределение зависимой переменной. 

Вместо этого используется полупараметрический подход, цель которого --- оценить параметры специфицированной плотности $f(y|x, \theta)$, не специфицируя плотность $h(x)$. Для простоты предположим, что мы знаем вероятности $H_s$. Косслетт (1981a) получил оценку ММП с эндогенной стратификацией, сперва разрешив $x$ быть дискретным с вероятностью $w_i$ того, что случится $x_i$, и максимизируя совместное правдоподобие по $\theta$ и $w_i$, $i = 1, \dots , N$. Условия первого порядка могут быть сведены к концентрированному правдоподобию, в котором будет только $(q+S-1)$ параметров $\theta$ и фукнций $\lambda_s(\theta), s = 1, \dots, S-1$. Далее концентрированное правдоподобие максимизируется по $\theta$ и $\lambda_s$ и получаются те же оценки, что и при максимизации по $\theta$ и $\lambda_s(\theta)$. Затем, так как можно трактовать $\lambda_s$ как параметр, та же процедура может быть использована в случае непрерывных регрессоров. Проблема размерности $q$ и бесконечно-мерная неизвестная плотность $h(x)$ была сведена к размерности $q+S-1$. 

\subsection*{Оценки обобщённого метода моментов}

Замечательные результаты Косслетта (1981a) сложно применить на практике. 

Имбенс (1992) разработал более простую \bfseries оценку ОММ с эндогенной стратификацией, \mdseries которая обладает такой же эффективностью, как и оценка Косслетта. Довольно общее описание и презентация этой оценки дана в Имбенс, Ланкастер (1996) для стратифицированных выборок, полученных мультиномиальным отбором, стандартным стратифицированным отбором, или отбором по вероятности переменных. Совместная плотность --- это опять $g^s(s,y,x|\theta)$ из~(\ref{eq24.16}) и выборочные вероятности страт $H_s$ могут быть неизвестны. ОММ строится на $S-1$ уравнении для $H_s$, $q$ уравнениях для $\theta$, основанных на функции условного правдоподобия $y$ при заданных $s$ и $x$, $S-1$ уравнениях для ограничений на вероятности страт в генеральной совокупности $Q_s(\theta)$ и последнее ограничение необязательно, если есть линейной ограничение на $Q_s(\theta)$, что происходит, к примеру, если страты взаимоисключающи и покрывают всё выборочное пространство. 

\subsection{Взвешенные оценки}

С эндогенной стратификацией легко работать, когда выборочные и истинные вероятности страт $H_s$ и $Q_s(\theta)$, определённые в~(\ref{eq24.14}), известны, хотя оценка в этом случае и не является полностью эффективной. Мы начнём с оценки ММП, прежде чем перейдём к более общим оценкам. 

\subsection*{Взвешенная оценка ММП}

Мански, Лерман (1977) предложили взвешенную оценку максимального правдоподобия (weighted maximum likelihood, WML). Она максимизирует

\begin{equation}
\label{eq24.17}
Q_{WML}(\theta) = \sum_i \frac{Q_i}{H_i} \ln f(y_i|x_i,\theta),
\end{equation}
где $H_i = H_s$ и $Q_i = Q_s$, если $i$-ое наблюдение принадлежит страте $s$. 

Мански, Лерман (1977) назвали эту оценку \bfseries взвешенной оценкой для экзогенного отбора \mdseries (weighted exogenous sampling estimator, WESML), так как~(\ref{eq24.17}) умножает обычный член $\ln f(y_i|x_i,\theta)$ в условном правдоподобии при экзогенном отборе на вес $H_i/Q_i$. Однако, обозначение WESML может привести к путанице, потому что проблема здесь заключается в эндогенности --- просто оказывается, что правильное взвешивание обычной экзогенной оценки может дать состоятельную оценку. 

Несмотря на сходство, целевая функция $Q_{WML}(\theta)$ с формальной точки зрения не является правдоподобием, так как~(\ref{eq24.16}) не предполагает, что выборочная условная плотность $y$ при заданных $x$ и $s$ задаётся $f^s(y|x,\theta) = f(y| x,\theta)^{Q_s/H_s}$. Тем не менее, оценка взвешенного максимального правдоподобия WML является состоятельной. Условия первого порядка для неё:

\begin{equation}
\label{eq24.18}
\sum_i \frac{Q_i}{H_i} \frac{\partial \ln{f(y_i|x_i,\theta)}}{\partial \theta} = 0
\end{equation}
Эта оценка будет состоятельна, если члены суммы имеют нулевые математические ожидания по выборочной плотности $g^s(s,y,x|\theta)$ из~(\ref{eq24.16}). Теперь

\begin{align}
\label{eq24.19}
&\E_s \left[ \frac{Q_s}{H_s} \frac{\partial \ln f(y|x,\theta)}{\partial \theta} \right] \nonumber \\
&=\int \int  \frac{Q_s}{H_s} \frac{\partial \ln f(y|x,\theta)}{\partial \theta} \frac{H_s}{Q_s(\theta)}f(y|x,\theta)h(x)dydx  \nonumber \\
&=\int \int  \frac{\partial \ln f(y|x,\theta)}{\partial \theta} f(y|x,\theta)h(x)dydx \nonumber \\
&=\int \E \left[\frac{\partial \ln f(y|x,\theta)}{\partial \theta} \right] h(x) dx \nonumber \\
&=0,
\end{align}
при обычных условиях, что в генеральной совокупности плотность удовлетворяет $\E[\partial \ln f(y|x,\theta) / \partial \theta] = 0$. Тогда оценка взвешенного максимального правдоподобия состоятельна в присутствии эндогенной стратификации. 

Уравнение для информационной матрицы не выполняется для целевой функции $Q_{WML}(\theta)$ в~(\ref{eq24.17}), так что нам надо использовать сэндвич-форму $N^{-1}A^{-1}BA^{-1}$ для асимптотической дисперсии $\hat \theta_{WML}$, где

\begin{equation}
\label{eq24.20}
A(\theta_0) = \plim \left. \frac{1}{N} \sum_{i=1}^N \frac{Q_i}{H_i} \frac{\partial^2 \ln f(y_i|x_i, \theta)}{\partial \theta \partial \theta'} \right|_{\theta_0}
\end{equation}
и
\begin{equation}
\label{eq24.21}
B(\theta_0) = \plim \left. \frac{1}{N} \sum_{i=1}^N \left( {\frac{Q_i}{H_i}} \right) ^2 \frac{\partial \ln f(y_i|x_i, \theta)}{\partial \theta} \frac{\partial \ln f(y_i|x_i, \theta)}{\partial \theta'}  \right|_{\theta_0}.
\end{equation}

Такая оценка менее эффективна, чем оценка ММП Косслетта или Имбенса, но её достаточно просто реализовать. Но, разумеется, она предполагает знание вероятностей страт. 

\subsection*{Взвешенная М-оценка}

Взвешенная оценка ММП может быть применена к другим оценкам помимо условной ММП-оценки. К примеру, Хаусман, Уайз (1979) рассматривают схожую взвешенную оценку для регрессии методом наименьших квадратов. 

Предположим, что используется простой случайный отбор. Тогда мы минимизируем $\sum_i q(y_i|x_i, \theta)$, с условиями первого порядка $\sum_i \partial q(y_i|x_i, \theta) / \partial \theta = 0$, и предположим, что в генеральной совокупности
$$
\E[\partial q(y|x,\theta) / \partial \theta] = 0,
$$
необходимое условие для состоятельности. Тогда, если отбор --- эндогенно стратифицированный как в разделе 24.2 и в выборке и генеральной совокупности известны вероятности страт $H_s$ и $Q_s$, $\theta$ может быть состоятельно оценена \bfseries взвешенной М-оценкой \mdseries $\hat \theta_W$, которая минимизирует

\begin{equation}
\label{eq24.22}
Q_W(\theta) = \sum \frac{Q_i}{H_i} q(y_i|x_i, \theta). 
\end{equation}
Доказательство состоятельности следует из~(\ref{eq24.18}) и~(\ref{eq24.19}) для оценки взвешенного максимального правдоподобия и дисперсионной матрицы в форме $N^{-1}A^{-1}BA^{-1}$, где $A$ и $B$ определены в~(\ref{eq24.20}) и~(\ref{eq24.21}) с единственным изменением --- заменой $\partial \ln f(y_i|x_i, \theta) / \partial \theta$ на $\partial q(y_i|x_i,\theta) / \partial \theta$. Вулдридж (2001) приводит формальное доказательство. 

Аналогично, для оценки, основанной на $q$ моментов
$$
\E[h(y,x,\theta)] = 0,
$$
при эндогенной стратификации, используем \bfseries взвешенную оценку оценивающих уравнений \mdseries, которая решает
$$
\sum_i \frac{Q_i}{H_i} h(y_i, x_i, \theta) = 0.
$$
Результаты взвешенного ММП применяются с $\partial \ln{f(y_i|x_i, \theta)} / \partial \theta$ заменённой на $h(y_i| x_i, \theta)$. 

Отметим, что веса $Q_i/H_i$ те же самые, что и предложенные в разделе 24.3.2 для оценки параметра ценза при простом экзогенном стратифицированном отборе. Мотивация, однако, отличается. В данном разделе предполагается, что условные моменты корректно специфицированы, так что при экзогенном стратифицированном отборе невзвешенные оценки были бы состоятельными и эффективными. Веса становятся необходимыми, если стратификация эндогенна. 

\section{Кластеризация}

Разделы 24.3 и 24.4, посвященные взвешиванию и стратификации, рассматриваются методы для учета устройства выборки, ведущего к отличиям выборочного распределения от распределения в генеральной совокупности. Предположение о независимости попавших в выборку наблюдений сохранялось. 

В реальности же, данные опросов, как правило, не независимы. Это может возникать в силу использования кластеризованных выборок для уменьшения расходов на проведение опроса, таких, как интервьюирование нескольких домохозяйств в одном квартале. В таких случаях, данные могут коррелировать внутри кластера в силу наличия общего ненаблюдаемого эффекта кластера. Такая зависимость, однако, может возникать и при простом случайном отборе. К примеру, может присутствовать ненаблюдаемый эффект, общий для всех домохозяйств в одном штате. 

Существует несколько методов учёта ненаблюдаемых эффектов внутри кластера. Если внутри-кластерные ненаблюдаемые эффекты не коррелированы с регрессорами, необходимо скорректировать только дисперсии коэффициентов. Если же они коррелированы с регрессорами, оценки параметров регрессии становятся несостоятельными и нужны альтернативные оценки. Анализ также затрудняется тем, что методы могут изменяться в зависимости от того, рассматривается ли большое количество маленьких кластеров или несколько больших. Другие проблемы, такие как взвешивание и стратификация рассмотрены в разделе 24.6. 

Обозначения и модели представлены ниже. Основные различия сводятся к разнице между случайными кластерными эффектами и постоянными кластерными эффектами, схожей с ситуацией для панельных данных. Разные способы оценивания представлены ниже. 

\subsection{Модели с индивидуальными эффектами кластеров}

Рассмотрим оценку линейной регрессии по данным $(y_i,x_i)$, $i = 1, \dots, N$, где $i$ обозначает $i$-ое наблюдение в выборке, к примеру, домохозяйство. 

Проблема заключается в том, что некоторые параметры регрессии могут изменяться в зависимости от кластера $c$, $c = 1, \dots, C$. Пусть $i$-ое наблюдение из выборки --- это $j$-ое наблюдение в $c$-ом вошедшем в выборку кластере. Тогда общая модель для кластеризованных данных:

\begin{equation}
\label{eq24.23}
y_{jc} = x'_{jc} \beta_c + u_{jc}, \qquad j = i, \dots , N_c, \: c = 1, \dots, C.
\end{equation}
где $\Cov[u_{jc}, u_{kc}] \ne 0$, однако $\Cov[u_{jc}, u_{kd}] = 0$ при $c \ne d$. Эта модель учитывает влияние кластеров как через параметры регрессии, которые изменятся в зависимости от кластера, так и через ошибки. которые коррелированы внутри кластера. 

Здесь мы сконцентрируемся на частном случае, на \bfseries модели с индивидуальными эффектами кластеров:\mdseries

\begin{equation}
\label{eq24.24}
y_{jc} = x'_{jc} \beta + \alpha_c + \e_{jc}.
\end{equation}

Здесь только постоянный коэффициент регрессии $\alpha_c$ зависит от кластера, тогда как коэффициенты наклона предполагаются постоянными. В самой простой модели ошибка $\e_{jc}$ предполагается гомоскедастичной

\begin{equation}
\label{eq24.25}
\e_{jc} \sim [0,\sigma^2_{\e}],
\end{equation}

Это предположение может быть ослаблено, чтобы добавить в модель гетероскедастичность и корреляцию внутри кластера. Что более существенно, можно сделать разные предположения относительно $\alpha_c$, что приведёт к двум разным моделям, которые мы сейчас рассмотрим. 

\subsection*{Случайные кластерные эффекты}

В \bfseries моделях со случайными кластерными эффектами \mdseries (cluster-specific random effects, CSRE) константы $\alpha_c$ в~(\ref{eq24.24}) считаются случайными с распределениями, не зависящими от наблюдаемых переменных. В простейшем случае предполагается, что

\begin{equation}
\label{eq24.26}
\alpha_c \sim [0, \sigma^2_{\alpha}].
\end{equation}

Эта модель --- прямой аналог модели со случайными эффектами для панельных данных. Это простая линейная регрессия $y_{jc}$ на $x_{jc}$ с усложнением, заключающимся в том, что ошибки $\alpha_c + \e_{jc}$ коррелированы для наблюдений в одном кластере. МНК-оценки состоятельны, но неэффективны. Корреляция между ошибками приводит к необходимости корректировать стандартные ошибки для МНК-оценок. Оценки обобщенного МНК более эффективны. 

При выполненных предпосылках~(\ref{eq24.25}) и~(\ref{eq24.26}) на $\e_{jc}$ и $\alpha_c$, $\V[\alpha_c + \e_{jc}] = \sigma^2_{\alpha} + \sigma^2_{\e}$ и $\Cov[\alpha_c + \e_{jc}, \alpha_c + \e_{kc}] = \sigma^2_{\alpha}$ для $k \ne j$. Определим \bfseries внутриклассовый коэффициент корреляции: \mdseries

\begin{equation}
\label{eq24.27}
\rho = \Cor[\alpha_c + \e_{jc}, \alpha_c + \e_{kc}] = \frac{\sigma^2_{\alpha}}{\sigma^2_{\alpha}+\sigma^2_{\e}}.
\end{equation}

Есть взаимно-однозначное соответствие между $(\sigma^2_{\alpha}, \sigma^2_{\e})$ и $(\sigma^2, \rho)$, где $\rho$ определяется~(\ref{eq24.27}) и $\sigma^2 = \sigma^2_{\alpha} + \sigma^2_{\e}$. Модель CSRE эквивалентна модели с постоянной внутриклассовой корреляцией. Модель также может иметь Байесовскую интерпретацию, если рассматривать каждое наблюдение как имеющее свою собственную константу $\alpha_{jc}$, которая извлекается из одномерного распределения, и обращаясь к критерию взаимозаменяемости, так что нижний индекс в $\alpha_{jc}$ --- это просто обозначение и не имеет особого значения. Во всех случаях кластеризация имеет ожидаемый эффект, вызывая положительную корреляцию между ошибками внутри кластеров. 

\subsection*{Постоянные кластерные эффекты}

В \bfseries моделях со постоянными кластерными эффектами \mdseries (cluster-specific fixed effects, CSFE) константы $\alpha_c$ из~(\ref{eq24.23}) --- случайные и ненаблюдаемые, как и в CSRE, но могут быть коррелированы с регрессорами. $x_{jc}$ больше не включает константу. 

Эта модель --- прямой аналог модели с постоянными эффектами для панельных данных. Условное математическое ожидание $\E[y_{jc}|x_{jc},\alpha_c] = x'_{jc} \beta + \alpha_c$. Оценка МНК из регрессии $y_{jc}$ на $x_{jc}$ несостоятельна для $\beta$, если пропущенная переменная $\alpha_c$ коррелирована с $x_{jc}$. Состоятельная оценка $\beta$ требует состоятельной оценки $\alpha_c$, которая возможна, если кластеры большие. Если же кластеры маленькие индивидуальные $\alpha_c$ необходимо устранять взятием разностей. 

\subsection*{Сравнение с анализом панельных данных}

Структура и терминология рассматриваемой проблемы, очевидно, очень похожа на случай с анализом панельных данных, рассмотренный в главах 21 и 23. Но в то же время, есть и ряд различий. 

Для панельных данных отдельное наблюдение, такое, как домохозяйство, наблюдается больше, чем один раз, тогда как для случая кластеров оно наблюдается только один раз. В принятой в анализе панельных данных системе обозначений $it$ первый индекс соответствует кластеру, если рассматривается короткая панель, тогда как в кластерных обозначениях $jc$ второй индекс соответствует кластеру. Анализ панельных данных сосредоточен на сбалансированных панелях, тогда как кластеризованные данные обычно несбалансированы, потому что $N_c$ различается для разных кластеров. 

Микроэконометрические методы для панельных данных сосредотачивают внимание на коротких панелях. Это аналогично большому количеству кластеров с маленьким количеством наблюдений на кластер. Тогда $N_c$ маленький, а $C \to \infty$, мы называем их маленькими кластерами. Но нередко встречаются большие кластеры, где $N_c \to \infty$ и $C$ маленький. Для CSFE моделей с большими кластерами надо будет оценить небольшое количество $\alpha_c$ и проблемы со вспомогательными параметрами не возникнут. 

В отличие от панельных данных, может быть неочевидно, как правильно разделить наблюдения по кластерам. К примеру, для Текущего обследования населения CPS кластеризация может рассматриваться как возникающая внутри штатов, внутри страт, внутри PSU или внутри USU. Этот вопрос откладывается до раздела 24.6. Можно ожидать, что внутрикластерная корреляция будет убывать для кластеризации по более агрегированным уровням. Если кластеризация проводится на уровне штатов, кластеры будут большими, тогда как если она проводится на уровне USU они будут маленькими. Более того, возможно, что данные не включают необходимую для кластеризации информацию, такую как страта или USU для наблюдения. 

Аналог динамических, а не статичных панельных моделей --- это модель, где $y_{jc}$ зависит не только от $x_{jc}$, но и от $x_{kc}$, где $k \ne j$. Для кластеризованных данных обычно достаточно специфицировать \bfseries модель со взаимными эффектами \mdseries, которая включает средний по кластеру $\overline{x}_c$, так как порядок наблюдений внутри кластера обычно не важен. 

\section*{Обзор}

Три основных оценки для кластеризации --- это МНК, ОМНК, и оценки within, представленные в разделах 24.5.2 --- 24.5.4. Свойства этих оценок, приведенные в таблице 24.2, могут меняться в зависимости от истинной модели. Прежде всего, если в истинной модели есть постоянные кластерные эффекты, МНК и оценки со случайными эффектами становятся несостоятельными, тогда как оценка within даёт состоятельные оценки, но только коэффициентов для тех регрессоров, которые изменяются внутри кластера. Даже если оценка состоятельна, обычные стандартные ошибки часто требуют коррекции, чтобы учесть кластеризацию и возможную гетероскедастичность, что будет подробнее рассмотрено ниже. 

\begin{table}[h]
\caption{\label{tab:pred} Свойства оценок для разных моделей кластеризации}
\begin{center}
\begin{tabular}{lllc}
\hline
\hline
Раздел & Оценка & Модель кластеризации &  Состоятельность \\
\hline
24.5.2 & МНК & Случайные эффекты & Да \\
  &   & Постоянные эффекты & Нет \\
24.5.3 & ОМНК со случайными эффектами & Случайные эффекты & Да \\
  &   & Постоянные эффекты & Нет \\
24.5.4 & within с постоянными эффектами & Случайные эффекты & Да \\
  &   & Постоянные эффекты & Да \\
\hline
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{Оценки метода наименьших квадратов}

Рассмотрим МНК регрессию

\begin{equation}
\label{eq24.28}
y_{jc} = x'_{jc} \beta + u_{jc}.
\end{equation}

МНК даёт несостоятельные оценки из-за наличия пропущенных переменных, если истинная модель --- CSFE (то есть, $u_{jc} = \alpha_c + \e_{jc}$), где постоянный эффект $\alpha_c$ коррелирован с $x_{jc}$. В этом случае вместо МНК нужно использовать оценку CSFE, рассмотренную в разделе 24.5.4. 

Напротив, в случае CSRE моделей с $\alpha_c$ некоррелированным с $x_{jc}$ МНК остаётся состоятельным. В общем, МНК состоятелен при более широком круге моделей $u_{jc}$, чем CSRE, при условии что $u_{jc}$ некоррелирована с $x_{jc}$. Рассмотрим МНК-оценку для этого случая, обращая внимание на получение корректных стандартных ошибок, зная корреляцию $u_{jc}$ внутри кластера. 

\subsection*{Замечание}

Собирая в~(\ref{eq24.28})  наблюдения внутри кластера в вектор получаем

\begin{equation}
\label{eq24.29}
y_{c} = X_{c} \beta + u_{c},
\end{equation}
где $y_c$ и $u_c$ --- вектора размера $N_c \times 1$ и $X_c$ --- матрица $N_c \times K$. Собирая кластеры в векторы, получаем:

\begin{equation}
\label{eq24.30}
y = X \beta + u,
\end{equation}
где $y$ и $u$ --- вектора размера $N \times 1$ и $X$ --- матрица размера $N \times K$, $N = \sum_c N_c$. 

Три формы представления CSRE модели дают три эквивалентных способа получения МНК оценки модели~(\ref{eq24.28}):

\begin{align}
\label{eq24.31}
 \hat{\beta}_{OLS} &= (X'X)^{-1}X'y \\
&=\left( \sum_{c=1}^C X'_cX_c \right)^{-1}  \sum_{c=1}^C X'_c y_c  \nonumber \\
&=\left( \sum_{c=1}^C \sum_{j=1}^{N_c} x_{jc} x'_{jc} \right)^{-1} \sum_{c=1}^C \sum_{j=1}^{N_c} x_{jc} y_{jc}. \nonumber
\end{align}

Вторая из этих форм может быть очень полезной при предположении о независимости ошибок в разных кластерах. Тогда, как до этого в панельном случае, оценка МНК сходится к

\begin{align}
\label{eq24.32}
\sqrt{N} (\hat{\beta}_{OLS} --- \beta) \overset{d}{\to}  \mathcal N [0, A^{-1} B A^{-1}], 
\end{align}
где
\begin{align}
\label{eq24.33}
& A = \plim N^{-1} \sum_{c=1}^C X'_c X_c, \\
& B = \plim N^{-1} \sum_{c=1}^C X'_c u_c u'_c X_c. \nonumber
\end{align}
Используя независимость $u_c$ по $c$. Разные предположения о свойствах $u_c$ ведут к разным оценкам $B$. 

\subsection*{МНК с робастными к кластерам стандартными ошибками}

При небольшом размере кластеров их число становится большим и можно получить состоятельную оценку $B$ из~(\ref{eq24.33}) заменой $u_c$ на $\hat u_c = y_c --- X_c \hat \beta$. Тогда $\hat \beta_{OLS}$ имеет асимптотическое нормальное распределение с робастной к кластерам ковариационной матрицей

\begin{equation}
\label{eq24.34}
\hat \V [\hat \beta_{OLS}] = \left( \sum_{c=1}^C X'_c X_c \right)^{-1} \sum_{c=1}^C X'_c \hat u_c \hat u'_c X_c \left( \sum_{c=1}^C X'_c X_c \right)^{-1}. 
\end{equation}

Эта формула не налагает ограничений на гетероскедастичность и корреляцию внутри кластеров, потому что на $\V[u_c]$ и, следовательно, на $\V[u_{jc}]$ и $\Cov[u_{jc}, u_{kc}]$ не налагается никаких ограничений. Однако, здесь предполагается, что $N_c$ маленькое и $C \to \infty$. Статистические пакеты часто дают коррекцию на степени свободы. Как правило, оценка~(\ref{eq24.34}) умножается на

$$
dfc = \frac{N-1}{N-K} \times \frac{C}{C-1},
$$
для коррекции оценки $\beta$, потому что на практике число кластеров конечно. 

Что посмотреть, как работает~(\ref{eq24.34}) будем считать регрессоры фиксированными и заметим, что

\begin{align}
B & = \lim N^{-1} \sum_{c=1}^C X'_c \E[u_c u'_c] X_c \nonumber\\
& = \lim N^{-1} \sum_{c=1}^C \sum_{j=1}^{N_c} \sum_{k=1}^{N_c} \E[u_{jc}u'_{kc}] x_{jc} x'_{kc}. \nonumber
\end{align}
Тогда~(\ref{eq24.34}) получается оценкой

\begin{align}
\hat{B} & =  N^{-1} \sum_{c=1}^C X'_c \hat u_c \hat u'_c X_c, \nonumber\\
& =  N^{-1} \sum_{c=1}^C \sum_{j=1}^{N_c} \sum_{k=1}^{N_c} \hat u_{jc} \hat u'_{kc} x_{jc} x'_{kc}. \nonumber
\end{align}

К примеру, рассмотрим оценивание $\E[y]$ с помощью $\overline{y}$. Это регрессия~(\ref{eq24.28}) с $x_{jc}=1$, $\hat \beta_{OLS} = \overline{y}$ и $\hat u_{jc} = y_{jc} --- \overline{y}$. Тогда~(\ref{eq24.34}) приводит к $\hat \V[\overline{y}] = N^{-2} \sum_c (\sum_j (y_{jc} --- \overline{y}))^2$ , вместо оценки $N^{-1} \sum_c \sum_j (y_{jc} --- \overline{y})^2$, которая дополнительно предполагает независимость внутри кластеров. 

\subsection*{Стандартные ошибки в предположении CSRE модели}

Робастные к кластерам оценки~(\ref{eq24.34}) требуют большого числа кластеров. Альтернативные оценки, которые также работают в случае небольшого числа кластеров, могут быть использованы при определенных предпосылках относительно дисперсий и ковариаций ошибки $u_{jc}$. Эти альтернативные оценки также позволяют оценить влияние кластеров на дисперсии оценок. 

В частности, предположимм модель CSRE, заданную~(\ref{eq24.24}) и~(\ref{eq24.26}). Тогда ошибки $u_{jc} = \alpha_c + \e_{jc}$ независимы по $c$, а внутри кластера

$$
\Cov[u_{jc}, u_{kc}]=\begin{cases}
\sigma^2,&\text{$j = k$,}\\
\rho\sigma^2,&\text{$j \ne k$,}
\end{cases}
$$
где коэффициент внутриклассовой корреляции $\rho$ определён в~(\ref{eq24.27}). Тогда

\begin{equation}
\label{eq24.35}
\sum_c = \V[u_c] = \sigma^2 [(1-\rho) I_c + \rho e_c e'_c],
\end{equation}
где $I_c$ --- единичная матрица размера $N_c \times N_c$, $e_c$ --- вектор из единиц размера $N_c \times 1$. 

Зная $\sum_c$  из~(\ref{eq24.35}) и~(\ref{eq24.32}) и~(\ref{eq24.33}), получаем

\begin{equation}
\label{eq24.36}
\V[\hat \beta_{OLS}] = \left( \sum_{c=1}^C X'_c X_c \right)^{-1} \sum_{c=1}^C \sigma^2 X'_c [(1-\rho) I_c + \rho e_c e'_c] X_c \left( \sum_{c=1}^C X'_c X_c \right)^{-1}.
\end{equation}
При постоянной внутриклассовой корреляции, оценка корреляционной матрицы состоятельна как при маленьких, так и при больших кластерах. Очевидные оценки для $\sigma ^2$ и $\rho$:

$$
\hat \sigma^2 = \frac{1}{N-K-1} \sum_{c=1}^C \sum_{j=1}^{N_c} \hat u^2_{jc}
$$
и
$$
\hat \rho = \frac{1}{\sum_c N_c (N_c -1)} \frac{1}{\hat \sigma^2} \sum_{c=1}^C \sum_{j=1}^{N_c} \sum_{k \ne j}^{N_c} \hat u_{jc} \hat u_{kc}.
$$
Оценка $\rho$ содержит много внутрикластерных пар, и состоятельная оценка может быть получена с использованием только их части. Используются пары $\sum_c N_c(N_c --- 1)$, тогда как фактически каждая уникальная внутри-кластерная пара учитывается дважды, так как и $\hat u_{jc} \hat u_{kc}$, и $\hat u_{kc} \hat u_{jc}$ фигурируют в суммах. 

Если кластеры большие, внутрикластерная корреляции может быть разной в разных кластерах. Тогда в~(\ref{eq24.35}) и~(\ref{eq24.36}) $\sigma^2$ и $\rho$ могут быть заменены на $\sigma^2_c$ и $\rho_c$ соответственно. Можно получить их состоятельные оценки:

$$
\hat \sigma^2_c = \frac{1}{N_c-K-1}\sum_{j=1}^{N_c} \hat u^2_{jc}
$$
и
$$
\hat \rho_c = \frac{1}{N_c (N_c -1)} \frac{1}{\hat \sigma^2_c} \sum_{j=1}^{N_c} \sum_{k \ne j}^{N_c} \hat u_{jc} \hat u_{kc}.
$$

\subsection*{Смещение стандартных ошибок, полученных МНК}

Следуя интуиции, можно прийти к выводу, что для кластеризованных данных, стандартная формула для оценки дисперсии метода наименьших квадратов

$$
\V^{Formula}[\hat \beta_{OLS}] = \sigma^2 \left( \sum_{c=1}^C X'_c X_c \right)^{-1},
$$
недооценивает истинную дисперсию оценки МНК в предположении положительной внутрикластерной корреляции, так как каждое дополнительное наблюдение в кластере приносит меньше, чем одну часть независимой информации. Продемонстрируем это смещения для ситуации, когда ошибки описываются CSRE моделью. 

Рассмотрим CSRE модель с одинаковыми регрессорами внутри каждого кластера, так что $x_{jc} = x_c$ и $X_c = e_c x'_c$. Тогда используя $e'_c e_c = N_c$, (\ref{eq24.36}) превращается в

$$
\V[\hat \beta_{OLS}] = \left( \sum_{c=1}^C N_c x_c x'_c \right)^{-1} \sum_{c=1}^C N_c \sigma^2 [1+ \rho(N_c -1)] x_c x'_c \left( \sum_{c=1}^C N_c x'_c x_c \right)^{-1},
$$
результат, представленный Клоэком (1981) и Моултоном (1986).

Теперь перейдем к сбалансированным кластерам. Пусть $M$ --- средний размер кластера, то есть $M = N_c = N/C$. Тогда выражение для дисперсии оценки упрощается до
$$
\V[\hat{\beta}_{OLS}] = [1+\rho (M-1)] \times \sigma^2 \left( M \sum_{c=1}^C x_c x_c'  \right)^{-1},
$$
тогда как формула дисперсии упрощается до $\sigma^2 (M \sum_c x_c x'_c)^{-1}$. Истинные дисперсии --- это произведение множителя

$$
\tau = [1+\rho (M-1)]
$$
на обычную МНК оценку ковариационной матрицы. Даже если $\rho$ маленькие, корректирующий фактор может быть довольно большим. К примеру, при среднем размере кластера $M = 101$ наблюдение, обычные стандартные ошибки, полученные МНК, должны умножаться на $\sqrt{1+100\rho}$. Предполагаемая независимость внутри кластера также может привести к смещению оценки $\sigma^2$, но это не так важно. Для случая сбалансированных кластеров Клоэк показал, что $\E[\sum_c \sum_j \hat u^2_{jc}] = \sigma^2 [N --- K(1+\rho(m-1))]$, так что нам надо корректировать на $[N --- K(1+\rho(m-1))]^{-1}$, а не на $[N-K]^{-1}$. 

На практике некоторые регрессоры могут быть постоянными внутри кластера, а другие могут варьировать. Тогда для случая регрессии со свободным членом и скалярным регрессором (к примеру, $x'_{jc}\beta = \beta_1 + \beta_2 x_{jc}$), Скотт и Холт (1982) показали, что обычная формула для оценки дисперсии свободного члена методом наименьших квадратов должна быть умножена на $1+\rho(M-1)$, как это делалось до этого, но для коэффициента наклона она должна умножаться на меньший коэффициент $1 + \hat \rho_x \rho (M-1)$, где $\hat \rho_x$ может рассматриваться как оценка внутриклассового коэффициента корреляции $x_{jc}$. Для пространственных данных $\hat \rho_x$ сравнительно небольшой, так что основная проблема заключается в стандартных ошибках для инвариантных к кластеру регрессоров. 

Моултон (1986) продемонстрировал в приложении, что смещение в стандартных ошибках при использовании некорректной формулы для МНК оценок дисперсии может быть довольно значительным. Он оценивал модель для логарифма заработной платы, используя пространственные данные Текущего обследования населения CPS с кластеризацией по штатам. В его приложении $N = 18 946$ и $C = 49$. Оцененный коэффициент внутриклассовой корреляции оказался небольшим, $\hat \rho =0.032$. Однако, размер кластеров большой, и если проигнорировать тот факт, что данные несбалансированы и использовать формулы со средним размеров кластера $M = 387$, то $\hat \tau = [1+ \hat \rho (M-1)] = 13.3$. Для постоянных по штату регрессоров истинные стандартные ошибки метода наименьших квадратов должны быть в $\sqrt{13.3} = 3.7$ раза больше полученных обычным путём стандартных ошибок, что является очень большим смещением. Один из способов трактовки этого смещения заключается в том, что для постоянных по штату регрессоров $18 946$ кластеризованных наблюдений дают ту же точность, что и $18946/13.3 = 1425$ независимых наблюдений. Для варьирующих регрессоров смещение будет гораздо меньше, к примеру $[1+ \hat \rho_x \hat \rho(M-1) ] = 2.23$ если $\hat \rho_x = 0.1$. Моултон не приводит результаты для включенных переменных изменяющихся по индивидам. Для постоянных по штату регрессоров, таких как темп роста занятости в штате, скорректированные стандартные ошибки для МНК как правило в 3 --- 4 раза больше некорректных, полученных по стандартной формуле. 

Эти рассуждения сводятся к тому, что присутствует значительное смещение вниз оценок стандартных ошибок для метода наименьших квадратов в случае постоянных по кластеру регрессоров. Для варьирующих по кластеру переменных он также присутствует, но значительно меньше. Постоянные по кластеру регрессоры часто используются при работе с кластеризованными данными, так как обычной практикой является моделировать индивидуальное поведение как зависящее, помимо прочего, от свойств кластера. В этом случае, для того, чтобы сделать статистически корректные выводы, нужно учесть влияние кластеризации. 

\subsection{Индивидуальные для кластеров случайные эффекты}

Если данные описываются моделью со случайными эффектами, то оценка ОМНК в целом более эффективна, чем оценка МНК из предыдущего раздела. При независимости между кластерами оценка ОМНК модели~(\ref{eq24.29}):

\begin{equation}
\label{eq24.37}
\hat \beta_{GLS,RE} = \left( \sum_{c=1}^C X'_c \Sigma_c^{-1} X_c \right)^{-1} \sum_{c=1}^C  X'_c \Sigma_c^{-1} y_c,
\end{equation}
где $ \Sigma_c = \V[u_c]$. Оценка допустимого ОМНК заменяет $ \Sigma_c$ состоятельной оценкой $ \hat \Sigma_c$, тогда, предполагая, что модель~(\ref{eq24.29}) и ковариационная матрица ошибок $ \Sigma_c$ специфицированы правильно, мы получаем:

$$
\V[\hat \beta_{GLS,RE}] = \left( \sum_{c=1}^C X'_c \Sigma_c^{-1} X_c \right)^{-1}.
$$

Для CSRE модели, $ \Sigma_c$ из~(\ref{eq24.35}) может быть состоятельно оценена при помощи $ \hat \Sigma_c$, которая заменяет $\sigma^2$ и $\rho$ из состоятельными оценками из~(\ref{eq24.36}). Как и в похожей модели со случайными эффектами для панельных данных, оценка допустимого ОМНК асимптотически эквивалентна оценке ММП при дополнительных предположениях, что $\alpha_c$ и $\e_{jc}$ нормально распределены. 

CSRE модель привлекательна тем, что оценка ОМНК~(\ref{eq24.37}) может быть просто получена как оценка методом наименьших квадратов трансформированной регрессии

\begin{equation}
\label{eq24.38}
y_{jc} --- \theta_c \overline{y}_c = (x_{jc} -\theta_c \overline{x}_c)' \beta + (\e_{jc} -\theta_c \overline{\e}_c),
\end{equation}
где
\begin{equation}
\label{eq24.39}
\theta_c = 1 --- \frac{\sqrt{1-\rho}}{\sqrt{1+\rho(N_c-1)}} = 1 --- \frac{\sigma_{\e}}{\sqrt{\sigma_{\e}^2 + N_c \sigma_{\alpha}^2}},
\end{equation}
Данный результат доказывается ниже в этом разделе. Для его реализации мы должны заменить $\theta_c$ состоятельной оценкой $\hat \theta_c$. Как и для моделей панельных данных, можно показать, что что обычные стандартные ошибки, полученные МНК в этой регрессии, могут быть использованы, если ошибки $\e_{jc}$ в модели~(\ref{eq24.24}) гомоскедастичны. 

Оценка ОМНК по меньшей мере также эффективна, как оценка МНК, предполагая, что выполнены~(\ref{eq24.24}) и~(\ref{eq24.26}). В частном случае, когда все регрессоры в модели постоянны внутри кластеров, нет выигрыша по эффективности, потому что оценки ОМНК совпадают с МНК (Клоэк, 1981). Скотт и Холт (1982) дают консервативную верхнюю границу для потери эффективности МНК по сравнению с ОМНК:

$$
\frac{\V[c' \hat \beta_{GLS}]}{\V[c' \hat \beta_{OLS}]} \ge 1 --- \left( 1+ \frac{4(1-\rho)[1+\rho(N_0 -1)]}{N_0^2 \rho^2} \right)^{-1}
$$
для произвольного вектора $c$, где $N_0 = \max\{ N_c\}$ --- размер самого большого кластера. Эта граница возрастает по $N_0$ и $\rho$, и даже для $N_0 = 1000$ и $\rho = 0.1$, МНК менее эффективен, чем ОМНК, не больше чем на $22\%$. 

Учитывая то, что выигрыш по эффективности от ОМНК невелик, как правило исследователи фокусируют внимание на МНК с правильными стандартными ошибками, кроме случаев, когда МНК несостоятелен из-за того, что данные описываются CSFE моделью. Основное влияние кластеризации заключается в том, что МНК становится значительно менее эффективным по сравнению со случаем отсутствия кластеризации, как становится ясным из дискуссии о вычислении стандартных ошибок для МНК оценок в разделе 24.5.2. 

Если кластеры велики, CSRE модель может быть ослаблена допущением, что дисперсия и внутриклассовая корреляция могут меняться в зависимости от кластера. Тогда в~(\ref{eq24.35}) для вычисления $\Sigma_c$ мы заменяем $\sigma^2$ и $\rho$ на $\sigma^2_c$ и $\rho_c$ соответственно, используя состоятельные оценки для $\sigma^2_c$ и $\rho_c$, данные после~(\ref{eq24.36}). 

Если кластеры маленькие, можно получить робастные стандартные ошибки, которые не требуют постоянства корреляции ошибок внутри кластеров, аналогично~(\ref{eq24.34}) для МНК. Тогда:

$$
\hat \V [\hat \beta_{GLS,RE}] = \left[ \sum_{c=1}^C X'_c \hat \Sigma_c^{-1} X_c \right]^{-1} \sum_{c=1}^C  X'_c \hat \Sigma_c^{-1/2} \hat u_c \hat u'_c \hat \Sigma_c^{-1/2} X_c \left[ \sum_{c=1}^C X'_c \hat \Sigma_c^{-1} X_c \right]^{-1},
$$
где $\hat u_c = y_c --- X_c \hat \beta_{GLS,RE}$. Эта оценка требует малого $N_c$ и $C \to \infty$ и предполагает независимость оценок в разных кластерах. 

\subsection*{ОМНК, полученный как МНК по трансформированной модели}

Чтобы получить~(\ref{eq24.38}), заметим, что для $\Sigma_c$, определённой в~(\ref{eq24.35}) 

\begin{align}
\Sigma_c^{-1} & = \left[ \sigma^2 [(1-\rho)I_c + \rho e_c e'_c] \right]^{-1} \nonumber\\
& =  \frac{1}{\sigma^2 (1-\rho)} [I_c --- (\rho / \tau_c) e_c e'_c]^{-1}, \nonumber
\end{align}
где $\tau_c = 1 + =\rho (N_c --- 1)$, и, следовательно:

$$
\Sigma_c^{-1/2}=  \frac{1}{\sigma \sqrt{1-\rho}} [I_c --- (\theta_c / N_c) e_c e'_c], 
$$
используя тот факт, что $e$ --- это вектор из единиц размера $M \times 1$, получим

\begin{align}
& [I+aee']^{-1} = I --- [a/(1+aM)] ee', \nonumber\\
& [I+aee']^{-1/2} = I --- M^{-1}[ 1 --- \sqrt{1+aM}]M ee'. \nonumber
\end{align}

Теперь в~(\ref{eq24.37}) $X'_c \Sigma_c^{-1} X_c = \left( \Sigma_c^{-1/2} X_c \right)' \Sigma_c^{-1/2} X_c$, где

\begin{align}
\Sigma_c^{-1/2} X_c & = [I_c --- (\theta_c / N_c) e_c e'_c]X_c \nonumber\\
& = X_c --- \theta_c e_c \overline{x}'_c, \nonumber
\end{align}
где $\overline{x}'_c = N_c^{-1} \sum_j x_{jc}$ и множитель $1 / \sigma \sqrt{ 1 --- \rho}$ игнорируется, потому что он сократится, когда мы будем рассматривать $X'_c \Sigma_c^{-1} y_c$. Отсюда получаем трансформированную модель~(\ref{eq24.38}). 

\subsection{Индивидуальные для кластеров постоянные эффекты}

Основная идея CSFE модели проста: пусть кластерные эффекты входят в условное среднее через постоянный член. Модель выглядит следующим образом:

\begin{equation}
\label{eq24.40}
y_{jc} = \alpha_c + x'_{jc} \beta + \e_{jc}, \qquad j = 1, \dots , N_c, \: c = 1, \dots , C,
\end{equation}
где оценке подлежат $\beta$ и $\alpha_c, \: c = 1, \dots, C$. 

Для оценки CSFE модели необходимо удалить все постоянные по кластеру регрессоры, потому что они не могут быть оценены отдельно от $\alpha_c$. К примеру, если кластеризация проводилась по штату и данные описываются моделью с постоянными эффектами, то влияние постоянных по штату регрессоров, таких как средний уровень безработицы в штате, не может быть идентифицировано. Если требуется всё-таки оценить влияние этих показателей, необходимо использовать МНК или CSRE-оценки. Однако, предварительно нужно использовать тест Хаусмана, аналогичный представленному в главе 21 дял панельных данных, чтобы подтвердить сильное допущение CSRE модели, что $\alpha_c$ некоррелирован с регрессорами. 

Мы будем рассматривать модели в предположении

$$
\e_{jc} \sim [0, \sigma^2_{jc}].
$$
Это разрешает гетероскедастичность неизвестной формы, однако предполагает, что включение кластерного постоянного эффекта $\alpha_c$ достаточно, чтобы учесть любую корреляцию ошибок внутри кластера. Это отличается от ситуации с панельными данными, когда корреляция ошибок во времени даже после включения индивидуальных эффектов допускалась и приводила к более сложным моделям. Однако, если есть желание, можно дополнительно скорректировать оценку стандартных ошибок на корреляцию внутри кластеров методами, схожими с использованными в разделе 24.5.2. 

Главное затруднение при оценке CSFE моделей заключается в необходимости оценивать слишком много $\alpha_c$ в случае большого числа маленьких кластеров. 

\subsection*{Модель с кластерными дамми-переменными}

Для начала рассмотрим случай больших кластеров, когда количество кластеров мало по сравнению с общим размеров выборки. Тогда константы $\alpha_c$ могут быть оценены простым МНК с введением дамми-переменных на каждый кластер. 

Пусть наблюдение $i$ обозначает $j$-ое наблюдение в $c$-ом кластере. Тогда~(\ref{eq24.40}) может быть переписано как \bfseries модель с кластерными дамми-переменными \mdseries

\begin{equation}
\label{eq24.41}
y_i = \sum_{c=1}^C \alpha_c d_{ci} + x'_i \beta + \e_i, \qquad i= 1, \dots , N,
\end{equation}
где $d_{ci}$ --- переменные-индикаторы, равные 1, если $i$-ое наблюдение принадлежит кластеру $c$ и 0 иначе. Таким образом вводятся $C$ кластерных дамми-переменных, таких как дамми-переменные на штат, и, чтобы избежать ловушки дамми-переменных, $x$ не должен содержать постоянного члена. 

МНК оценка этой модели даёт состоятельные оценки как $\alpha_1, \dots, \alpha_C$, так и $\beta$ в предположении, что число кластеров фиксировано и равно $C$ при $N \to \infty$. Можно использовать обычную оценку Эйкера-Уайта для получения робастных в гетероскедастичности стандартных ошибок. 

\subsection*{Оценка within для кластеризованных данных}

В присутствии большого числа маленьких кластеров модель~(\ref{eq24.40}) больше не может оцениваться МНК. Во-первых, могут проблемы с вычислением, потому что число параметров $C+K \to \infty$ в силу того, что $C \to \infty$. Во-вторых, что более важно, в силу того, что число параметров стремится к бесконечности, оценка МНК будет несостоятельна, кроме случаев, когда $N_c \to \infty$. 

Интерес, как правило, лежит в оценивании параметров $\beta$ в~(\ref{eq24.40}), а $\alpha_1 , \dots, \alpha_c$ рассматриваются как несущественные параметры. В таком случае, может оказаться удобным трансформировать данные для удаления фиксированных эффектов. Каждое наблюдение $(y_{jc}, x_{jc})$ заменяется отклонением от кластерной средней $(y_{jc} --- \overline{y}_c, x_{jc} --- \overline{x}_c), \: i = 1, \dots, N_c, \: c = 1, \dots, C$, где $\overline{y}_c = N_c^{-1} \sum_j y_{jc}$ и $\overline{x}_c = N_c^{-1} \sum_j x_{jc}$ --- средние по кластеру. Тогда модель~(\ref{eq24.40}) для $y_{jc}$ предполагает, что

\begin{equation}
\label{eq24.42}
y_{jc} --- \overline{y}_c = (x_{jc} --- \overline{x}_c)' \beta + \e_{jc} --- \overline{\e}_c.
\end{equation}

Применение МНК к трансформированной регрессии~(\ref{eq24.42}) даёт состоятельную оценку $\beta$. Если коэффициенты CSFE также представляют интерес, они могут быть оценены как $\hat \alpha = \overline{y}_c --- \overline{x}'_c \beta$, но эта оценка несостоятельна при маленьких $N_c$. 

Сравнение с главой 21 показывает, что это аналог \bfseries оценки within \mdseries для панельных данных. Как и для панельных данных, оценка $\beta$ из~(\ref{eq24.42}) совпадает с МНК оценкой $\beta$ из модели с кластерными дамми-переменными~(\ref{eq24.41})

Можно также рассмотреть \bfseries оценку between \mdseries, аналогичную оценке для линейных панельных моделей. В этом случае $\overline{y}_c$ регрессируется на $\overline{x}_c, \: c = 1, \dots , N_c$. Из~(\ref{eq24.37}), оценка ОМНК CSRE модели включает регрессию в квази-разностях, где кластерные средние умножаются на $\theta_c$ (определенные в~(\ref{eq24.39})) перед взятием разности. Можно показать, что оценка ОМНК --- это линейная комбинация оценок within и between. Она приближается к оценке within для больших $N_c$, потому что в этом случае $\theta_c \to 1$. Отметим, что оценка within состоятельна при CSRE модели. 

Необходимо проявлять осторожность, трактуя стандартные ошибки, если регрессия оценивалась по скорректированным на среднее наблюдениям. Число степеней свободы для такой регрессии равно $(N-K-C)$, а не $(N-K)$. Если программы пренебрегают этой корректировкой, дисперсию, полученную в результате оценивания, необходимо скорректировать умножением её на $(N-K)/(N-K-C)$, а стандартные ошибки должны быть увеличены на корень из этого числа. 

\subsection{Тесты на наличие кластерных эффектов}

В линейной регрессии тест на наличие кластерных постоянных эффектов при нормальных ошибках --- это просто стандартный $F$-тест с линейными ограничениями $H_0 = \alpha_1 = \alpha_2 = \dots =\alpha_c = 0$ в модели~(\ref{eq24.40}). Этот тест сводится к простому сравнению $R^2$ для двух регрессий --- с кластерными дамми-переменными и без них. 

Для CSRE модели тест на кластерные эффекты --- односторонний тест с нулевой гипотезой $H_0: \sigma^2_{\alpha} = 0$ против $H_1 : \sigma^2_{\alpha} > 0$. Можно также сформулировать эквивалентный тест как $H_0: \rho = 0$ против $H_1 : \rho > 0$, используя определение из~(\ref{eq24.27}). Односторонний LM тест этой гипотезы, рассмотренный Моултоном (1987):

\begin{equation}
\label{eq24.43}
LM = \frac{\sum_c (N_c \overline{u}_c)^2 --- \sum_c \sum_i \hat u_{ic}^2}{\hat \sigma^2 [2(\sum_{\hat c} N_c^2 --- N)]^{1/2}},
\end{equation}
где $\hat \sigma^2 = \sum_c \sum_i \hat u^2_{ic} / N$, $\hat u_{ic}$ обозначает остатки из МНК регрессии $y$ на $x$, и $\overline{u}_c$ --- средний остаток для кластера $c$. 

\subsection{Кластеризация в нелинейных моделях}

Нелинейные модели с кластеризованными данными не получили большого внимания в эконометрической литературе. Однако, есть огромное количество работ по биостатистике, фокусирующих внимание на моделях с бинарным исходом (Пендергаст и др. 1996). Также рассматривались другие модели, такие как пуассоновская регрессия и некоторые модели длительности жизни. Иерархические (многоуровневые) модели также активно использовались, особенно для моделей с бинарным исходом. 

Здесь мы продолжим рассматривать сходства между кластеризованными и панельными данными. Как и в линейном случае, данные $(y_i, x_i)$, $i = 1, \dots, N$, обозначаются как $(y_{jc}, x_{jc})$, $j = 1, \dots, N_c$, $c = 1, \dots, C$. Мы предполагаем независимость по $c$, однако допускаем зависимость наблюдений внутри кластера $c$. 

\subsection*{М-оценки с кластеризацией}

Рассмотрим оценку, являющуюся решением нелинейных уравнений

\begin{equation}
\label{eq24.44}
\sum_{c=1}^{C} \sum_{j=1}^{N_c} h (y_{jc}, x_{jc}, \theta) = 0.
\end{equation}
Часто эти уравнения получаются из задачи максимизации или минимизации целевой функции $\sum_c \sum_j q(y_{jc}, x_{jc}, \theta)$; в таком случае $  h (y_{jc}, x_{jc}, \theta) = \partial q(y_{jc}, x_{jc}, \theta) / \partial \theta$. К примеру, для метода квази-максимального правдоподобия, основанного на произведении частных плотностей $ h (y_{jc}, x_{jc}, \theta) = \partial \ln{ f (y_{jc}| x_{jc}, \theta)} / \partial \theta$. 

Мы предполагаем, что данные кластеризованы, поэтому $\Cov[h_{jc}, h_{kc}] \ne 0$.Однако, мы предполагаем $\E[ h (y_{jc}, x_{jc}, \theta)] = 0$, необходимое условие для состоятельности, что исключает модель с кластерными постоянными эффектами, также представленную ниже. 

Робастная к кластерам дисперсия МНК оценки~(\ref{eq24.34}) легко адаптируется к текущей ситуации заменой $x_{jc} x'_{jc}$ на $\partial h_{jc} / \partial \theta'$ и $x_{jc} \hat u_{jc}$ на $h_{jc} (\hat \theta)$. Тогда $\hat \theta$ асимптотически нормальна с робастной к кластерам ковариационной матрицей

\begin{equation}
\label{eq24.45}
\hat \V[\hat \theta] = \left( \sum_{c=1}^C \sum_{j=1}^{N_c} \left. \frac{\partial h'_{jc}}{\partial \theta} \right| _{\hat \theta} \right)^{-1} \sum_{c=1}^C \sum_{j=1}^{N_c} \sum_{k=1}^{N_c} h_{jc}(\hat \theta) h_{kc} (\hat \theta)' \left( \sum_{c=1}^C \sum_{j=1}^{N_c} \left. \frac{\partial h_{jc}}{\partial \theta'} \right| _{\hat \theta} \right)^{-1}. 
\end{equation}
Некоторые компьютерные программы используют эту оценку как стандартную опцию для многих параметрических нелинейных моделей. 

Популярный пример --- это оценка квази-ММП, основанная на произведении частных плотностей внутри кластера вместо совместной плотности. При наличии зависимости по $j$ внутри кластера $c$ мы должны максимизировать логарифм функции правдоподобия

$$
\ln{L(\theta)} = \sum_{c=1}^{C} \ln{f (y_{1c}, \dots, y_{N_c c}, x_{1c}, \dots, x_{N_c c}, \theta)}.
$$ 
Однако с совместной плотностью достаточно тяжело работать и могут быть проблемы с её получением, потому что  многим одномерным плотностям  соответствует узкий класс  многомерных плотностей. Вместо этого мы можем максимизировать

\begin{align}
Q(\theta) & = \sum_{c=1}^C \ln [f(y_{1c}, x_{1c}, \theta) \times \dots \times f(y_{N_c}, x_{N_c}, \theta)] \nonumber\\
& = \sum_{c=1}^C \sum_{j=1}^{N_c} \ln{f(y_{jc}, x_{jc}, \theta)}. \nonumber
\end{align}
Это больше не является истинной функцией правдоподобия, кроме случаев, когда $y_{jc}$ независимы по $j$, поэтому равенство информационных матриц больше не работает. Предшествовавшие формулы применяются с $h_{jc}(\theta) = \partial \ln{f(y_{jc}, x_{jc}, \theta)} / \partial \theta$ и $\partial h_{jc}(\theta) / \partial \theta = \partial^2 \ln{f(y_{jc}, x_{jc}, \theta)} / \partial \theta \partial \theta'$. 

Это означает, что внутри каждого кластера мы не используем правдоподобие по всем наблюдениям сразу, как в случае независимых наблюдений; вместо этого, мы заменяем его суммой правдоподобий по всем элементам кластера. 

\subsection*{Нелинейные кластерные случайные эффекты}

Достаточно общий подход к работе со кластерными эффектами в нелинейных моделях заключается в рассмотрении оценки, которая минимизирует или максимизирует

\begin{equation}
\label{eq24.46}
Q(\beta, \alpha_1, \dots, \alpha_C) = \sum_{c=1}^C \sum_{j=1}^{N_c} q(y_{jc}, x_{jc}, \beta, \alpha_c),
\end{equation}
где кластерные эффекты входят только через скаляр $\alpha_c, \: c = 1, \dots, C$. 

Простая модель со случайными эффектами предполагает, что $\alpha_c$ --- независимые, одинаково распределенные с параметрами $\delta$. Математическое ожидание по $\alpha_c$ даёт целевую функцию

$$
Q(\beta, \delta) = \sum_{c=1}^C \int \sum_{j=1}^{N_c} q(y_{jc}, x_{jc}, \beta, \alpha_c) f(\alpha_c|\delta) d \alpha_c.
$$
Оценивание может быть сложным, особенно если не существует выражения для интеграла суммы в явной форме. 

Часто оказывается несложно получить математическое ожидание по одному наблюдению $\E_{\alpha_c} [q(y_{jc},$ $x_{jc}, \beta, \alpha_c)] = q^* (y_{jc}, x_{jc}, \beta, \delta)$. Тогда можно применять более простую оценку, которая игнорирует кластеризацию и минимизирует $Q^*(\beta, \delta) = \sum_c \sum_j q^* (y_{jc}, x_{jc}, \beta, \delta)$. Она будет состоятельной, однако стандартные ошибки надо будет скорректировать на кластеризацию~(\ref{eq24.45}). 

К примеру, для счётных данных можно сделать кластерный аналог модели со смесью распределения Пуассона и гамма-распределения для панельных данных. Но пуассоновский квази-ММП, игнорирующий кластеризацию, может по-прежнему использоваться, потому что он состоятельный, однако стандартные ошибки требуют коррекции на кластеризацию. 

Следовательно, несмотря на возможность создания нелинейных моделей со случайными эффектами, зачастую можно оценить их параметры, игнорируя кластеризацию и корректируя стандартные ошибки оценок на кластеризацию. Так что единственная причина, по которой можно оценивать модели с кластерными случайными эффектами, заключается в возможном выигрыше в эффективности. 

\subsection*{Нелинейный кластерные постоянные эффекты}

Нелинейные версии моделей с кластерными постоянными эффектами также максимизируют или минимизируют 

$$
Q(\beta, \alpha_1, \dots, \alpha_C) = \sum_{c=1}^C \sum_{j=1}^{N_c} q(y_{jc}, x_{jc}, \beta, \alpha_c),
$$
как в~(\ref{eq24.43}), но теперь параметры $\alpha_1, \dots, \alpha_C$ оцениваются, а не устраняются интегрированием. 

Для больших кластеров, то есть, маленьких $C$ и $N_c \to \infty$, мы просто оптимизируем $Q(\beta, \alpha_1, \dots, \alpha_C)$ по $\beta$ и $\alpha_1, \dots, \alpha_C$. Предполагая, что $\alpha_1, \dots, \alpha_C$ полностью учитывают кластеризацию, можно проводить оценивание, базируясь на стандартных ошибках, полученных в обычном предположении независимости и одинаковой распределенности. Это нелинейный аналог модели с кластерными дамми-переменными~(\ref{eq24.41}).

Для маленьких кластеров, когда $N_c$ мал и $C \to \infty$, мы сталкиваемся с проблемой в виде слишком большого количества несущественных параметров $\alpha_1, \dots, \alpha_C$. В отличие от случая линейных моделей, для нелинейных моделей в общем случае невозможно элиминировать параметры $\alpha_1, \dots, \alpha_C$ (Холл, Северини, 1998). Однако, в соответствии с главой 23 для панельных данных, это возможно сделать в некоторых случаях. 

К примеру, \bfseries бинарная логит-модель с кластерными постоянными эффектами \mdseries специфицирует

\begin{equation}
\label{eq24.47}
\Pr[y_{jc} = 1] = \frac{1}{1+\exp(-\alpha_c -x'_{jc}\beta)},
\end{equation}
где $x_{jc}$ не может включать постоянный член или постоянные по кластеру наблюдения (иначе модель не будет идентифицироваться). Постоянные эффекты $\alpha_c$ могут быть устранены использованием \bfseries условного ММП \mdseries, с условием на сумму ответов внутри кластера, $\sum_{j=1}^{N_c} y_{jc} = N_c \overline{y}_c$. Совместная условная вероятность для $c$-ого кластера:

\begin{align}
\label{eq24.48}
\Pr[y_{1c}, \dots, y_{N_c c} | N_c \overline{y}_c] = & \frac{\exp(\beta \sum_{j=1}^{N_c} x_{jc} y_{jc})}{\sum_{d \in \widetilde{B_c}} \exp(\beta \sum_{j=1}^{N_c} x_{jc} d_{jc}) }  \nonumber\\
& \times \frac{\Gamma [\sum_{j=1}^{N_c} y_{jc} + 1] \Gamma [N_c --- \sum_{j=1}^{N_c} + 1] }{\Gamma (N_c+1)},
\end{align}
где $\widetilde{B_c} = \{ (d_{1c}, \dots, d_{N_c c}) | d_{nc} = 0 \text{ или } 1, \text{ и } \sum_j d_{jc} = \sum_j y_{jc} \}$. Условное правдоподобие --- это произведение по всем кластерам таких членов, как эти, с исключением из выборки кластеров размера 1. Второй член на правой стороне не зависит от неизвестных параметров и поэтому не может повлиять на максимизацию правдоподобия, поэтому его можно игнорировать при максимизации. Максимизировать такое правдоподобие будет затруднительно, потому что для множества $\widetilde{B_c}$ существуют разные способы выбора $N_c$ исходов, где $y_{jc} = 1$ из $(N_{1_c} + N_{0_c})$ исходов в кластере $c$. К счастью, некоторые современные компьютерные пакеты имеют опцию \bfseries условный логит \mdseries для оценки этой модели. Ковариационная матрица всех неизвестных параметров оценивается как обратная к гессиану логарифма функции правдоподобия. 

В качестве другого примера, рассмотрим \bfseries пуассоновскую модель с кластерными постоянными эффектами: \mdseries

$$
y_{jc} \sim \mathcal P [\mu_{jc} = \alpha_c \exp(x'_{jc} \beta)], \qquad c=1, \dots, C, 
$$
где $\mathcal P[\cdot]$ обозначает распределение Пуассона, а $x_{jc}$ исключает константу и постоянные по кластеру переменные. Это обычная пуассоновская модель, за исключением того, что обычное условное среднее $\exp(x'_{jc} \beta)$ умножается на кластерный постоянный эффект $\alpha_c$. Для этой конкретной модели для удаления параметров $\alpha_c$ можно применить целый ряд подходов, включая условный ММП и концентрированный ММП. Состоятельные оценки параметров $\beta$ могут быть получены из 

$$
\sum_{c=1}^C \sum_{j=1}^{N_c} x_{jc} \left( y_{jc} --- \frac{\overline{y}_c}{\overline{\lambda}_c} \lambda_{jc} \right) =0,
$$
где $\lambda_{jc} = \exp(x'_{jc}\beta)$ и $\overline{y}_c = N_c^{-1} \sum_j y_{jc}$ и $\overline{\lambda}_c = N_c^{-1} \sum_j \lambda_{jc}$ --- кластерные средние. Более подробно эта модель обсуждается в применении к панельным данным в разделе 23.7. 

\subsection{Другие методы работы с кластеризованными данными}

Важное свойство кластеризованных данных заключается в том, что существует зависимость между наблюдениями. Близкая тема --- это \bfseries пространственная корреляция \mdseries (см., к примеру, Анселин (2001), Ли (2004)), где единица наблюдения --- регион, к примеру, штат, и наблюдения в близкорасположенных регионах могут коррелировать. 

Случайные эффекты могут распространены и на коэффициенты наклона, в дополнение к константам. Этот подход представлен в следующем разделе \bfseries иерархические линейные модели\mdseries. Для нелинейных моделей есть сходство с панельными данными, рассмотренными в главе 23. 

Для получения робастных к кластеризации стандартных ошибок в ситуациях, где кластеризация ведёт к внутрикластерной корреляции, но не влияет на состоятельность оценок, может использоваться \bfseries бутстрапирование. \mdseries Интуитивно, нужно строить псевдовыборки с возвращением по кластерам $c$; в таком случае мы хотим маленькие кластеры с $C \to \infty$. На $b$-ой репликации мы извлекаем $C$ кластеров с возвращением и используем все домохозяйства $j$ в этих $C$ кластерах, попавших в псевдовыборку, для оценки $\hat \theta_b$, которая является решением~(\ref{eq24.44}). Можно оценить $\V[\hat \theta]$ применяя обычную формулу для дисперсии к $\hat \theta_1, \dots, \hat \theta_B$, где $B$ --- число итераций бутстрапа. Отметим, что псевдовыборки строятся по кластерам, а не по домохозяйствам, потому что мы считаем кластеры независимы и одинаково распределенными, тогда как внутри кластеров допускаем связь между наблюдениями. 

\section{Иерархические линейные модели}

В разделе 24.5 роль кластеров в модели со случайными эффектами сводилась к влиянию на постоянный член в регрессии. В общем случае, модели со случайными эффектами могут разрешать коэффициентам наклона изменяться в зависимости от кластера. Межкластерная изменчивость части параметров регрессии может быть связана с наблюдаемыми характеристиками кластеров. В силу того, что такие модели требуют нескольких уровней спецификации, они называются \bfseries иерархическими моделями.\mdseries

Стандартный способ работы с кластеризованными данными во многих прикладных статистических дисциплинах --- это использование \bfseries иерархических линейных моделей (hierarchical linear model, HLM) \mdseries, также называемых \bfseries многоуровневыми моделями, \mdseries моделей со случайными коэффициентами, моделей с дисперсией коэффициентов (variance components models), и смешанных линейных моделей или \bfseries моделей со смешанными эффектами. \mdseries Этот класс моделей добавляет дополнительную информацию в спецификацию модели. Мы начнём с рассмотрения модели для индивидов, кластеризованных в группы. Затем модель будет адаптирована к коротким панелям, где наблюдения в разные моменты времени кластеризованы для каждого индивида. 

\subsection{Структура модели}

Иерархическая, или многоуровневая модель --- это модель, которая может быть применена к данным с сгруппированной структурой. К примеру, это данные по индивидам внутри региона, такого как штат или страна, или внутри организации, такой как школа или сообщество, или внутри семьи, если используются данные по близнецам. Панельные данные также относятся к сгруппированным данным. В этом случае повторяемые наблюдения за одним и тем же индивидом сгруппированы внутри индивида. 

Начнём с линейной модели

\begin{equation}
\label{eq24.49}
y_{ij} = x'_{ij} \beta_j + u_{ij}, 
\end{equation}
где, в отличие от предыдущих случаев, $K$ параметров $\beta$ изменяются в зависимости от группы (кластера) $j$. В качестве примера можно привести данные об учениках школ. Тогда $y_{ij}$ --- это результирующая переменная, такая как результат теста $i$-ого ученика $j$-ой школы, и предельный эффект изменения регрессора, к примеру, расы, может меняться в зависимости от школы. Заметим, что в стандартной нотации, применяемой в иерархических линейных моделях, нижние индексы пишутся в другом порядке по сравнению с нотацией, использованной в разделе 24.5, где $y_{cj}$ соответствовал бы результату студента $j$ в школе $c$. 

\bfseries Двухуровневая линейная иерархическая модель \mdseries определяет коэффициенты первого уровня в модели~(\ref{eq24.49}) через линейную функцию от случайного члена и переменных второго уровня, здесь --- характеристик школы. Скалярный параметр $\beta_{kj}$ --- $k$-ый компонент $K \times 1$ вектора $\beta_j$. Тогда $\beta_{kj}$ зависит от вектора характеристик школы $w_k$, принимающего значение $w_{kj}$ для $j$-ой школы:

\begin{equation}
\label{eq24.50}
\beta_{kj} = w'_{kj} \gamma_k + u_{kj}, \qquad k = 1, \dots , K, 
\end{equation}
где первый компонент в $w_{kj}$ обычно константа. Векторизуя по $K$ компонентам $\beta$ получаем:

$$\begin{bmatrix}
\beta_{1j} \\ \vdots \\ \beta_{Kj}
\end{bmatrix} = \begin{bmatrix}
w'_{1j} & 0 & 0 \\ 0 & \ddots & 0 \\ 0 & 0 & w'_{Kj}
\end{bmatrix} \begin{bmatrix}
\gamma_{1} \\ \vdots \\ \gamma_{K}
\end{bmatrix} + \begin{bmatrix}
v_{1j} \\ \vdots \\ v_{Kj}
\end{bmatrix}
$$
или в очевидных матричных обозначениях:

\begin{equation}
\label{eq24.51}
\beta_{j} = W_{j} \gamma + v_j.  
\end{equation}

Модель~(\ref{eq24.50}) достаточно гибкая и включает в себя много других моделей как частные случаи. Сюда входят модели со случайными постоянными членами и случайными коэффициентами наклона, но сюда же входят модели с коэффициентами, зависящими от переменных второго уровня $w_j$. Круг моделей очень широк. 

Если $\beta_{kj} = \gamma_k$, то есть не зависит от регрессоров второго уровня или ненаблюдаемых переменных, то $k$-ый коэффициент первого уровня называется \bfseries постоянным коэффициентом. \mdseries  Если все коэффициенты первого уровня постоянны, модель~(\ref{eq24.49}) упрощается до $y_{ij} = x'_{ij} \gamma + u_{ij}$, в этом случае можно оценивать методом наименьших квадратов. Стоит отметить, что термин <<постоянный коэффициент>> серьезно отличается по смыслу от термина <<постоянный эффект>>, используемого в контексте панельных данных. 

Если $\beta_{kj} = w'_{kj} \gamma_k$, то $k$-ый коэффициент первого уровня называют \bfseries неслучайно варьирующим коэффициентом. \mdseries  Тогда коэффициент становится линейной функцией от характеристик школы. Если все коэффициенты первого уровня в модели постоянны, а константа неслучайно варьирует, модель~(\ref{eq24.49}) сокращается до $y_{ij} = x'_{ij} \beta + w'_{1j} \gamma_1 + u_{ij}$ --- стандартной МНК регрессии результирующей переменной на индивидуальные характеристики и характеристики школы. 

Если $\beta_{kj} = \gamma_k + v_{kj}$, то $k$-ый коэффициент первого уровня называют \bfseries случайно варьирующим коэффициентом. \mdseries Тогда коэффициент становится чисто случайным и не зависит от характеристик школы. Если все коэффициенты первого уровня случайно варьируют, $\beta_j = \gamma + v_j$, модель называют \bfseries моделью с дисперсией коэффициентов \mdseries или моделью со случайными коэффициентами. Если все коэффициенты первого уровня постоянны, кроме случайно варьирующей константы, модель~(\ref{eq24.49}) упрощается до $y_{ij} = x'_{ij} \beta + u_{1j} + u_{ij}$ --- модели со случайной константой. 

На практике некоторые коэффициенты первого уровня могут варьировать как случайно, так и неслучайно, как в общем случае, описанном в~(\ref{eq24.49}). Если только константа первого уровня описывается~(\ref{eq24.49}), а другие коэффициенты первого уровня фиксированы, модель~(\ref{eq24.49}) сокращается до $y_{ij} = x'_{ij} \beta + w'_{1j} \gamma_1 + \upsilon_{1j} + u_{ij}$. Это обычная регрессионная модель с ошибкой, состоящей из двух компонентов. Следовательно, есть корреляция ошибок для респондентов из одной школы. 

Иерархические линейные модели можно расширить путем введения дополнительных уровней. К примеру, отдельные студенты (индекс $i$) могут группироваться в школах (индекс $j$), которые сгруппированы в регионы (индекс $k$). Тогда трехуровневая иерархическая линейная модель специфицируется следующим образом: результат студента $y_{ijk} = z'_{ijk} \pi_{jk} + e_{ijk}$, где параметры $\pi_{jk} = X_{jk} \beta_{k} + u_{jk}$, и в свою очередь $\beta_k = W_j \gamma + w_k$. 

Иерархическую линейную модель можно представить как \bfseries смешанную линейную модель \mdseries, потому что подставляя~(\ref{eq24.50}) в~(\ref{eq24.49}) получаем

\begin{equation}
\label{eq24.52}
y_{ij} = (x'_{ij} W_j) \gamma + x'_{ij} v_j + u_{ij}.
\end{equation}
Цель --- оценить параметр регрессии $\gamma$ и ковариационные матрицы ошибок $u_{ij}$ и $v_j$. Предполагается, что ошибки не зависят от регрессоров, поэтому оценка~(\ref{eq24.52}) как сквозной регрессии методом наименьших квадратов дает состоятельные оценки $\gamma$. Иерархическая линейная модель дает более состоятельные оценки, делая предположения о ковариационных матрицах $u_{ij}$ и $v_j$. 

В простейшем случае $v_{jk}$ предполагаются независимыми и одинаково распределенными $\mathcal N [0, \sigma^2]$ и $v_j$ предполагаются независимыми и одинаково распределенными $\mathcal N [0, \Gamma]$. Тогда модель может быть представлена в следующей форме:

\begin{align}
& y_{ij} \sim \mathcal N [x'_{ij} \beta_j, \sigma^2], \nonumber\\
& y_{ij} \sim \mathcal N [W_j \gamma, \Gamma]. \nonumber
\end{align}
Одними из первых такие модели рассмотрели Линдлей и Смит (1972) в рамках байесовского подхода. Коэффициенты $\gamma$ они называли \bfseries гиперпараметрами \mdseries, при этом гиперпараметры, в свою очередь, могут зависеть от гиперпараметров более высокого уровня. Параметры $\gamma$, $\sigma^2$ и $\Gamma$ могут оценены методом максимального правдоподобия или при помощи байесовских методов. Либо можно использовать вариант ММП, аналогичный представленному для смешанных линейных моделей для панельных данных, представленный в разделе 21.7. Наиболее полно этот вопрос рассматривали Брайк и Рауденбуш (1992, 2002). 

\subsection{Иерархические линейные модели для панельных данных}

В иерархических линейных моделях короткие панели интерпретируются как повторяющиеся измерения для одного индивида. Тогда в двухуровневых иерархических моделях индивидуальный уровень становится вторым, тогда как до этого мы рассматривали его как первый. Модель~(\ref{eq24.28}) превращается в

\begin{equation}
\label{eq24.53}
y_{ti} = x'_{ti} \beta_i + u_{ti},
\end{equation}
где, к примеру, $y_{ti}$ обозначает результат студента $i$ в момент времени $t$, и предельный эффект изменения регрессоров, таких как набор предметов, изученных студентом, меняется в зависимости от студента. Скаляр $\beta_{ki}$, $k$-ый элемент вектора $\beta_i$ размерности $K \times 1$, зависит от вектора индивидуальных характеристик $w_k$, принимающих значение $w_{ki}$ для $i$-ого индивида:

\begin{equation}
\label{eq24.54}
\beta_{ki} = w'_{ki} \gamma_k + v_{ki}, \qquad i = 1, \dots, N.
\end{equation}

Модель с индивидуальными эффектами --- это частный случай преставленной модели, где все коэффициенты первого уровня фиксированы, то есть $\beta_{ki} = \gamma_k$, кроме константы $\beta_{1i}$, которая изменяется в зависимости от индивида (показателя второго уровня). 

Модель с индивидуальными постоянными эффектами возникает, если $\beta_{1i}$ не моделируется, а непосредственно оценивается для каждого индивида. Это крайний случай модели с неслучайно варьирующим коэффициентом, где $\beta_{1i} = w'_{1i} \gamma_1$, а $w_1i$ --- $N \times 1$ вектор переменных-индикаторов, где $l$-ый компонент равен 1, если $i=l$ и равен 0 иначе, так что $\beta_{1i} = \gamma_{1i}$. Иерархические линейные модели не слишком хорошо работают с постоянными эффектами. 

Индивидуальные случайные эффекты возникают, если константа $\beta_{1i}$ является случайно варьирующим коэффициентом, то есть $\beta_{1i} = \gamma_1 + v_{1i}$. Очевидно, можно специфицировать более общую модель со случайными эффектами, где $\beta_{ki}$ будет также зависеть от регрессоров $w_{ki}$. 

Как уже было замечено, иерархическая линейная модель --- это смешанная линейная модель. Для панельного случая аналог~(\ref{eq24.52})

$$
y_{ti} = (x'_{ti} W_i) \gamma + x'_{ti} v_j + u_{ti}. 
$$
Модель со случайными эффектами из главы 21 --- это спецификация $y_{ti} = x'_{ti} \gamma + v_j + u_{ti}$.

Стандартное приложение иерархических моделей --- это модели роста, где результирующая переменная $y_{ti}$ --- это индивидуальный интеллект или рост, который является функцией возраста, и предельный эффект возраста может изменяться в зависимости от индивида. Здесь не только константа, но и коэффициент наклона может изменяться в зависимости от индивида. 

\section{Пример кластеризации: расходы на медицинское обслуживание во Вьетнаме}

В этом разделе мы рассмотрим оценивание моделей при наличии кластеризации, потому что это наиболее часто встречающаяся при проведении микроэконометрических исследований проблема. Используются методы, представленные в разделе 24.5. 

Оцениваются линейные и нелинейные регрессионные модели, основанные на данных индивидуального уровня и уровня домохозяйств из опроса Всемирного Банка Обследование уровня жизни во Вьетнаме, Vietnam Living Standarts Survey (VLSS), проводившегося в 1997 --- 1998 гг. В опросе представлена детальная информация по широкому кругу вопросов о 27700 индивидах в приблизительно 6000 домохозяйств, сгруппированных в 194 коммуны. Тогда коммуна рассматривается как кластер, и предполагается, что переменные могут быть коррелированы внутри коммуны. Средний размер кластера в выборке домохозяйств --- 26, максимальный --- 39, минимальный --- 1. Для иллюстрации линейный и нелинейных моделей будут моделироваться три результирующих переменных. 

Во-первых, мы рассмотрим (лог)линейную модель общих годовых расходов домохозяйства на медицинское обслуживание (LNEXP12M) для домохозяйств с положительными расходами как функцию (логарифма) общих расходов домохозяйства (HHEXP), контролируя на несколько стандартных социодемографических переменных, получив кривую Энгеля для расходов на здравоохранение. Интерес представляет коэффициент при общих расходах домохозяйства, являющийся оценкой эластичности спроса домохозяйства на медицинское обслуживание по доходу. 

Во-вторых, мы используем информацию по индивидам для оценки кластеризованных моделей счетных данных того типа расходов на здравоохранение, на который приходится большая доля агрегированных частных расходов на медицинское обслуживание. При моделировании этих переменных мы контролируем на текущий статус здоровья индивида, доход домохозяйства, наличие медицинской страховки и ряд демографических характеристик, таких как возраст, пол, семейный статус и уровень образования главы домохозяйства. Информация о здоровье индивида ограничена наличием болезней (переменная ILLNESS) и травм (переменная INJURY) в период проведения опроса, продолжительностью болезни и количеством дней ограниченной дееспособности. Больше всего нас интересуют коэффициенты при доходе и индикаторе наличия страховки. 

В таблице 24.3 представлены определения и описательные статистики переменных, использованных в этих примерах. 

В обоих случаях основной вопрос заключается в следующем: каково влияние кластеризации на оценки эластичности и как оцененная эластичность изменяется в зависимости от используемых статистических предположений, моделей и оценок? 

\subsection{Обсуждение результатов}

В таблице 24.4 представлены результаты для случаев МНК регрессии, HC $t$-отношения, постоянных и случайных эффектов. Использование устойчивой к гетероскедастичности оценки ковариационной матрицы, не учитывающей кластеризацию, приводит к относительно слабым изменениям в оценке стандартных ошибок. Однако, использование устойчивой к кластеризации оценки ковариационной матрицы~(\ref{eq24.34}) приводит к существенным изменениям в стандартных ошибках. Значение $t$-статистики для эластичности расходов падает с 16.01 до 12.68. Все $t$-статистики становятся меньше, а $t$-статистики для переменных SEX и HHSIZE падают ниже 1.96. Как и ожидалось, игнорирование внутрикластерной корреляции приводит к раздутию $t$-статистик методом наименьших квадратов. 

$F$-тест на одновременное равенство всех постоянных эффектов нулю отвергает нулевую гипотезу. Результаты для модели с фиксированными эффектами сходны с полученными ранее, но $t$-статистики стали ещё меньше. Точечная оценка эластичности по доходу теперь 0.60 против 0.67 для МНК. Однако, никаких заметных отличий в результатах с точки зрения роли и влияния отдельных переменных не наблюдается. 

$\chi^2(1)$ тест на равенство нулю случайной составляющей в константе, основанный на~(\ref{eq24.43}), отвергает нулевую гипотезу, показывая, что модель со случайными эффектами является значимым улучшением стандартной модели. Однако, использование RE модели также не приводит к существенным изменениям оценок влияния отдельных переменных. Как и ожидалось, результаты, полученные доступным ОМНК и в модели со случайными эффектами (ОМНК) оказались очень схожими. Небольшие различия обусловлены различиями в оценках, использованных при ОМНК преобразовании. Оценки ДОМНК основываются на $\hat \rho = 0.12$, полученной усреднением 100 разных оценок $\rho$, полученных при помощи 100 репликаций остатков из МНК. 

\begin{table}[h]
\caption{\label{tab:pred} Расходы на медицину во Вьетнаме: описание данных}
\begin{center}
\begin{tabular}{p{3cm} p{10cm} c c}
\hline
\hline
Данные по & Определение & Среднее &  Стандартное\\
домохозяйствам & & & отклонение \\
\hline
LNEXP12M & Общие расходы домохозяйства на медицинское обслуживание за год & 6.31 & 1.59 \\
AGE & Возраст главы домохозяйства & 48.01 & 13.77 \\
SEX & Равен 1, если глава домохозяйства женщина, 0 иначе & 0.27 & 0.44 \\
HHSIZE & Размер домохозяйства & 4.73 & 1.96 \\
URBAN & Равен 1 для городских домохозяйств, 0 иначе & 0.29 & 0.45 \\
EDUC & Количество лет образования главы домохозяйства & 7.09 & 4.41 \\
HHEXP & Общие номинальные расходы домохозяйства (вьетнамские донги, в ценах 1998) & 15273 & 13020 \\
Индивидуальные данные & & &\\
\hline
PHARVIS & Число посещений аптеки & 0.51 & 1.31 \\
LNMEDEXP (>0) & логарифм общих расходов на медицину для тех, у кого они положительны (вьетнамские донги, в ценах 1998)  & 2.14 & 1.08 \\
AGE & Возраст в годах & 29.7 & 9.6 \\
SEX & Равен 1, если респондент --- мужчина & 0.51 & 0.49 \\
MARRIED & Равен 1 для состоящих в браке респондентов & 0.40 & 0.49 \\
EDUC & Уровень полученного образования & 3.38 & 1.94 \\
ILLNESS & Число болезеней, перенесенных за последние 12 месяцев & 0.62 & 0.90 \\
INJURY & Равен 1, если были травмы в период наблюдения & 0.62 & 0.90 \\
ILLDAYS & Число дней, которые человек был болен & 2.80 & 5.45 \\
ACTDAYS & Число дней ограниченной активности & 0.06 & 1.11 \\
INSURANCE & Равен 1, если у респондента есть медицинская страховка & 0.16 & 0.37 \\
MEDEXP (>0) & Медицинские расходы при условии, что они положительны & 21.04 & 208 \\
MEDEXP & Медицинские расходы (вьетнамские донги, в ценах 1998) & 6.13 & 112.75 \\
\hline
\hline
\end{tabular}
\end{center}
\end{table}

Абсолютные различия между результатами  моделей со случайными и фиксированными эффектами сравнительно невелики. Неформальное сравнение не позволяет сказать, какая модель работает значимо лучше; однако, тест Хаусмана показывает, что есть статистически значимые различия между двумя наборами оценок. 

Подводя итог, полученные результаты говорят о том, что необходимо учитывать внутрикластерную корреляцию, однако то, как мы это сделаем, не имеет большого значения. 

Теперь рассмотрим результаты, полученные для счетной переменной --- количества посещений аптеки индивидами (PHARVIS) --- при помощи пуассоновской модели. Это очень интересный показатель, потому что высокая доля медицинских расходов во Вьетнаме приходится на лекарства, которые люди покупают непосредственно в аптеках и принимают самостоятельно, без консультаций с врачом. Считается, что такая форма лечения по качеству хуже лечения, проводимого профессиональным врачом. Во Вьетнаме только часть населения, как правило, высокооплачиваемые работники государственного и частного секторов, могут купить себе медицинскую страховку, которая дает им право на лечение в государственных больницах и получение необходимых лекарств. Из таблицы 24.3 видно, что 16\% населения имеют такую страховку. 


\begin{sidewaystable}[!htbp]
\caption{\label{tab:pred} Расходы на медицину во Вьетнаме: FE и RE модели для положительных расходов}
\begin{minipage}{\textwidth}
\begin{center}
\begin{tabular}{lcccccccccc}
\hline
\hline
& \multicolumn{4}{c}{МНК} & \multicolumn{2}{c}{ДОМНК} & \multicolumn{2}{c}{FE} & \multicolumn{2}{c}{RE (ОМНК)} \\
\cmidrule(r){2-5} \cmidrule(r){6-7} \cmidrule(r){8-9} \cmidrule(r){10-11}
Переменная\footnote{$R^2_W$ --- $R^2$ для within-регрессии; $R^2_B$ --- $R^2$ для between-регрессии; $R^2$ --- общий $R^2$} & Коэф. & OLS & $|t|$-Гет. & $|t|$-Класт. & Коэф. & $|t|$ & Коэф. & $|t|$ & Коэф. & $|t|$ \\
\hline
LNHHEXP & 0.670 & 16.01 & 15.76 & 12.68 & 0.620 & 14.14 & 0.603 & 11.61 & 0.626 & 13.39 \\
AGE & 0.010 & 6.39 & 6.36 & 5.46 & 0.011 & 6.96 & 0.011 & 6.93 & 0.011 & 6.85 \\
SEX & 0.097 & 1.88 & 1.88 & 1.64 & 0.108 & 2.13 & 0.112 & 2.17 & 0.106 & 2.09 \\
HHSIZE & 0.028 & 2.19 & 2.15 & 1.89 & 0.014 & 1.06 & 0.010 & 0.76 & 0.015 & 1.17 \\
FARM & 0.134 & 2.73 & 2.72 & 2.22 & 0.088 & 1.58 & 0.069 & 1.14 & 0.092 & 1.69\\
EDUC & $-0.090$ & 7.36 & 7.07 & 6.03 & $-0.61$ & 4.73 & $-0.51$ & 3.76 & $-0.063$ & 4.92 \\
CONS & $-0.510$ & 1.34 & 1.34 & 1.09 & $-0.051$ & 0.30 & $-0.051$ & 0.08 & $-0.166$ & 0.40 \\
$R^2$ & \multicolumn{2}{c}{0.088} &  &  &  &  &  &  &  &  \\
$R^2_W$ (>0) & \multicolumn{8}{c}{ } & \multicolumn{2}{c}{0.051} \\
$R^2_B$ & \multicolumn{8}{c}{ } & \multicolumn{2}{c}{0.288} \\
$\rho$ & \multicolumn{4}{c}{ } & \multicolumn{2}{c}{0.12} & \multicolumn{4}{c}{ }\\
$\frac{\sigma^2_{\alpha}}{\sigma^2_{\alpha} + \sigma^2}$ & \multicolumn{8}{c}{ } & \multicolumn{2}{c}{0.093}\\
$F(193, 4806)$ & \multicolumn{6}{c}{ } & \multicolumn{2}{c}{3.49} & \multicolumn{2}{c}{ } \\
$\chi^2(1)$ & \multicolumn{8}{c}{ } & \multicolumn{2}{c}{432.75} \\
Хаусман $\chi^2(6)$ & \multicolumn{6}{c}{ } & \multicolumn{4}{c}{17.89} \\
N & \multicolumn{4}{c}{5006} & \multicolumn{2}{c}{4977} & \multicolumn{4}{c}{ } \\
\hline
\hline
\end{tabular}
\end{center}
\end{minipage}
\end{sidewaystable}


 
\begin{table}
\caption{\label{tab:pred} Число посещений аптек}
\begin{center}
\begin{tabular}{lccccccccccc}
\hline
\hline
Число & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10+ \\
\hline
PHARVIS & 20639 & 3827 & 1716 & 776 & 359 & 174 & 64 & 43 & 16 & 4 & 115 \\
PHARVIS (доля) & 0.744 & 0.137 & 0.062 & 0.028 & 0.013 & 0.006 & 0.002 & 0.001 & 0.000 & 0.000 & 0.004 \\
\hline
\hline
\end{tabular}
\end{center}
\end{table}

В таблице 24.5 приведено наблюдаемое частотное распределение переменной PHARVIS. Около $26\%$ респондентов по меньшей мере один раз за период наблюдения посещали аптеку и около $95\%$ делали это не более трех раз. 


\begin{table}[h]
\caption{\label{tab:pred} RE и FE модели для числа посещений аптек}
\begin{center}
\begin{tabular}{ p{2.5cm} cc cc cc cc}
\hline
 & \multicolumn{2}{c}{Пуассон} & Уст. к гет. & Уст. кластер & \multicolumn{2}{c}{FE Пуассон} & \multicolumn{2}{c}{RE Пуассон}\\
\cmidrule(r){2-3} \cmidrule(r){4-4} \cmidrule(r){5-5} \cmidrule(r){6-7} \cmidrule(r){8-9}
Переменная & Коэф. & $|t|$ & $|t|$ & $|t|$ & Коэф. & $|t|$ & Коэф. & $|t|$ \\
\hline
CONS & $-1.637$ & 35.78 & 18.81 & 12.25 & ---  & --- & 1.318 & 19.41 \\
LNHHEXP & 0.078 & 5.68 & 3.08 & 1.90 & $-0.114$ & 6.01 & $-0.095$ & 4.95 \\
INSURANCE & $-0.245$ & 9.57 & 5.68 & 4.29 & $-0.163$ & $6.17$ & $-0.178$ & $6.44$ \\
SEX & 0.084 & 4.96 & 2.76 & 2.73 & 0.098 & 5.75 & 0.099 & 571 \\
AGE & 0.024 & 2.38 & 1.27 & 1.06 & 0.003 & 0.32 & 0.005 & 0.55 \\
MARRIED & 0.124 & 5.92 & 2.96 & 2.78 & 0.164 & 7.59 & 0.158 & 7.38 \\
ILLDAYS & 0.042 & 40.00 & 14.91 & 12.91 & 0.046 & 40.14 & 0.46 & 40.18 \\
ACTDAYS & 0.008 & 1.71 & 0.43 & 0.45 & 0.025 & 4.53 & 0.024 & 4.35 \\
INJURY & 0.171 & 2.30 & 0.84 & 0.85 & 0.144 & 1.80 & 0.143 & 1.80 \\
ILLNESS & 0.562 & 87.15 & 24.60 & 21.81 & 0,584 & 73.45 & 0.585 & 74.16 \\
EDUC & $-0.52$ & 11.10 & 6.47 & 3.92 & $-0.24$ & 4.18 & $-0.026$ & 4.61\\
$-\ln L$ & & \multicolumn{2}{c}{25281} &  & \multicolumn{2}{c}{22446} & \multicolumn{2}{c}{23419} \\
N & & \multicolumn{2}{c}{27765} & & \multicolumn{2}{c}{27671} & \multicolumn{2}{c}{27765} \\
\hline
\hline
\end{tabular}
\end{center}
\end{table}


В таблице 24.6 представлены результаты оценивания для нескольких вариантов пуассоновской регрессии, аналогичных приведенными в таблице 24.4 для линейной регрессии. В первом столбце даны оценки ММП, во втором --- обычные нескоректирвоанные $t$-статистики. Далее приводятся робастные к гетероскедастичности $t$-статистики. Они заметно меньше, иногда более чем вдвое, чем нескорректированные. В четвертом столбце находятся скорректированные на кластеризацию $t$-отношения, основанные на~(\ref{eq24.45}). Они заметно меньше, чем полученные другими способами статистики, что говорит о наличии значительной внутрикластерной корреляции. Средний размер кластера больше 140, поэтому даже небольшая внутрикластерная корреляция может сильно <<раздуть>> $t$-статистики. 

После этого мы рассматриваем моделирование внутрикластерной корреляции при помощи моделей со случайными и фиксированными эффектами. Модель с фиксированными эффектами оценивается при помощи условного ММП. Кластеры, где недостаточно внутрикластерной изменчивости, исключаются из рассмотрения. Полученные коэффициенты кардинально отличаются от полученных для пуассоновской регрессии при помощи метода максимального правдоподобия. Во-первых, коэффициент при $\ln(HHEXP)$ из значимого положительного становится значимым отрицательным. Это означает, что стандартная регрессия определяет посещение аптеки как нормальный товар, а регрессия с фиксированными эффектами --- как инфериорный; то есть, люди меньше занимаются самолечением по мере роста дохода. Это может быть объяснено тем, что постоянные эффекты учитывают влияние пропущенных переменных, коррелированных с зависимой переменной. К пропущенным переменным можно отнести количество и качество альтернативных медицинских услуг, доступных жителям коммуны. Они могут серьезно изменяться в зависимости от географического расположения и экономического статуса коммуны. 

Последние два столбца таблицы 24.6 показывают результаты, полученные по модели со случайными эффектами. Здесь предполагается, что константа в пуассоновской модели изменяется в зависимости от кластера и случайна, при этом все константы извлекаются из одного одномерного распределения --- гамма-распределения с единичным средним. Такая формулировка привлекает тем, что не требует дополнительных условий. Пуассоновская модель со случайными эффектами с постоянным членом, подчиняющимся гамма-распределению, была предложена Хаусманом и другими (1984); её функцию правдоподобия можно представить аналитически и адаптировать для случая кластеризованных данных. Оценки, полученные при помощи моделей со случайными эффектами, качественно похожи на полученные по модели с фиксированными эффектами. Однако, оценка коэффициента при доходе --- одной из ключевых переменных --- серьезно отличается от полученной для простой пуассоновской регрессии. 

Этот пример показывает, что внутрикластерная корреляция может влиять не только на эффективность, но и на сами оценки. 

\section{Комплексные опросы}

В предыдущих разделах наше внимание было сосредоточено на стратификации, взвешивании и кластеризации по отдельности. Здесь мы сосредоточимся на комплексных опросах, которые используют многоуровневые стратифицированные выборки с кластеризацией. Такие опросы фокусируются на описании генеральной совокупности в условиях, когда её параметры могут изменяться в зависимости от страты. Тогда используются взвешенные оценки и они же рассматриваются как оценки параметров генеральной совокупности. Цель --- получение состоятельной оценки дисперсии взвешенной оценки с учетом кластеризации, которая может быть сложнее, чем рассмотренная в разделе 24.5. 

\subsection{Оценка дисперсии в комплексных опросах}

Рассмотрим следующую ситуацию. $i$-ое наблюдение в выборке --- это домохозяйство $j$, находящееся в кластере $c$ из страты $s$. К примеру, зависимая переменная обозначается $y_{scj}$, хотя, строго говоря, наблюдение $(s, c, j)$ надо представлять как $(s, c_s, j_{C_s})$. Данные --- это наборы $(y_{scj}, x_{scj}, w_{scj})$, где $w_{scj}$ --- это выборочные веса, обратно пропорциональные вероятности попадания наблюдения в выборку. Нижние индексы упорядочены по уровню дезагрегирования, в обратном порядке по сравнению с нотацией из раздела 24.5. 

Внутри страты используется двухшаговый или многошаговый отбор, поэтому домохозяйства попадают в выборку в результате по меньшей мере двух последовательных отборов. На первом шаге случайным образом выбирается подмножество  из всех PSU внутри страты. На втором --- выбирается подмножество из домохозяйств, входящих в выбранные PSU. На этом этапе возможен кластеризованный отбор. Также возможны дальнейшие отборы при использовании SSU. 

\subsection*{Дисперсия линейной статистики}

Начнем с рассмотрения оценки дисперсии линейной статистики, которую можно просуммировать по стратам, PSU и домохозяйствам:

$$
\hat u = \sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} u_{scj} = \sum_{s=1}^S \sum_{c=1}^{C_s} u_{sc}, 
$$
где $u_{sc}$ --- это сумма по PSU, то есть
$$
u_{sc} = \sum_{j=1}^{N_{cs}} u_{scj}.
$$
Примеры $u_{scj}$, такие, как взвешенное среднее или взвешенная регрессия, приведены ниже. Дисперсия $u$:

$$
\V[u] = \sum_{s=1}^S \sum_{c=1}^{C_s} \V[u_{sc}] = \sum_{s=1}^S C_s \sigma^2_s, 
$$
В предположении, что $u_{sc}$ независимы по стратам и одинаково распределены по PSU с общей дисперсией $ \sigma^2_s$. Если $u_{sc}$ независимы по $c$ и одинаково распределены, можно использовать обычную несмещенную оценку дисперсии $ \sigma^2_s$, так что $\hat  \sigma^2_s = (C_s --- 1)^{-1} \sum_c (u_{sc} --- \overline{u}_s)^2$. Тогда 

\begin{equation}
\label{eq24.55}
\V[\hat u] = \sum_{s=1}^S \frac{C_s}{C_s --- 1}  \sum_{c=1}^{C_s} (u_{sc} --- \overline{u}_s)^2, 
\end{equation}
где $\overline{u}_s = C_s^{-1} \sum_c u_{sc}$ --- среднее по страте сумм по PSU. 

Эта оценка допускает кластеризацию внутри PSU, потому что 

\begin{align}
\sum_{c=1}^{C_s} (u_{sc} --- \overline{u}_s)^2 & = \sum_{c=1}^{C_s} \left(  \sum_{j=1}^{N_{cs}} u_{scj} ---  \overline{u}_s \right)^2 \nonumber\\
& =\sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} (u_{scj} --- \overline{u}_s)^2 + \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} \sum_{k \ne j}^{N_{cs}} (u_{scj} --- \overline{u}_s)(u_{sck} --- \overline{u}_s). \nonumber
\end{align}
Первая сумма проистекает из дисперсии при SRS. Вторая сумма будет положительной при кластеризованном отборе и тем самым увеличит дисперсию. По поводу вида отбора внутри страты и типа кластеризации не делается никаких предположений. К примеру, (\ref{eq24.55}) дает правильные стандартные ошибки даже при трехшаговом отборе с дальнейшим отбором внутри SSU. 

Оценка~(\ref{eq24.55}) требует, чтобы из каждой страты извлекалось по меньшей мере два PSU. Если извлекается только один PSU, одна из возможностей --- это включить страту с одним PSU в другую страту, которая а-приори считается похожей. Это допустимо при $C_s \ge 2$ то есть, если на одну страту приходится по меньшей мере два PSU. Это приведет к завышению оценки $\V[u]$, потому что различия в средних по стратам привносят смещение вверх. \footnote{Это метод не применим к Текущему обследованию населения, CPS, потому что во многие страты входит только один PSU, а для остальных только один PSU попадает в опрос. Для борьбы с этим формируются псевдо-страты и используются методы репликации для получения новых выборок из псевдо-страт. См. Бюро переписи населения США (U.S. Bureau of Census, 2002)}

На практике PSU часто отбираются без возвращения, поэтому в $u_{sc}$ присутствует определенная зависимость. Тогда~(\ref{eq24.55}) переоценивает $\V[u]$, аналогично ситуации из раздела 24.2.3. В этом случае используются более сложные формулы. 

\subsection*{Дисперсия взвешенного среднего}

Среднее по генеральной совокупности оценивается как отношение суммы взвешенных $y_{scj}$, назовем её $\hat y$, к сумме выборочных весов, $\hat w$. Тогда

$$
\overline{y}_W = \hat y / \hat w = \sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} w_{scj} y_{scj} \bigl/  \sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} w_{scj}.
$$

Если выборочные веса известны, получаем
$$
\overline{y}_W = \sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} w^*_{scj} y_{scj},
$$
где $w^*_{scj} =w_{scj} / \hat w$ и $\V[\overline{y}_W]$ может быть рассчитана при помощи~(\ref{eq24.55}) с $u_{scj} = w^*_{scj} y_{scj}$. 

Если выборочные веса рассматриваются как неизвестные, можно использовать \bfseries дельта-метод \mdseries или \bfseries  метод линеаризации \mdseries для получения $\V[\hat y / \hat w]$ как функции от $\V[\hat y]$, $\V[\hat w]$ и $\Cov[\hat y, \hat w]$. Первые два показателя могут быть оценены при помощи~(\ref{eq24.55}) с $u_{scj} = w_{scj} y_{scj}$ и $u_{scj} = w_{scj}$. Третий может быть оценен, если заменить $(u_{sc} --- \overline{u}_s)^2$ в~(\ref{eq24.55}) на $(u_{sc} --- \overline{u}_s) (v_{sc} --- \overline{v}_s)$ и принять $u_{scj} = w_{scj} y_{scj}$ и $v_{scj} = w_{scj}$. Это пример оценки-соотношения. 

Для нелинейных статистик, таких как оценки-соотношения, в литературе предлагаются другие методы, основанные на техниках \bfseries джекнайф \mdseries и \bfseries повторяющихся сбалансированных репликациях. \mdseries Из-за нелинейности оценки дисперсии больше не являются несмещенными, но остаются состоятельными при количестве страт $S \to \infty$ (см. Кревски и Рао, 1981). Некоторые результаты при фиксированном S и $\sum_{c=1}^{C_s} N_{cs} \to \infty$ приведены в Волтер (1985). Можно также использовать \bfseries бутстрап\mdseries, но тут требуется осторожность. Подробнее см. Рао и Ву (1988) и Шао и Ту (1995). 


\subsection*{Дисперсия оценки взвешенного МНК}

Оценка $\hat \beta_W$ взвешенного МНК параметров регрессии (см. раздел 24.3) является решением

$$
\sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} w_{scj} x_{scj} (y_{scj} --- x'_{scj} \hat \beta_W) = 0.
$$

Обычными алгебраическими преобразованиями получаем
$$
\hat \beta_W --- \beta = \left( \sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} w_{scj} x_{scj} x'_{scj} \right)^{-1} \times \sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} w_{scj} (y_{scj} --- x'_{scj} \hat \beta_W).
$$
Соответственно, получаем дисперсию $\beta$ в сэндвич-форме $\V[\hat \beta] = A^{-1} B A^{-1}$, где B --- дисперсия второй тройной сумму, которую можно оценить при помощи~(\ref{eq24.55}) с $u_{scj} = w_{scj} x_{scj} (y_{scj} --- x'_{scj} \hat \beta_W)$. 

\subsection*{Дисперсия взвешенной М-оценки}

В достаточно общем случае рассматривается взвешенная М-оценка $\hat \theta_W$, которая является решением

$$
\sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} w_{scj} h( y_{scj}, x_{scj}, \hat \theta_W) = 0
$$
Примеры включают линейную регрессию с $h_{scj} = x_{scj} (y_{scj} --- x'_{scj} \beta)$ и квази-ММП с $h_{scj} = \partial \ln f (y_{scj} | x_{scj}, \theta) / \partial \theta$. 

Предполагая состоятельную оценку $\theta$, которая требует $\E[h(y_{scj}, x_{scj}, \theta)] = 0$, мы можем использовать разложение в ряд Тейлора первого порядка и получить

$$
\sqrt{N} (\hat \theta_W --- \theta) \overset{d}{\to} \mathcal N \left[  0, A^{-1} B A'^{-1} \right],
$$
где
$$
A = \plim N^{-1} \sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} w_{scj} \frac{\partial h(y_{scj}, x_{scj}, \theta)}{\partial \theta'}
$$
и
$$
B = \plim N^{-1} \sum_{s=1}^S \sum_{c=1}^{C_s} \sum_{j=1}^{N_{cs}} \sum_{k=1}^{N_{cs}} w_{scj} w_{sck} h(y_{scj}, x_{scj}, \theta)  \frac{\partial h(y_{sck}, x_{sck}, \theta)}{\partial \theta'},
$$
где выражение для $B$ предполагает независимость $h_{scj}$ по стратам и кластерам, но разрешает зависимость внутри кластера. Оценивание $A$ очевидно. Для $B$ используется~(\ref{eq24.55}) с $u_{scj} = w_{scj} h_{scj}$, поэтому

$$
B = \sum_{s=1}^S \frac{C_s}{C_s --- 1} \sum_{c=1}^{C_s} [\overline{z}_{sc} --- \overline{z}_s]^2, 
$$
где $ \overline{z}_{sc} = \sum_{j=1}^{N_{cs}} w_{scj} h (y_{scj}, x_{scj}, \theta)$ и $\overline{z}_{s} = C_s^{-1} \sum_{c=1}^{C_s} \overline{z}_{s}$. 

\subsection*{Эндогенная стратификация}

Саката (1998) распространил эти результаты на случай эндогенного отбора. Он рассматривает параметры ценза и разрабатывает асимптотическую теорию, предполагая, что количество страт $S \to \infty$. Результаты аналогичны представленным в предыдущем разделе. 

\section{Практические замечания}

В микроэкономических исследованиях обычным является использование структурного подхода. При отсутствии эндогенной стратификации используются невзвешенные оценки. Главная проблема заключается в поиске правильных стандартных ошибок при наличии кластеризации. При случайных кластерных эффектах потери в эффективности от игнорирования кластеризации невелики. В некоторых пакетах могут быть встроены робастные к кластеризации оценки стандартных ошибок (не путать с робастными к гетероскедастичности), которые подходят для случайных кластерных эффектов и большого количества кластеров. CSRE и CSFE модели могут быть реализованы при помощи МНК, при условии (в случае CSFE), что кластеров не слишком много. В качестве альтернативы можно проводить оценивание при помощи процедур для панельных данных, если они поддерживают несбалансированные панели. Как и в случае в панельными данными, большинство исследователей, не занимающихся глубоко эконометрикой, могут быть удовлетворены моделями со случайными эффектами, но для получения состоятельных оценок иногда всё же требуется использовать постоянные эффекты. 

Если применяется описательный подход и параметры изменяются в зависимости от страты, необходимо использовать взвешивание. Можно использовать взвешивание для МНК оценок, но его необходимо комбинировать с робастными к кластеризации стандартными ошибками. В некоторых пакетах есть модули для оценки опросных данных, которые позволяют получить робастные к кластеризации стандартные ошибки методами, представленными в разделе 24.6. В пакете SUDAAN представлены многие методы, рассмотренные в этой главе для линейных и основных нелинейных моделей. 

\section{Библиографические заметки}

\begin{enumerate}
\item[$24.2 --- 24.3$] Есть множество литературы, посвященной отбору. Классические ссылки на выборочные опросы включают Киш (1965) и Кохран (1997, первое издание в 1953). В работе Скиннера (1989) приведен хороший обзор, у Гровза (1989) представлено достаточно нетехническое описание подходов к опросам, используемых во многих общественных науках, и при этом рассмотрено много полезных на практике вопросов. Для полноты мы представили это литературу по отбору при формировании опросов, хотя эконометрические исследования редко используют методы, представленные в разделе 24.8. Есть немного эконометрических работ, за исключением Падни (1989) и Дитона (1997) и главы в книге Уллаха и Бройнига (1998). 
\item[$24.4$] Больше всего внимания в эконометрической литературе было уделено учету эндогенной стратификации. Литературы много и мы ограничиваемся простым обзором. Подробнее эти вопросы разбирает Амэмия (1985), где приведено много ссылок, включая Мански и Лерман (1977) для моделей дискретного выбора и Хаусман и Уайз (1979) для моделей с самоотбором выборки. Простые взвешенные оценки как правило применимы, хотя и неэффективны. Имбенс и Ланкастер (1996) рассматривают способ реализации на практике эффективной оценки при заданной спецификации условной плотности. 
\item[$24.5$] Для микроэконометрических приложений учет кластеризации очень важен. Работы Клока (1981) и Моултона (1986, 1990) сыграли ключевую роль в осознании этой проблемы. Дэвис (2002) рассматривает общий подход к моделям с многоуровневыми ошибками. Гробард и Корн (1994) хорошо разбирают линейный регрессионный анализ в приложении к кластеризованным данным. Они рассматривают модели как со случайными, так и с постоянными эффектами, с упором на предположения, которые должны быть выполнены, чтобы оценки модели со случайными эффектами оставались применимыми. Пендергаст и другие (1996) приводят обзор методов анализа кластеризованных бинарных данных. Из-за того, что средний член на правой стороне уравнения~(\ref{eq24.34}) включает усреднение по кластерам, точность этой оценки зависит от количества кластеров. Последствия использования робастных к кластеризации оценок ковариационной матрицы при малом числе кластеров остается интересной темой для исследования (Доналд и Ланг, 2001; Ангрист и Лэви, 2002). Вулдридж (2003) приводит обзор. 
\item[$24.6$] Иерархические линейные модели оцень активно используются в общественных науках. Брайк и Рауденбуш (2002) приводят хороший обзор, покрывающий ситуации бинарных, порядковых, счетных и мультиномиальных зависимых переменных как с точки зрения вероятности, так и с точки зрения байесовского подхода. 
\item[$24.7$] Дитон (1997) рассматривает ряд вопросов, связанных с оценкой моделей по кластеризованным данным опросов о стандартах жизни (Living Standarts Surveys), проводимых Всемирным Банком в развивающихся странах. 
\item[$24.8$] Во многих стандартных статистических пакетах (к примерах, STATA и SUDAAN) встроены процедуры для оценки моделей с постоянными и случайными кластерными эффектами для линейных и нелинейных моделей по сквозным и панельным данным. 
\end{enumerate}

\subsection*{Упражнения}

\begin{enumerate}
\item[$24 --- 1$]
\begin{enumerate}
\item Проверьте выражение для $\sum_c$, приведенное в~(\ref{eq24.25}).
\item Докажите состоятельность для оценок $\hat \sigma ^2$ и $\hat \rho$ в CSRE модели.
\item Рассмотрите смещение в стандартных ошибках для CSRE модели по сбалансированным кластерам. Покажите, что в этом случае $\E [\sum_c \sum_j \hat u^2_{cj}] = \sigma^2 [N --- K (1 + \rho (m-1))]$. 
\end{enumerate}

\item[$24 --- 2$] (адаптировано из Гринвальда, 1983) Рассмотрите линейную регрессионную модель $y = X \beta + u$, где $\E[u] = 0$ и $\E [uu'] = \sigma^2 \Omega^* = \Omega$. При помощи стандартного результата для МНК оценки $\hat \beta = (X'X)^{-1} X'y$ (см. раздел 4.4) можно получить правильное выражение для $\V[\hat \beta]$ как $V_2 = (X'X)^{-1} (X' \Omega X)^{-1} (X'X)^{-1}$, тогда как $V_1 = \hat \sigma^2 (X'X)^{-1}$ с $\hat \sigma^2 = \hat u' \hat u / (N-K)$ некорректна при $\Omega \ne I$. 
\begin{enumerate}
\item Покажите, что смещение $V_1$ можно задать как $B = B_1 + B_2$, где $B_2 = (X'X)^{-1} X' (\Omega --- \sigma^2 I) X (X'X)^{-1}$ и $B_1 = (N --- K)^{-1} \tr\{B_2 (X'X)\} (X'X)^{-1}$ (Гринвальд называет $B_2$ <<прямым смещением>>)
\item Оцените два члена для специального случая $X'X = I_K$. Покажите, что $B \to B_2$ при $N \to \infty$. 
\end{enumerate}

\item[$24 --- 3$] Рассмотрите робастную к кластеризации МНК оценку дисперсии~(\ref{eq24.33}). Предположите, что есть два уровня кластеризации. К примеру, в терминах эмпирических приложений из этой главы, кластеризация может быть на уровне семьи и, затем, коммуны, если несколько членов одной семьи из одной коммуны включены в выборку. Как будет модифицироваться формула при наличии двух уровней кластеризации?

\item[$24 --- 4$] Для этого упражнения используйте $50\%$ выборки из Обследование уровня жизни во Вьетнаме, VLSS. Определите $y = 1$, если индивид по меньшей мере один раз посещал аптеку (PHARVIS) и $y = 0$ иначе. Этот пример предполагает, что у Вас есть доступ к программе, работающей с кластеризованными данными. 
\begin{enumerate}
\item Используя те же объясняющие переменные, что были использованы в пуассоновской модели в разделе 24.7, оцените бинарную логит-модель методом максимального правдоподобия, используя как стандартную оценку дисперсии, так и робастную в сэндвич-форме. 
\item Переоцените модель из пункта $(a)$, используя робастные к кластеризации стандартные ошибки. Объясните разницу между робастными стандартными ошибками из пунктов $(a)$ и $(b)$. 
\item Используйте переменную <<commune>> в качестве идентификатора кластера. Переоцените логит-модель при помощи моделей с постоянными и случайными кластерными эффектами. Сравните оценки и стандартные ошибки коэффициентов при LNHHEXP и INSURANCE. Влияет ли кластеризация в данных на выводы о значимости этих переменных? 
\end{enumerate}

\end{enumerate}




