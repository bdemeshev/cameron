
\chapter {Методы симуляционного моделирования}


\section{Введение}
Оценивание параметров нелинейными методами, рассмотренными ранее, не предполагало  наличия решений в явном виде. Тем не менее, теория сильно опирается на аналитическое представление результатов. В частности, предполагалось, что целевая функция может быть задана аналитически и асимптотическое распределение формировалось на основе линеаризации оцениваемых уравнений. 

В этой главе описаны методы, основанные на симуляционном моделировании. При расчете ММП-оценки, которая была изложена в Главе 5, предполагалось, что плотность $f(y|x,\theta)$ может быть записана аналитически. При отсутствии аналитического выражения для плотности, возможно использовать ММП-оценку при наличии хорошей аппроксимации $\hat{f}(y|x,\theta)$ для $f(y|x,\theta)$, при построении функции правдоподобия.
Главная причина отсутствия аналитического выражения для плотности заключается в наличии трудности невыразимого аналитически  математического ожидания  в определении  $f(y|x,\theta)$. Например, в модели со случайными коэффициентами могут возникнуть трудности при интегрировании по случайным параметрам. Если значение математического ожидания заменить аппроксимирующим значением, полученным методом Монте-Карло, тогда результирующая оценка будет называться оценкой, рассчитанной при помощи симуляционного моделирования. Аналогичный симуляционный подход может быть применен к оценке методом моментов в основе которого лежит оценка момента условного среднего, для которого не существует решения в аналитической форме. При использовании метода моментов возможно получить состоятельные оценки параметров с меньшим количеством симуляций, чем в случае с ММП-оценками. 

Имитационные методы оценки требуют больших объемов вычислений, поскольку в них применяется метод Монте-Карло для построения выборки. При использовании этих методов ставятся вопросы о точности приближенных значений, эффективности расчетов и свойствах выборочных оценок, рассчитанных на основе приближенных значений.

В Разделе 12.2 представлены примеры на которых показывается целесообразность применения методов имитационного моделирования. В Разделе 12.3 даны основы расчета интегралов, это необходимо поскольку математическое ожидание случайной величины задается интегралом. В Разделах 12.4 и 12.5 рассмотрены симуляционный метод максимального правдоподобия и симуляционный метод моментов; В Разделе 12.6 представлены следствия применениях этих методов. Для симуляционного моделирования важны основные техники (раздел 12.7) и псевдо-случайные числа (раздел 12.8).

\section{Примеры}

Рассмотрим примеры, где условная плотность $y$ при заданных значениях $x$ и вектора параметров $\theta$ рассчитывается при помощи следующего интеграла

\begin{equation}
f(y|x,\theta)=\int{h(y|x,\theta,u)g(u)du},
\end{equation}
где функциональная форма $h(\cdot)$ и $g(\cdot)$ известна и $u$ обозначает случайную величину, не обязательно ошибки модели, по которой производится интегрирование. Если для интеграла нет аналитического решения, а следовательно отсутствует аналитическое выражение для функции правдоподобия, следует использовать методы симуляционного моделирования.

\subsection{Модель со случайными коэффициентами}

В модели \textbf{со случайными параметрами} или модели \textbf{со случайными коэффициентами} возможно изменение значений коэффициентов регрессии между отдельными наблюдениями в соответствии с некоторым случайным распределением. Полностью параметрическая модель со случайными коэффициентами определяет переменную $y_i$ как зависимую от $x_i$ при заданных параметрах $\gamma_i$, функция распределения зависимой переменной представлена как $f(y_i|x_i,\gamma_i)$, где $\gamma_i$ независимы и одинаково распределены  с плотностью $g(\gamma_i|\theta)$. Выводы построены на условной плотности распределения $y_i$ при заданных $x_i$ и  $\theta$,

\begin{equation}
f(y|x,\theta)=\int{f(y|x,\gamma)g(\gamma|\theta)d\gamma}.
\end{equation}

Данный интеграл не имеет аналитического решения за исключением некоторых случаев. Чаще всего предполагается, что случайные параметры нормально распределены, т.е. $\gamma_{i}{\sim }\mathcal{N}[\mu,\sum]$.  Тогда $\gamma_{i}=\mu+\Sigma^{-1/2}u_{i}$, где $u_{i}{\sim }\mathcal{N}[0,I]$ и значит выражение (12.2) можно записать в форме (12.1), где $\theta$ вектор, состоящий из $\mu$ и отдельных компонент $\sum$, а $g(u)$ имеет $\mathcal{N}(0,I)$ плотность.

Простой пример модели случайных параметров --- скрытая гетерогенность. При скрытой гетерогенности  один из  заданных параметров, как правило свободный член, считается случайным. Рассмотренный интеграл является одномерным и легко аппроксимируется численно. В общем случае размерность интеграла может быть выше. 

Среди примеров моделей со случайными коэффициентами и скрытой гетерогенности можно обозначить: (1) нормально распределенные случайные параметры в мультиномиальной логит-модели (логит-модель со случайными параметрами ; см. Главу 15); (2) ненаблюдаемая гетерогенность, имеющая гамма-распределение в моделях дюрации Вейбулла (см. Главу 19), (3) ненаблюдаемая гетерогенность, имеющая гамма-распределение в пуассоновской модели со счетными  данными (см. Главу 20); и (4) индивидуальные случайные эффекты в моделях с панельными данными (см. Главу 21). Явные выражения для частной функции плотности после интегрирования по гетерогенной составляющей можно найти в примере 3 и при нормальной линейной модели в примере 4. В примерах 1 и 2, а также в нелинейных моделях примера 4 явные решения получить невозможно.


\subsection{Модели с ограниченной зависимой переменной}

Ограниченная зависимая переменная (limited dependent variable) --- это зависимая переменная, у которой мы наблюдаем только часть значений из-за цензурирования или усечения. В таком случае плотность наблюдаемой переменной --- интеграл, который может не иметь явного выражения.

Основной класс моделей с ограниченной зависимой переменной --- модели дискретного выбора, которые подробны описаны в главах 14 и 15. Здесь мы вводим модели дискретного выбора, так как они являются предметом исследования литературы по эконометрике, которая посвящена оцениванию с помощью симуляций.

В качестве примера рассмотрим выбор потребителя из трёх взаимоисключающих альтернатив, например, из трёх товаров длительного пользования, только один из которых будет выбран индивидом.  Предположим, что потребитель максимизирует полезность, и пусть полезность каждой из альтернатив 1, 2 и 3 задана $U_1$, $U_2$ и $U_3$ соответственно. Эти полезности являются ненаблюдаемыми величинами. Вместо этого мы можем только наблюдать дискретную переменную исхода $y = 1, 2$ или 3 в зависимости от того, какая альтернатива выбрана.

Предположим, что выбрана альтернатива 1, так как она обладает наибольшей полезностью. Тогда функция вероятности задана следующим образом $p_1 = \Pr[y=1]$, где

\[
p_1=\Pr[U_1-U_2 \geq  0, U_1-U_3 \geq  0]
\]

\[
=\Pr[(x_1-x_2)' \beta+\e_1-\e_2 \geq  0, (x_1-x_2)' \beta+\e_1-\e_3 \geq  0],
\]
если мы сделаем стандартное предположение (см. раздел 15.5.1) о том, что $U_j = x_j'\beta + \e_j$, $j = 1, 2, 3$, где регрессор $x$ измеряет различные качества трех товаров, а ошибка $\e$ может быть в промежутке $(-\infty, \infty)$. Определяя $u_1 = U_1 --- U_2$ и $u_2= U_1 --- U_3$,  мы получаем
 
\begin{equation}
p_1=\int^{\infty}_{0}\int^{\infty}_{0}g(u_1,u_2)du_1 du_2,
\end{equation}
где $g(u_1, u_2)$, более формально $g(u_1, u_2| x, \theta)$ --- двумерная плотность для вектора $(u_1, u_2)$ или эквивалентно
\begin{equation}
p_1=\int^{\infty}_{-\infty}\int^{\infty}_{-\infty}{\bf{1}}[u_1 \geq  0,u_2 \geq  0]g(u_1,u_2)du_1 du_2,
\end{equation}
где ${\bf{1}}[A]$ --- функция-индикатор, который равен 1, если событие $A$ происходит, и равно 0 в противном случае.

Интеграл из (12.4) можно представить в виде (12.1). Так как границы интеграла покрывают только часть значений $(u_1, u_2)$ (см. (12.3)), решение в явном виде может не существовать, несмотря на то что мы знаем, что $\int \int g(u_1, u_2)du_1du_2 = 1$, когда интегрирование проводится по всем значениям $(u_1, u_2)$.

В частности, если ошибки $\e$ имеют нормальное распределение, как в мультиномиальной пробит-модели, интеграл (12.3) считается по положительному ортанту двумерного нормального распределения. 
Не существует решения для $p$ в неявном виде, и поэтому не существует простого выражения для плотности $f(y|x,\theta)$. На практике размерность интеграла может быть очень большой, что усложняет нахождение численной аппроксимации, так при выборе  среди $m$  взаимоисключающих альтернатив размерность интеграла равна $m-1$. До того, как было развито оценивание с помощью симуляций, исследователи либо использовали модели с $m \leq 4$, либо выбирали другое распределение ошибок такое, чтобы оно приводило к более ограниченной мультиномиальной логит-модели.

\subsection{Оценка максимального правдоподобия}

Для простоты рассмотрим метод максимального правдоподобия. Предположим, что наблюдения независимы и условная плотность $y$ имеет вид $f(y|x,\theta)$.

Усложнение двух предыдущих примеров состоит в неприменимости оценки максимального правдоподобия на практике, поскольку нет аналитического решения для функции плотности $f(y|x,\theta)$, заданной сложным интегралом. Вместо этого, заменим интеграл, используя численное приближение $\hat{f}(y|x,\theta)$ и максимизируем следующее выражение по $\theta$.

\[
\ln\hat{L}_N(\theta)=\sum^{N}_{i=1}\ln\hat{f}(y_i|x_i,\theta)
\]

Оценка будет состоятельной и иметь такое же асимптотическое распределение как и оценка максимального правдоподобия, если $\hat{f}(y|x,\theta)$ является хорошей аппроксимацией для $f(y|x,\theta)$.

Полученные условия первого порядка как правило заданы нелинейно и решаются итерационными методами. Поскольку $\hat{f}(y_{i}|x_{i},\theta)$ меняется по $i$ и $\theta$, оценка градиента с использованием численных производных потребует $Nqr$ оценок, где $N$ размер выборки, $q$ размерность вектора $\theta$ и $r$ число итераций. К примеру, 1000 наблюдений, 10 параметров и 50 итераций дают 500 000 оценок функции. 

Стандартное время вычисления для нелинейных моделей теперь умножается на количество оцениваний, необходимых для расчета приближенного значения интеграла $f(y|x,\theta)$. Очевидно, что желательно методы с малым количеством вычислений. 

\subsection{Байесовские методы}

Байесовские методы рассмотрены отдельно в Главе 13. Отметим, что в байесовских методах рассчитывается интеграл, по форме аналогичный 12.2. Но при этом, в отличие от метода максимального правдоподобия, определяется (апостериорное) распределение параметров, а не точечная оценка.

\section{Основы расчета интегралов}

Рассмотрим интеграл

\begin{equation}
I=\int^{b}_{a}f(x)dx,
\end{equation}
где функция $f(\cdot)$ непрерывна на отрезке $[a,b]$ и, возможно, что границы интеграла могут быть разширены до плюс и минус бесконечности, соответственно, т.е. $a=-\infty$ и/или $b=\infty$. В этом разделе изначально считается, что $x$ --- скаляр и обозначает переменную интегрирования. В задачах регрессии обычно используется интегрирование по $u$, а $x$ обозначает регрессоры (см. 12.1). Предположим, что интеграл существует, условие существование интеграла необходимо проверять, поскольку методы аппроксимации дают конечную оценку даже расходящемуся интегралу.

Для начала рассмотрим численное интегрирование, как правило применяемое к интегралам малой размерности. Для интегралов большой размерности аналогом численного интегрирования выступает метод Монте-Карло.

Материал данного раздела описывает реализацию методов симуляционного моделирования; в связи с чем, некоторые читатели вначале могут предпочесть ознакомиться с разделами 12.4-12.6.

\subsection{Численное интегрирование детерминистическим методом}

Интеграл можно рассматривать как меру площади или объема. Численное интегрирование детерминистическим методом или просто интегрирование предполагает расчет площади фигуры в три шага: деление изначально заданной фигуры на несколько частей, расчет площади отдельных фигур и далее суммирование площадей. Иначе говоря, производится оценка подинтегральной функции в нескольких точках и рассчитывается средневзвешенная сумма полученных значений. Префикс <<детерминистическое>> используется для обозначения отсутствия симуляций при использовании приближенного метода расчета интегралов.

\begin{center}
Правило Симпсона
\end{center}

По определению интеграла 

\begin{equation}
I=\lim_{\Delta{x_i} \rightarrow 0}\sum^{n}_{j=1}f(x_j)\Delta{x_j},
\end{equation}
где промежуток $[a,b]$ разбит на $(n+1)$ промежутков, $x_{0}<x_{1}<\ldots <x_{n}$ и $n \rightarrow \infty$. Стандартные методы аппроксимации являются уточнениями выражения  12.6 и, соответственно, дают более точные результаты для конечного $n$. Ниже представлены выводы для равноотдаленных точек. В общем случае интегрирование детерминистическим методом может применяться и для неравноотдаленных точек. Для простоты допустим, что значения $f(x)$ могут быть рассчитаны в конечных точках $a$ и $b$. 

Согласно правилу прямоугольников сначала вычисляются значения в средней точке $\overline{x}_{j}=\dfrac{1}{2}(x_{j-1}+x_j)$ интервала $x_{j-1},x_j$ и затем суммируются $n$ прямоугольников с основанием $(b-a)/n$ и высотой $f(\overline{x}_j)$. Таким образом, приближенное значение интеграла равно 

\begin{equation}
\hat{I}_M=\sum^{n}_{j=1}\dfrac{b-a}{n}f(\overline{x}_j).
\end{equation}

В свою очередь, правило трапеций дает более точное приближение. Чертится прямая линия от $f(x_{j-1})$ до $f(x_j)$ и затем суммируются $n$ трапеций с основанием $(b-a)/n$  и средней высотой $(f(x_{j-1})+f(x_j))/2$. В этом случае, приближенное значение $I$ будет равно 

\begin{equation}
\hat{I}_T=\sum^{n}_{j=1}\dfrac{b-a}{n}\dfrac{f(x_{j-1})+f(x_j)}{2}.
\end{equation}

Правило парабол (правило Симпсона) предполагает использование парабол проходящих через $f(x_{j-1}), f(x_j)$ и $f(x_{j+1})$, в то время как в правиле трапеций строится линия, соединяющая идущие друг за другом значения функции. 

Правило Симпсона дает следующие результаты:

\begin{equation}
\hat{I}_S=\sum^{n}_{j=0}\dfrac{(b-a)}{3n}w_{j}f(x_j),
\end{equation}
где $n$ четное число, $w_j=4$, если $j$ четно и $w_j=2$, если $n$ нечетно, кроме исключений $w_0=w_n=1$. Дальнейшие обобщения используют полином степени $p$ по $(p+1)$ следующим друг за другом точкам.

Границы ошибок интегрирования растут по экспоненциальному закону с расширением диапазона интегрирования,$b-a$, и экспоненциально падают при сокращении количества интервалов. Для правила Симпсона, $|I_S-I|\leq M_{4}(b-a)^{5}/180n^4$, где $M_4$ максимум абсолютного значения четвертой производной по $x$ на отрезке $[a,b]$. Для правила трапеции справедливо неравенство $|I_T-I|\leq M_{2}(b-a)^{3}/12n^2$, где $M_2$ максимальное абсолютное значение второй производной по $x$ на отрезке $[a,b]$. Очевидно, что количество интервалов должно увеличиваться с ростом количества значений $x$, в связи с чем необходимо определить чувствительность диапазона значений к изменению количества интервалов.

Правило Симпсона и связанные с ним правила хорошо применимы к интегралам, определенным на отрезке, трудности могут возникнуть, если интеграл будет неопределенными интегралами из-за отсутствия граничных значений. Например, предположим что $[a,b]=[0,\infty)$. Тогда при выборе $x_n$ необходимо будет принять компромиссное решение. С одной стороны, верхнее значение границы $x_n$ должно быть большим, с другой стороны это приведет к большим расстояниям между точками. Также полезно определить чувствительность ответа к увеличению $x_n$.

\begin{center}
Интегрирование по Гауссу
\end{center}

Интегрирование по Гауссу является численным методом и было предложено Гауссом в 1814 году. Данные метод предлагает правило выбора точек оценки $x_j$, которые теперь неравномерно расположены. Метод особенно полезен для оценки неопределенных интегралов. 

Для начала преобразуем выражение 12.5 

\begin{equation}
I=\int^{d}_{c}w(x)r(x)dx,
\end{equation}

где как правило $w(x)$ это одна из следующих функций от $x$. Метод Гаусса-Эрмита полагает  $w(x)=e^{-x^2}$, и используется для интервала вида $[c,d]=(-\infty,\infty)$. Метод Гаусса-Лежандра полагает  $w(x)=e^{-x}$ для случая $[c,d]=(0,\infty)$. Метод Гаусса-Лежандра полагает $w(x)=1$ для случая $[c,d]=[-1,1]$.

В самом простом случае выражение 12.10 можно получить из 12.5, определив $r(x)=f(x)/w(x)$. В общем случае, может потребоваться преобразование $x$, чтобы, к примеру, отрезок $[2,\infty)$ в 12.5 преобразуется в отрезок $[0,\infty)$ в выражении 12.10. Некоторые процедуры позволяют исследователю выбрать $f(x)$ и промежуток интегрирования, а все необходимые преобразования производятся автоматически.

С помощью интегрирования по Гаусу рассчитывается приближенное значение интеграла 12.10, с помощью взвешенной суммы

\begin{equation}
\hat{I}_{G}=\sum^{m}_{j=1}w_{j}r(x_j),
\end{equation}
где исследователь выбирает $m$. Формулы для $m$ точек оценки $x_j$ и весов $w_j$ можно найти в литературе, например у  Абрамовица и Стегуна (1971) или получить при помощи компьютерной программы, например см. Пресс и др. (1993).

В теории, согласно которой рассчитываются приближенные значения, за основу берутся ортогональные многочлены $p_j(x), j=0,\ldots ,m$ с весами $w(x)$, удовлетворяющие следующему равенству:

\[
I=\int^{d}_{c}w(x)p_{j}(x)p_{k}(x)dx=0, j{\neq}k, j,k=0,\ldots ,m.
\] 
Если к тому же $\int^{d}_{c}w(x)p^{2}_{j}(x)dx=1$ полиномы называются ортонормальными. Приближение (12.11) является точным, если порядок полинома $r(x)$ меньше или равен $2m-1$, иными словами наилучшее приближение достигается, если значения $r(x)$ в (12.10) хорошо аппроксимируется с помощью полинома порядка $2m-1$. Хороший выбор количества точек оценки $m$ требует экспериментирования, однако во многих приложениях $m$ не более, чем 20 или 30.

В качестве примера рассмотрим интегрирование Гаусса-Эрмита, частый способ интегрирования в эконометрике, где границы интегрирования часто равны $(-\infty, \infty)$. Для $w(x)=e^{{-x}^2}$ ортогональные полиномы $p_{j}(x)$ являются полиномами Эрмита $H_{j}(x)$ и ортонормальная форма $H_{j}(x)$ задается рекурсивно $H_{j+1}(x)=\sqrt{2/(j+1)}xH_{j}(x)-\sqrt{j/(j+1)}H_{j-1}(x)$, $j=1,\ldots ,m$, где $H_{-1}=0$ и $H_0=\pi^{-1/4}$. При этом $m$ значений абсцисс $x_j$ являются $m$ корнями уравнений $H_{m}=0$ и для ортонормальных полиномов Эрмита веса равны $w_j=1/[jH_{j-1}(x_j)^2]$. Как отмечалось ранее $x_j$ и $w_j$ для заданного значения $m$ даны в таблицах или их можно рассчитать при помощи статистического пакета.

Для определенных интегралов применение интегрирования Гаусса-Лежандра, как правило дает результаты лучше, чем правило Симпсона. Тем не менее, главное преимущество интегрирования по Гауссу заключается в возможности применения данного метода для вычисления неопределенных интегралов. Заметим, что если границы интегрирования равны $(-\infty, \infty)$, то иногда возможно преобразование переменных, приводящее границы интегрирования к $(0,\infty)$ и, тогда вместо метода Гаусса-Эрмита будет применяться метод Гаусса-Лежандра.

Существует большое количество других детерминистических методов оценки интегралов, в т.ч. аппроксимация Лапласа (Тьерни, Касс и Кадэйн, 1989).

\subsection{Интегрирование методом Монте-Карло} 

Интегрирование с помощью метода Монте-Карло является альтернативой детерминистическому численному интегрированию. В общем случае оценка интеграла $I=\int^{b}_{a}f(x)dx$ имеет вид

\begin{equation}
\hat{I}_{MC}=\sum^{S}_{s=1}f(x^s),
\end{equation}
где $x^1,\ldots ,x^s$ равномерно распределенные величины на отрезке $[a,b]$. По сравнению с правилом прямоугольников, значение функции $f(x)$ рассчитывается в $S$ точках, выбранных случайным, а не детерминистическим  образом. 

Наше изложение метода уделяет особое внимание регрессионным задачам, таким как были рассмотрены в Разделе 12.2. Интегрирование применяется для расчета, например, математического ожидания $\E[h(x)]$, где случайная величина $x$ имеет функцию плотности распределения $g(x)$. При непрерывности функции оценивается интеграл 

\begin{equation}
\E[h(x)]=\int^{b}_{a}h(x)g(x)dx,
\end{equation}

На протяжении всей главы предполагается, что $\E[h(x)]<\infty$, т.е. интеграл сходится. $\E[h(x)]$ может быть оценена при помощи простого интегрирования по методу Монте-Карло

\begin{equation}
\hat{I}_{DMC}=\hat{\E}[h(x)]=S^{-1}\sum^{S}_{s=1}h(x^s),
\end{equation}
где ${x^{s}, s=1,\ldots ,S}$ выборка Монте-Карло, состоящая из $S$ псевдо-случайных  значений с распределением $g(x)$. Данную выборку можно построить с помощью методов, изложенных в разделе 12.8. Оценка 12.14 рассчитывает $h(x)$, используя  значения $x$ сгенерированные согласно плотности $g(x)$. Оценка 12.12 рассчитывает $h(x)g(x)$, используя равномерно распределенные $x$. Преимущество (12.14) состоит в возможности использования (12.14) для расчета неопределенных интегралов, в то время как равномерное распределение в (12.12) может вызвать затруднения, если значения $a$ и $b$ не ограничены.


Оценка $\hat{\E}[h(x)]$ --- это среднее значений функции $f()$ в каждой из случайных точек $x^s$. Другими словами, $\hat{\E}[h(x)]$ --- это среднее арифметическое случайных величин $h(x^s)$, и его свойства при $S\to\infty$ могут быть получены с помощью закона больших чисел или центральной предельное теоремы. Здесь $x^s$ независимы и одинаково распределены, поэтому $h(x^s)$ независимы и одинаково распределены и мы можем применить закон больших чисел Колмогорова (приложение А, теорема А.8) поскольку конечность $\E[h(s)]$ уже была предположена. Следовательно,

\[
\hat{\E}[h(x)]\stackrel{p}{\rightarrow}\E[h(x)] \text{при} S \rightarrow \infty
\]

Вместе с тем, поскольку $h(x^s)$ независимо и равномерно распределены дисперсия $\hat{\E}[h(x)]$ равна $S^{-1}\V[h(x)]$, если существует $\V[h(x)]$. Вероятно, что приближенное значение будет близко к истинному для небольших значений $S$, если $S^{-1}V[h(x^s)]$ мало. 

\subsection{Пример расчета интеграла}

Предположим, что $x{\sim } \mathcal{N}[0,1]$. Рассчитаем математическое ожидание $x$ 

\[
\E[x]=(\sqrt{2\pi})^{-1}\int^{\infty}_{-\infty}x\exp(-x^{2}/2)dx
\]

а также момент $\E[\exp(-\exp(x))]$, который задан интегралом 

\[
\E[\exp(-\exp(x))]=(\sqrt{2\pi})^{-1}\int^{\infty}_{-\infty}\exp(-\exp(x))\exp(-x^{2}/2)dx.
\]

Для $\E[x]$ существует аналитическое выражение и $\E[x]=0$. В отличие от этого для $\E[\exp(-\exp(x))]$ отсутствует аналитическое решение. Перед тем как искать численную аппроксимацию, необходимо убедиться, что интеграл действительно сходится. 

Поскольку выражение $\exp(-\exp(x))$ строго положительно и монотонно убывает при максимальном значении 1, следовательно $|\exp(-\exp(x))|<1$, поэтому, $\E[\exp(-\exp(x))]$ $<\E[1]=1$ и интеграл сходится.

Одномерные интегралы просто рассчитать, используя детерминистскую численную аппроксимацию. Например, рассмотрим применение правила прямоугольников при $n=20$, где точки равномерно распределены между $x_0=-5$ и $x_{20}=5$. Тогда

\[
\hat{\E}[x]=(\sqrt{2\pi})^{-1}\sum^{20}_{j=1}\dfrac{10}{20}\overline{x}_{i}\exp(-\overline{x}^{2}_{j}/2),
\]

\[
\hat{\E}[\exp(-\exp(x))]=(\sqrt{2\pi})^{-1}\sum^{20}_{j=1}\dfrac{10}{20}\exp(-\exp(\overline{x}_j))\exp(-\overline{x}^{2}_{j}/2),
\]
где $\overline{x}_j=-5.25+j/2$. Как и ожидалось, $\hat{\E}[x]=0$ до большого количества десятичных знаков после запятой, в то время как $\hat{\E}[\exp(-\exp(x))]=0.38175656$. Последняя оценка меняется незначительно, после восьмого знака, если взять $n=200$ и  равноудаленные точки между -10 и 10. Очевидно, что в этом случае детерминистическая численная аппроксимация дает адекватные результаты.

Эти интегралы возможно рассчитать, используя метод Монте-Карло со следующими параметрами

\[
\hat{\E}=\dfrac{1}{S}\sum^{S}_{s=1}x^{s},
\]

\[
\hat{\E}[\exp(-\exp(x))]=\dfrac{1}{S}\sum^{S}_{s=1}\exp(-\exp(x^s)),
\]
где $x^s$ это $s$-ая точка из $S$ распределенных нормально с параметрами $\mathcal{N}[0,1]$. Способ получения таких точек рассмотрен в Приложении B. В таблице 12.1 даны значения оценок $\hat{\E}[x]$ и $\hat{\E}[\exp(-\exp(x))]$ для разного количества симуляций $S$. Можно увидеть, что при $S \rightarrow \infty$ оценки более стабильны и их значения близки к истинным, 0 и 0.38175656, где последняя получена с помощью детерминистической численной аппроксимации. Однако, даже при $S=10^6$ оценка $\hat{\E}[x]$ будет отлична от нуля до четвертого знака после запятой. В таком случае, $\V[\hat{\E}[x]]=S^{-1}\V[x^s]=1/S$, поскольку $\V[x^s]=1$ так, что даже если $S=10^6$ стандартное отклонение $\hat{\E}[x]$ довольно велико (0.001). Альтернативные методы дающие оценку Монте-Карло с меньшей дисперсией  рассмотрены в разделе 12.7.
 
\begin{table}[h]
\begin{center}
\caption{\label{tab:pred} Интегрирование Монте-Карло: пример для стандартного нормального $x$}
\begin{tabular}{lll}
\hline
\hline
$S$ = Количество симуляций & $\hat{\E}[x]$ & $\hat{\E}[\exp(-\exp(x))]$ \\ 
\hline 
10 & 0.145 & 0.336 \\ 
25 & -0.209 & 0.435 \\ 
50 & 0.050 & 0.369 \\ 
100 & -0.120 & 0.409 \\ 
500 & -0.059 & 0.398 \\ 
1,000 & 0.005 & 0.382 \\ 
10,000 & -0.007 & 0.383 \\ 
100,000 & -0.000 & 0.382 \\ 
1,000,000 & -0.000 & 0.381 \\ 
\hline 
\end{tabular}
\end{center}
\end{table} 

\subsection{Интегралы высокой размерности}

Интегралы высокой размерности можно оценить детерминистическими методами или методом Монте-Карло, последний позволяет становится более предпочтительным с ростом размерности.

Наилучшие результаты интегрирования детерминистическим методом получаются при интегрировании с помощью многомерного метода Гаусса или обычного метода Гаусса, если границы интегрирования не слишком сложные, поскольку тогда возможно понизить размерность интеграла и свести решение к оценке $m$ одномерных интегралов. Однако, из определения интеграла следует, что количество вычислений вырастет экспоненциально с ростом $m$. К примеру, если необходимо 20 оцениваний функции для одномерного интеграла, тогда для расчета интегралов пятой размерности может потребоваться $5^{20}$ или 95 биллионов оцениваний. Такая высокая точность может не понадобится, если похожие вычисления  с последующим суммированием производятся для каждой точки. Тем не менее, даже в таком случае количество расчетов может значительно увеличится с ростом размерности интеграла.

Оценка интегралов высокой размерности методом Монте-Карло не вызывает затруднений: необходимо задать $x$ в 12.13 и 12.14 как вектор и генерировать случайную выборку согласно многомерной плотности распределения $g(x)$. Казалось бы отсутствует негативное влияние размерности. 
Тем не менее, необходимо учитывать, что упрощенный метод Монте-Карло может не сработать, если подинтегральная функция имеет острые вершины, очень возможно, что острые вершины будут иметь место для интегралов высокой размерности. 
В частности, в примере дискретного выбора в разделе 12.2.2 подинтегральное выражение в (12.4) принимает ненулевые значения  только на небольшом диапазоне $(u,\nu)$, эти проблемы рассмотрены в Разделе 12.7. Кроме того, строить выборку из многомерного распределения сложнее, чем из одномерного. 

\section{Симуляционный метод максимального правдоподобия}

Рассмотрим способы интегрирования, которые применимы для расчета оценок максимального правдоподобия при отсутствии аналитической формы записи плотности. Основной результат симуляционных методов моделирования --- оценки параметров могут иметь такое же распределение, как оценки, полученные обычным методом максимального правдоподобия, при условии, что количество симуляций, проводимых при оценивании функции плотности для каждого наблюдения, стремится к бесконечности.

\subsection{Способы симуляций}

Предположим, что условная плотность распределения $f(y|x,\theta)$, включает интеграл, значение которого трудно посчитать. Например, предположим, как и в (12.1),

\begin{equation}
f(y_i|x_i,\theta)=\int{h(y_i|x_i,\theta,u_i)g(u_i)du_i}
\end{equation}

Прямым способом симулирования условной плотности $f(y_i|x_i,\theta)$ выступает метод Монте-Карло, согласно которому:

\begin{equation}
\hat{f}(y_i|x_i,u_{is},\theta)=\dfrac{1}{S}\sum^{S}_{s=1}h(y_i|x_i, \theta, u^{s}_i),
\end{equation}
где $u_{is}$ вектор состоящий из $S$ независимых значений $u^{s}_{i}=1,\ldots ,S$, сгенерированных согласно плотности $g(u_i)$. Это по сути просто среднее арифметическое $h(y_i|x_i, \theta, u^{s}_{i})$ по $S$ значениям. Согласно выводам раздела 12.3.2 следует, что $\hat{f}_i$ несмещенная и состоятельная оценка для $f_i$ при $S \rightarrow \infty$.

Вместе с тем, возможно использовать иные методы симулирования, которые подробно рассмотрены в разделе 12.7. С помощью непрямых методов возможно получить оценку функции $\hat{f_i}$, лучше аппроксимирующую значение функции $f_i$, чем прямые методы, при конечном количестве симуляций. Например, допуская наличие корреляции между симуляциями, при условии, что частное распределение симуляций по-прежнему задано функцией плотности $g(u_i)$. В общем случае выражение для оценки условно заданной функции $f(y_i|x_i,\theta)$ методом Монте-Карло имеет следующий вид:

\begin{equation}
\hat{f}(y_i|x_i,u_{is},\theta)=\dfrac{1}{S}\sum^{S}_{s=1}\tilde{f}(y_i|x_i,\theta,u^{s}_i),
\end{equation}
где $u^{s}_i=1,\ldots ,S$ это $S$ случайных значений сгенерированных согласно плотности $g(u_i)$, но необязательно независимых по $s$. Для того, чтобы оценка $\hat{f_i}$ была полезной, необходимо выполнение условия $\hat{f}_i \stackrel{p}{\rightarrow} f_i$ при $S \rightarrow \infty$. Вероятно, что последнее выполняется, если вспомогательная оценка $\tilde{f}(\cdot)$ является несмещенной и справедливо:

\begin{equation}
\E[\tilde{f}(y|x,\theta,u^s)]=f(y|x,\theta).
\end{equation}

Желательно, чтобы оценка $\hat{f_i}$ было дифференцируема по $\theta$, тогда для оценки параметра $\theta$ будет возможно использовать стандартные итерационные градиентные методы. Для устранения <<шума>>, вызванного симуляциями, а также для обеспечения численной сходимости, полученные с помощью Монте-Карло значения, используемые для построения $\hat{f}_i$, не должны меняться при изменении значений $\theta$ между итерациями. 

\subsection{Оценивание с помощью симуляционного метода максимального правдоподобия}

При выполнении условии независимости по $i$, оценки максимального правдоподобия, $\hat{\theta}_{ML}$, максимизируют значение функции $\ln{L_N}(\theta)=\sum^{N}_{i=1}\ln{f}(y_i|x_i,\theta)$. В свою очередь, оценка симуляционного максимального правдоподобия (maximum simulated likelihood), $\hat{\theta}_{MSL}$ максимизирует логарифмическую функцию максимального правдоподобия, построенную на основе оцененных значений плотности, то есть

\begin{equation}
\ln\hat{L}_{N}(\theta)=\sum^{N}_{i=1}\ln\hat{f}(y_i|x_i,u_{is},\theta),
\end{equation}
где вспомогательная оценка $\hat{f}(\cdot)$ задана в (12.7). Если $\hat{f}(\cdot)$ дифференцируема по $\theta$, тогда $\hat{\theta}_{MSL}$ может быть рассчитана стандартными градиентными методами  Главы 10, с использованием как аналитической, так и численной производной.

\subsection{Распределение оценок симуляционного максимального правдоподобия}

Согласно общему методу доказательства состоятельности оценок (см. раздел 5.3.2), оценка симуляционного метода максимиального правдоподобия будет иметь такой же предел по вероятности, как и ММП-оценка, если пределы по вероятности функции $N^{-1}\ln{\hat{L}_N(\theta)}$, аппроксимирующей целевую, и исходной целевой функции $N^{-1}\ln{\hat{L}_N}(\theta)$ равны. Это произойдет, если $\ln{\hat{f}_i}-\ln{f_i} \stackrel{p}{\rightarrow} 0$, для чего достаточно условия $\hat{f}_i-f_i \stackrel{p}{\rightarrow} 0$ при $S \rightarrow \infty$.

Даже если симуляционная ММП-оценка состоятельна, возможно что случайность симуляций  приведет к росту дисперсии по сравнению с ММП-оценкой. В качестве примера формальных условий, при которых оценка симуляционного правподобия полностью эффективна, дадим утверждение, которое является переформулировкой теоремы, которую приводят Гурьеру и Монфорт (1991).

\begin{proposition}
[Распределение оценок симуляционного правдоподобия](Гурьеру и Монфорт, 1991)

Предположим, что
\begin{enumerate}
\item Значения взяты из случайной выборки, а условная плотность распределения $f(y|x,\theta_0)$ удовлетворяет регуляторным условиям так, что оценка максимального правдоподобия состоятельна и асимптотически нормально распределена с предельной матрицей дисперсий $A^{-1}(\theta_0)$, где
\[
A(\theta_0)=-\left. \plim\left[ N^{-1}\sum^{N}_{i=1}\dfrac{{\partial}^{2}\ln f(y_i|x_i,\theta)}{\partial\theta\partial\theta^{'}} \right|_{ \theta_{0}}\right] 
\]

\item Плотность $f$ рассчитывается с помощью вспомогательной оценки $\hat{f}$, приведенной в (12.17) с $\tilde{f}$ несмещенной для $f$.
\end{enumerate}

Тогда оценка симуляционного правдоподобия, определение которой дано в (12.19) асимптотически эквивалентна ММП-оценке если $S,N \rightarrow \infty$ и $\sqrt{N}/S \rightarrow 0$ и имеет предельное нормальное распределение 


\begin{equation}
\sqrt{N}(\hat{\theta}_{MSL}-\theta_0)\stackrel{d}{\rightarrow} \mathcal{N}[0,A^{-1}(\theta_0)].
\end{equation}
\end{proposition}

Оценка симуляционного правдоподобия фактически является состоятельной, если взять более слабое условие, $S,N \rightarrow \infty$. Это условие будет удовлетворено, если, к примеру, $S=N^{0.4}/a$ для некоторой константы $a$. В таком случае, $\sqrt{N}/S=aN^{0.1} \rightarrow \infty$, т.е., по утверждению 12.1 оценка симуляционного правдоподобия не будет эффективной. Используя стандартную процедуру разложения в ряд Тейлора можно увидеть, что предельное распределение $\sqrt{N}(\hat{\theta}_{MSL}-\theta_0)$ с точностью до умножения на матрицу задано выражением $N^{-1/2}\sum_{i}\partial{\ln\hat{f}_i/\partial{\theta}}|_{\theta_0}$. Оно зависит от изменчивости $\partial{\ln{f_i}}/\partial\theta$ и от ошибки симуляций при аппроксимации $\hat{f}_i$. Согласно утверждению 12.1 ошибка симуляций асимптотически исчезает при условии, что количество симуляций растет с увеличением размера выборки со скоростью, превышающей $\sqrt{N}$.

Для расчета ковариационной матрицы симуляционного правдоподобия необходимо получить оценку $A(\theta_0)$. Для этого можно просто применить симуляционный вариант BHHH-метода, рассмотренный в разделе 5.5.2. Поскольку $\partial{\ln{f_i}}/\partial\theta=(\partial{f_i}/\partial\theta)/f_i$, оценка информационной матрицы по BHHH-методу будет равна

\[
\hat{B}=\dfrac{1}{N}\sum^{N}_{i=1}\dfrac{\partial{f_i}(\hat{\theta})/\partial\theta}{f_{i}(\hat{\theta})}\dfrac{\partial{f_i}(\hat{\theta})/\partial\theta^{'}}{f_{i}(\hat{\theta})}.
\]
Поскольку не существует аналитического решения для функции $f_i$ и $\partial{f_i}/\partial\theta$, невозможно вычислить значение данного выражения. Следовательно, заменим $f_i$ на $\hat{f_i}$, заданное в (12.17) и получим симуляционную оценку асимптотической вариации
\begin{equation}
\hat{\V}[\hat{\theta}_{MSL}]=\left( \sum^{N}_{i=1}\left(\dfrac{\sum^{S}_{s=1}\partial\tilde{f}^{s}_{i}(\hat{\theta})/\partial\theta}{\sum^{S}_{s=1}f^{s}_{i}(\hat{\theta})}\dfrac{\sum^{S}_{s=1}\partial\tilde{f}^{s}_{i}(\hat{\theta})/\partial\theta^{'}}{\sum^{S}_{s=1}f^{s}_{i}(\hat{\theta})} \right) \right)^{-1},
\end{equation}
где $\tilde{f}^{s}_{i}(\hat{\theta})=\tilde{f}(y_i|x_i,u^{s}_i,\hat{\theta}_{MSL})$. Альтернативные варианты оценок могут быть получены по аналогии с оценкой с помощью Гессиана или сэндвич-оценкой, определенными в разделе 5.5.2.

С практической точки зрения важна проблема определения количества симуляций. Возможно увеличивать количество симуляций с увеличением размера выборки, но абсолютное значение $S$ остается неопределенным. Если разница в оценке параметров при разном количестве симуляций несуществена, например, при 2400 или 2600, то это можно считать свидетельством того, что 2400 симуляций достаточно. Предположим, что размер выборки увеличился в четыре раза. Тогда, насколько должно измениться количество симуляций? Согласно Утверждению 12.1 количество симуляций $S$ должно увеличиться более чем в два раза, т.е. должно быть больше 4800, тогда соотношение $\sqrt{N}/S$ станет ближе к нулю. Однако нельзя утверждать, что значение $\sqrt{N}/S$ достаточно близко к нулю, так при $S=2,400$ и $N=6,400$ соотношение равно $1/30$. Таким образом, возникают затруднения при ответе на вопрос о достаточном количество симуляций. Многие эмпирические исследователи полагаются на приближенные показатели сходимости точечных оценок, неформально основанных на расчете градиентов $L_N(\theta)$. Формальный подход выбора $S$, основанный на проведении теста, рассмотрен у Хаживассилиу (2000). 

\subsection{Оценка симуляционного правдоподобия, скорректированная на смещение}

Оценка симуляционного правдоподобия является несостоятельной или асимптотически смещенной когда количество симуляций $S<{\infty}$. Смещение существует для конечных значений $S$, поскольку оценка $\ln{\hat{f}_i}$ смещена для $\ln{f_i}$, даже если вспомогательная оценка $\hat{f}_i$ несмещена для $f_i$. Смещение возникает из-за взятия натурального логарифма. Тогда, $N^{-1}\ln{\hat{L}_N}$ и $N^{-1}\ln{L_N}(\theta)$ имеют разные пределы по вероятности для конечного $S$. Это подталкивает к поиску альтернативных оценок, полученных на основе симуляций, так как мы не можем установить $S = \infty$, а устанавливать большое $S$ может быть затруднительным в вычислительном плане.

Очевидный подход --- найти несмещенную вспомогательную оценку для логарифма плотности $\ln f_i$, а не для $f_i$, но на практике это невозможно. Вместо этого, в этом разделе мы представляем вариант оценки симуляционного правдоподобия с поправкой на смещение, а в следующем разделе мы представляем альтернативу, менее эффективную оценку, чем оценку симуляционного правдоподобия, которая является состоятельной для конечного $S$.

Гурьеру и Монфорт (1991) приводят выражение для смещения оценки симуляционного правдоподобия. При фиксированном $S$ оценки симуляционного ММП  могут быть несостоятельными из-за того, что в этом случае $\ln \hat{f}$ --- несостоятельная оценка $\ln f$. Для уменьшения несостоятельности возможно использовать скорректированную на смещение логарифмическую функцию правдоподобия. Запишем

\[
\ln\hat{f}=\ln[f+(\hat{f}-f)].
\]

Разложение в ряд Тейлора до второго порядка в окрестности $\ln{f}$ даст

\[
\ln\hat{f} {\sim eq} \ln{f}+\dfrac{\hat{f}-f}{f}-\dfrac{1}{2}\dfrac{(\hat{f}-f)^2}{f^2}.
\]

Проинтегрируем согласно плотности распределения $u$ и вычислим значение $\ln{f}$

\begin{equation}
\ln{f} {\sim eq} \E_{u}[\ln\hat{f}]+\dfrac{1}{2}\dfrac{\E_{u}[(\hat{f}-f)^2]}{f^2},
\end{equation}

предполагая, что вспомогательная оценка $\hat{f}$ несмещенная и, следовательно, $\E_{u}[\hat{f}]=f$. Это выражение показывает, что если вспомогательная оценка $\hat{f}$ имеет маленькую дисперсию, то смещение незначительно.

Расчет оценок, скорректированных на смещение предполагает использование уточненной логарифмической функции максимального правдоподобия, основу которой составляет правая часть выражения (12.22). Для вспомогательной оценки (12.17), $\hat{f}$ равно $S^{-1}\sum_{s}\tilde{f}^{s}$ и $\E_{u}[(\hat{f}-f)^2]$ равно $S^{-1}\sum_{s}\E_{u}[(\tilde{f}^s-f)^2]$. Если симуляции независимы по $s$, то приближенное значение последнего выражения равно $S^{-1}\sum_{s}(\tilde{f}^s-\hat{f})^2$. Тогда, выражение (12.22) дает  оценку симуляционного ММП, скорректированную на смещение первого порядка, $\hat{\theta}_{BCMSL}$, которая максимизирует

\[
\ln\hat{L}_{B,N}(\theta)=\sum^{N}_{i=1}\left[\ln\hat{f}(y_i|x_i,u_{iS},\theta)+\dfrac{1}{2S}\dfrac{\sum^{S}_{s=1}[\tilde{f}(y_i,x_i,u^{s}_{i},\theta)-\hat{f}(y_i|x_i,u_{iS},\theta)]^2}{\hat{f}(y_i|x_i,u_{iS},\theta)^2} \right], 
\]
где $\hat{f}(y_i|x_i,u_{iS},\theta)=S^{-1}\sum_{s}\tilde{f}(y_i,x_i,u^{s}_i,\theta)$. Выгоды от сокращения смещения будут меняться от случая к случаю, поскольку смещение может быть больше, чем предполагалось.

\subsection{Пример ненаблюдаеммой гетерогенности}

Предположим, что $y_i{\sim } \mathcal{N}[\theta_i,1]$ и значения скалярного параметра $\theta_i$ заданы выражением $\theta_i=\theta+u_i$, где $u_i$ обозначает ненаблюдаемую гетерогенность, и известно распределение $u_i$. Условная плотность $y$ при заданном значении $u$, определяется как 

\begin{equation}
f(y|u,\theta)=\dfrac{1}{\sqrt{2\pi}}\exp\left\lbrace -(y-\theta-u)^{2}/2\right\rbrace. 
\end{equation}

Тем не менее, выводы по $\theta$ должны быть основаны на плотности безусловного распределения $y$, что требует  интегрирования по $u$. Предположим, что $u$ имеет скошенное распределение с ненулевым средним, не зависящим от неизвестных параметров, и плотность распределения задана выражением

\begin{equation}
g(u)=e^{-u}\exp(-e^{-u}),
\end{equation}

Оценка методом максимального правдоподобия невозможна, поскольку для плотности безусловного распределения $f(y|\theta)$, которая равна $\int{f(y|\theta,u)}g(u)du$, не существует выражения в аналитическом виде. Вместо ММП используется симуляционная оценка максимального правдоподобия, со вспомогательной оценкой из выражения (12.16) так, что $\hat{\theta}_{MSL}$ максимизирует

\begin{equation}
\ln\hat{L}_{N}(\theta)=\dfrac{1}{N}\sum^{N}_{i=1}\ln\left(\dfrac{1}{S}\sum^{S}_{s=1}\dfrac{1}{\sqrt{2\pi}}\exp\lbrace{-(y_i-\theta-u^{s}_i)^{2}/2}\rbrace \right), 
\end{equation}

где значения $u^{s}_{i}, s=1,\ldots ,S$ имеют  распределение экстремальных значений с  плотностью $g(u_i)$ из (12.24). Оценка симуляционного максимального правдоподобия  $\hat{\theta}_{MSL}$ является решением условия первого порядка

\begin{equation}
\dfrac{\partial{\ln\hat{L}_{N}(\theta)}}{\partial\theta}=\dfrac{1}{N}\sum^{N}_{i=1}\dfrac{\sum^{S}_{s=1}(y_i-\theta-u^{s}_i)\exp\lbrace{-(y_i-\theta-u^{s}_{i})^{2}/2}\rbrace}{\sum^{S}_{s=1}\lbrace{-(y_i-\theta-u^{s}_{i})^{2}/2}\rbrace} = 0,
\end{equation}

Не смотря на то, что параметр $\theta$ не может быть выражен аналитически, возможно использовать стандартные итерационные методы для расчета $\hat{\theta}_{MSL}$.

Для того, чтобы оценки симуляционного ММП были состоятельны, необходимо чтобы $S \rightarrow \infty$, помимо того, объем выборки должен стремиться к бесконечности, $N \rightarrow \infty$, это означает, что потенциально потребуется большой объем вычислений. Как обычно, оценка симуляционного ММП распределена асимптотически нормально с асимптотической дисперсией, наиболее легко рассчитываемой BHHH методом (12.21), равна 

\begin{equation}
\hat{\V}[\hat{\theta}_{MSL}]=\left(\sum^{N}_{i=1}\left[\dfrac{\sum^{S}_{s=1}(y_i-\hat{\theta}_{MSL}-u^{s}_i)\exp\lbrace{-(y_i-\hat{\theta}-u^{s}_i)^{2}/2} \rbrace} {\sum^{S}_{s=1}\lbrace{-(y_i-\hat{\theta}_{MSL}-u^{s}_i)^{2}/2} \rbrace} \right]^{2}  \right)^{-1}.
\end{equation}

Эта оценка является полностью эффективной.

\begin{table}[h]
\begin{center}
\caption{\label{tab:pred} Оценивание с помощью MSL: пример}
\begin{tabular}{lccccc}
\hline 
\hline
{\bf{Число симуляций}} & $S = 1$ & $S = 10$ & $S = 100$ & $S = 1,000$ & $S = 10,000$ \\ 
\hline
$MSL$-оценка параметра $\hat{\theta}$ & 1.0416 & 1.0594 & 1.175 & 1.185 & 1.1828 \\ 
Стандартная ошибка & (.0968) & (.1093) & (.1453) & (.1448) & (.0091) \\ 
$\ln\hat{L}(\hat{\theta})$ & -136.31 & -174.38 & -190.44 & -192.43 & -192.35 \\ 
\hline 
\hline
\end{tabular} 
\end{center}
\end{table}

Для иллюстрации рассмотрим выборку $\lbrace{y_1,\ldots ,y_{100}}\rbrace$ размером $N=100$, сгенерированную на основе моделей (12.23) и (12.24) с параметром $\theta=1$. В таблице 12.2 даны оценки с учетом роста количества симуляций $S$. Для малых значений $S$  оценка симуляционного ММП несостоятельна. При $S=10,000$  оценка $\hat{\theta}_{MSL}$ стабилизируется, несмотря на то, что оценка средней квадратической ошибки достаточно резко изменяется. Симуляционная функция правдоподобия падает с ростом $S$, но потом стабилизируются.     Падение ожидаемо, поскольку вспомогательная оценка дает несмещенные оценки для $f(y|\theta)$, но со смещением вверх для $\ln{f(y|\theta)}$, поскольку согласно неравенству Йенсена $\ln{\E[\hat{f}(y|\theta)]}>\E[\ln{\hat{f}(y|\theta)}]$, так как функция натурального логарифма глобально вогнута; см. Приложение A (Раздел А.8).

\section{Оценка симуляционного метода моментов}

Симуляционный подход для случаев, когда не существует аналитического выражения целевой функции, может быть применен не только для оценок максимального правдоподобия. Вместе с тем, в некоторых случаях возможно получить состоятельные оценки параметров при небольшом количестве симуляций на каждое наблюдение, несмотря на то, что существует потеря эффективности.

\subsection{Симуляционная М-оценка}

Рассмотрим М-оценку, пусть целевая функция имеет вид

\[
Q_N(\theta)=\dfrac{1}{N}\sum^{N}_{i=1}q(y_i,x_i,\theta).
\]

Метод максимального правдоподобия это частный случай с $q(y,x,\theta)=\ln{f(y|x,\theta)}$.

Предположим, что не существует аналитического выражения для $q(\cdot)$, но возможно получить оценку, используя симуляции. Тогда симуляционная М-оценка минимизирует функцию

\begin{equation}
\hat{Q}_N(\theta)=\dfrac{1}{N}\sum^{N}_{i=1}\hat{q}(y_i,x_i,u_{iS},\theta),
\end{equation}
где по аналогии с разделом 12.4.1, $\hat{q}_i$ оценка для $q_i$, рассчитанная на основе значений вектора $u_{iS}$, состоящего из $S$ симуляций $u^{s}_i, s=1,\ldots ,S$, из соответствующего распределения. Обычно, $\hat{q}(\cdot)=S^{-1}\sum_{s}\tilde{q}(y_i|x_i,\theta,u^{s}_i)$, где $u^{s}_i$ это $s$-тая симуляция.

Симуляционная М-оценка будет состоятельной, если исходная М-оценка состоятельна, а также 

\begin{equation}
\plim\hat{Q}_N(\theta)=\plim{Q_N(\theta)},
\end{equation}
поскольку из Раздела 5.3 следует, что необходимым условием состоятельности исходной М-оценки является максимальность предела целевой функции $\plim{Q_N(\theta)}$ в точке $\theta=\theta_0$. В этом случае первый вероятностный предел берется по всем стохастическим переменным, в том числе по симулированным значениям $u_{iS}$, в то время как второй вероятностный предел не зависит от $u_{iS}$.

Условие (12.29) удовлетворяется, если вспомогательная оценка  такова, что $\hat{q}_i-q_i \stackrel{p}{\rightarrow} 0$ при $S \rightarrow \infty$, поскольку тогда $N^{-1}\sum_{i}\hat{q}_i-N^{-1}\sum_{i}q_{i}\stackrel{p}{\rightarrow} 0$. Это  предположение было сделано Разделе 12.4. Кроме того, симуляционная М-оценка должна иметь такое же предельное распределение как обычный М-оценка, если, также как в Разделе 12.4 $S$ увеличивается с ростом размера выборки, таким образом, что $\sqrt{N}/S \rightarrow 0$. Для выполнения этого условия требуется много симуляций.

\subsection{Сокращение количества симуляций}

Предположим, что вспомогательная оценка $\hat{q}_i$ не только состоятельна, но и несмещенная. Далее, применение закона больших чисел и, для упрощения, исключение из обозначений стохастических переменных кроме симулированных значений, дает равенство $\plim{\hat{Q}_N}(\theta)=\lim{N^{-1}\sum_{i}\E_{u_{iS}}[\hat{q}_i]}=\lim{N^{-1}}\sum_{i}q_i=\plim{Q_{N}(\theta)}$ и условие (12.29) удовлетворено. Таким образом, симуляционная М-оценка  состоятельна, а на одно наблюдения приходится всего лишь одна симуляция $u_i$, при условии $\E_{u_{iS}}[\hat{q}_i]=q_i$.

К сожалению, этот результат трудно применить на практике, поскольку редко возможно найти несмещенную вспомогательную оценку $q_i$. Например, используя метод максимального правдоподобия возможно найти несмещенную вспомогательную оценку для плотности $f_i$, но невозможно найти несмещенную вспомогательную оценку для $\ln{f_i}$. Аналогично, для нелинейного МНК  возможно найти несмещенную вспомогательную оценку для условного среднего, но невозможно найти несмещенную оценку для среднеквадратических ошибок, т.к. она содержит в себе квадрат условного среднего. 

В некоторых случаях, возможно применить полученный результат, чаще это удается в случае, если используется метод моментов или обобщенный метод моментов, а не М-оценка.

\subsection{Симуляционный метод моментов}

Пусть, согласно теории, условие на условный момент задано выражением

\begin{equation}
\E[m(y_i,x_i,\theta_0)]=0,
\end{equation}
где, для упрощения, $m(\cdot)$ скаляр. Допустим, что $w_i$ обозначает инструментальные переменные, и функция $m$ от $x_i$ и $\theta_0$, удовлетворяют условию

\begin{equation}
\E[w_{i}m(y_i,x_i,\theta_0)]=0.
\end{equation}

Оценка параметра, полученная при помощи метода моментов $\hat{\theta}_{MM}$ (см. Главу 6.3.1) минимизирует значение функции

\begin{equation}
Q_{N}(\theta)=\left[\dfrac{1}{N}\sum^{N}_{i=1}w_{i}m(y_i,x_i,\theta)\right]^{'}\left[\dfrac{1}{N}\sum^{N}_{i=1}w_{i}m(y_i,x_i,\theta)\right],
\end{equation}
где для простоты предполагается случай точной идентификации, $\dim[w_i]=\dim[\theta]$. Результаты можно обобщить на более общий случай сверхидентифицируемой модели, тогда обозначения будут более сложными, поскольку необходимо вводить обозначения для взвешивающей матрицы и, кроме того, оценка производится при помощи ОММ.

Оценка параметра методом моментов состоятельна и в пределе имеет нормальное распределение с ковариационной матрицей, значения которой частично зависят от инструментов $w_i$. Рассмотрим пример нелинейной регрессии, где $m(y,x,\theta)=y-\E[y|x]$ --- это остаточный член и условное среднее $\E[y|x]$ является заданной функцией от $x$ и $\theta$. Тогда наилучшим выбором инструментальной переменной будет $w=\partial{\E[y|x]}/{\partial{\theta}}{\mid}_{\theta_0}$ при гомоскедастичности ошибок, поскольку тогда условия первого порядка метода моментов и нелинейного МНК совпадают.

Теперь предположим, что не существует аналитического выражения для $m(y,x,\theta)$. Например, в модели нелинейной регрессии может не быть аналитического выражения для условного среднего. Вместо этого, $m(y,x,\theta)$ может быть выражено интегралом

\begin{equation}
m(y_i,x_i,\theta)=\int{h(y_i,x_i,u_i,\theta)g(u_i)du_i},
\end{equation}
для некоторых функций $h(\cdot)$ и $g(\cdot)$, и интеграл  не имеет аналитического решения. В таком случае невозможно получить оценку методом моментов.

Оценка параметра, полученная симуляционным методом моментов (MSM, method of simulated mometns) $\hat{\theta}_{MSM}$ минимизирует

\begin{equation}
\hat{Q}_{N}(\theta)=\left[\dfrac{1}{N}\sum^{N}_{i=1}w_{i}\hat{m}(y_i,x_i,u_{iS},\theta) \right]^{'}\left[\dfrac{1}{N}\sum^{N}_{i=1}w_{i}\hat{m}(y_i,x_i,u_{iS},\theta) \right],  
\end{equation}
где $\hat{m}(y_i,x_i,u_{iS},\theta)$ несмещенная вспомогательная оценка для $m(y_i,x_i,\theta)$, которая удовлетворяет условию

\begin{equation}
\E[\hat{m}(y_i,x_i,u_{iS},\theta)]=m(y_i,x_i,\theta),
\end{equation}
где $u_{iS}$ означает $S$-тое случайное значение предельной плотности $g(u_i)$ и $S\geq 1$. Примеры $m_i$ и вспомогательных несмещенных оценка $\hat{m}_i$,  даны далее.

\subsection{Распределение оценок симуляционных моментов}

Оценка симуляционных моментов была предложена МакФадденон (1989), который доказал нижеследующие свойства этой оценки.

\begin{proposition}[Распределение оценок симуляционных моментов] (МакФадден (1989): Предположим, что 
\begin{enumerate}
\item У процесса порождающего данные функция $m(y,x,\theta_0)$ имеет нулевое условное среднее как в (12.30) и $w_{i}m(y,x,\theta_0)$ имеет нулевое безусловное среднее, как в (12.31) и выполняются другие предпосылки так, что оценка методом моментов, минимизирующая значение функции (12.32) состоятельна и распределена асимптотически нормально.
\item Функция $m(y,x,\theta_0)$ определена выражением (12.33) и её вспомогательная оценка $\hat{m}(y,x,\theta_0)$ является несмещенной и удовлетворяет условию (12.35).
\end{enumerate}
Тогда, при фиксированном $S$, оценка симуляционного метода моментов, минимизирующая (12.34), состоятельна, распределена асимптотически нормально при $N \rightarrow 0$ и имеет предельное нормальное распределение с
\end{proposition}

\begin{equation}
\sqrt{N}(\hat{\theta}_{MSM}-\theta_0) \stackrel{d}{\rightarrow} \mathcal{N}[0,A^{-1}(\theta_0)B(\theta_0)A^{-1}{(\theta_0)}^{'}],
\end{equation}

где

\begin{equation}
\left. A(\theta_0)=\plim\dfrac{1}{N}\sum^{N}_{i=1}w_{i}\dfrac{\partial{m_{i}(\theta)}}{\partial{\theta}'} \right|_{\theta_0}
\end{equation}

и

\begin{equation}
B(\theta_0)=\plim\dfrac{1}{N}\sum^{N}_{i=1}w_{i}\V[\hat{m}_{i}(\theta_0)]{w_{i}}',
\end{equation}
здесь ковариационная матрица $\V[\cdot]$,  рассчитывается по отношению к условному распределению переменной $y_i$, при заданном значении $x_i$, а также для симулированных значений $u_{iS}$, вычисляемых согласно (12.35).

Перед тем как перейти к выводу данного утверждения отметим следующее. Во-первых, оценка симуляционных моментов имеет особое свойство --- она состоятельна, даже при $S=1$. Во-вторых, для конечного числа $S$ наблюдается потеря эффективности. Ковариационная матрица оценки $\hat{\theta}_{MM}$ аналогична матрице оценки $\hat{\theta}_{MSM}$, за исключением того, что у оценки моментов $\V[\hat{m}_i]$ из (12.38) заменяется на меньшую $\V[m_i]$. В-третьих, потеря эффективности, которая появляется из-за симуляций, исчезает при $S \rightarrow \infty$, так как в этом случае $\V[\hat{m}_i] = \V[m_i]$. В-четвертых, как и для оценивания с помощью метода моментов, метод симуляционных моментов при $S \rightarrow \infty$ может быть неэффективен по сравнению с другими методами оценивания, если инструменты $w$ выбраны плохо.

Состоятельность оценок, полученных методом симуляционных моментов требует выполнения условия (12.29) для $\hat{Q}_N(\theta)$ и $Q_N(\theta)$, заданных выражениями (12.34) и (12.32), соответственно. Согласно закону больших чисел

\[
\plim\dfrac{1}{N}\sum^{N}_{i=1}w_{i}\hat{m}_i=\plim{N^{-1}\sum^{N}_{i=1}w_{i}\E_{u_{iS}}[\hat{m}_i]},
\]
где первый вероятностный предел берется по всем стохастическим переменным, в то время как второй вероятностный предел берется по всем переменным за исключением симулированных значений $u$. В данном случае, $\E_{u_{iS}}[\hat{m}_i]=m_i$, поскольку $\hat{m}_i$ является несмещенной вспомогательной оценкой, поэтому

\[
\plim\dfrac{1}{N}\sum^{N}_{i=1}w_{i}\hat{m}_i=\plim{N^{-1}\sum^{N}_{i=1}w_{i}m_{i}}.
\]
Это, в свою очередь, приводит к тому, что $\plim{\hat{Q}_N(\theta)}=\plim{Q_{N}(\theta)}$. Тогда, оценка $\hat{\theta}_{MSM}$ является состоятельной, если $\theta_0$ является точкой максимума функции  $\plim{Q_N(\theta)}$, что является необходимым условием состоятельности исходного метода моментов.

Для предельного распределения, дифференцирование $\hat{Q}_N(\theta)$ по $\theta$ приводит к

\[
\left(\dfrac{1}{N}\sum^{N}_{i=1}w_{i}\dfrac{\partial\hat{m}_{i}(\theta)}{\partial{\theta}'} \right)'\dfrac{1}{N}\sum^{N}_{i=1}w_{i}\hat{m}_{i}(\hat{\theta})=0.
\]

Первая матрица является квадратной матрицей полного ранга, то есть  $\hat{\theta}_{MSM}$ удовлетворяет условию первого порядка

\[
\dfrac{1}{N}\sum^{N}_{i=1}w_{i}\hat{m}_{i}(\hat{\theta})=0,
\]
где $\hat{m}_{i}(\theta)=\hat{m}_{i}(y_i,x_i,u_{iS},\theta)$. Используя стандартное разложение первого порядка в ряд Тейлора в окрестности точки $\theta_0$, получим

\[
\left. \sum^{N}_{i=1}w_{i}\hat{m}_{i}(\theta_0)+\sum^{N}_{i=1}w_{i}\dfrac{\partial{\hat{m}}_{i}(\theta)}{\partial{\theta}'}\right|_{\theta^{*}}(\hat{\theta}-\theta_0)=0,
\]

и, таким образом,

\[
\left. \sqrt{N}(\hat{\theta}-\theta_0)=-\left(N^{-1}\sum^{N}_{i=1}w_{i}\dfrac{\partial\hat{m}_i(\theta)}{\partial\theta'}\right|_{\theta^{*}}\right)^{-1}N^{-1/2}\sum^{N}_{i=1}w_{i}\hat{m}_i(\theta_0) 
\]
Теперь $\E_{u}[\partial\hat{m}(\theta)/\partial\theta]=\partial{\E_u[\hat{m}(\theta)]}/\partial\theta=\partial{m(\theta)}/\partial\theta$, тогда первая матрица с правой стороны сходится к $A(\theta_0)$, заданной в утверждении 12.2. Второй элемент справа имеет предельное нормальное распределение с нулевым средним и ковариационной матрицей

\[
B(\theta_0)=\plim{\dfrac{1}{N}}\sum^{N}_{i=1}w_{i}\V[\hat{m}_{i}(\theta_0)]w'_{i},
\]
как в утверждении 12.2, где дисперсия $\V[\hat{m}_{i}(\theta_0)]$ считается по отношению к  $u_{iS}$ и условному распределению $y_i$, при заданном значении $x_i$.

Поскольку значения $u_{iS}$ независимы от $y_i$ получим, что

\[
\V_{y,u}[\hat{m}(\theta_0)]=\V_{y}[\E_{u}[\hat{m}(\theta_0)]]+\E_{y}[\V_{u}[\hat{m}(\theta_0)]]=\V_{y}[m(\theta_0)]+\E_{y}[\V_{u}[\hat{m}(\theta_0)]].
\]

Применяя подстановку, получаем детальное выражение для $B(\theta_0)$,  данное в утверждении 12.2.


Симуляция приводит к росту дисперсии оценок симуляционных моментов из-за величины $\E_{y}[\V_{u}[\hat{m}(\theta_0)]]$, стремящейся к нулю при $S \rightarrow \infty$. В частном случае, когда вспомогательная оценка является частотной оценкой, может быть показано, что $\V_{y,u}[\hat{m}(\theta_0)]=(1+1/S)\V_{y}[m(\theta_0)]$, т.е. в данном случае симуляционный метод моментов увеличивает дисперсию MM-оценок в $(1+1/S)$ раз!

\subsection{Выбор между симуляционным методом моментов и симуляционным правдоподобием}

Любой практик хочет взвесить плюсы и минусы симуляционных моментов и симуляционного правдоподобия. При условии, что оценки симуляционных моментов состоятельны для малых $S$, и, учитывая трудность обеспечения достаточно большого значения $S$, чтобы была хорошая аппроксимация функции правдоподобия, почему оценка симуляционного правдоподобия может быть когда-либо более предпочтительной, чем оценка симуляционных моментов?

Во-первых, заметим, что симуляционное правдоподобие в принципе является прямым и простым для реализации способом. При параметрических предположениях, оптимальное взвешивание наблюдений внутренне присуще симуляционному правдоподобию. Метод симуляционных моментов, аналогично ОММ, требует работы с произведениями взвешивающих функций (или инструментальными переменными) и остатков, и эти компоненты могут быть коррелированы. Численная неустойчивость ОММ-оценки (без симуляций) была описана, например, Альтонжи и Сигалом (1996) (см. раздел 6.3.5). Точно так же, Гевеке, Кин, и Рункл (1997) и МакФадден и Рууд (1994) представили доказательства неустойчивости оценки симуляционных моментов. Тем не менее, хотя простота выступает в пользу симуляционного правдоподобия, нельзя забывать про трудности, связанные проведением достаточного количества симуляций.

\subsection{Пример ненаблюдаемой гетерогенности}

Обратимся к примеру, рассмотренному в Разделе 12.4.5. Тогда $y_i{\sim }\mathcal{N}[\theta+u_i,1]$, где $u_i$ имеют плотность $g(u_i)$, заданную выражением (12.24). Поскольку $\E[y_i-\theta-u_i]=0$, можно оценить $\theta$ методом моментов, и оценка  является решением 

\begin{equation}
\dfrac{1}{N}\sum^{N}_{i=1}(y_i-\theta-\E[u_i])=0,
\end{equation}
в результате получим, что $\hat{\theta}_{MM}=\overline{y}-\E[\overline{u}]$. Предположим, что $\E[\overline{u}]$ неизвестно. В таком случае вместо этого можно использовать оценку симуляционных моментов $\hat{\theta}_{MSM}$, которая является решением уравнения

\begin{equation}
\dfrac{1}{N}\sum^{N}_{i=1}\left(y_i-\theta-\dfrac{1}{S}\sum^{S}_{s=1}u^{s}_i \right)=0, 
\end{equation}
где $u^{s}_i$ независимы и имеют распределение экстремальных значений.

Оценивающее уравнение (12.40) может быть решено, и

\begin{equation}
\hat{\theta}_{MSM}=\overline{y}-\overline{\overline{u}},
\end{equation} 
где $\overline{\overline{u}}=(NS)^{-1}\sum_{i}\sum_{s}u^{s}_i$ --- это среднее и по $N$, и по $S$. Однако, в общем случае, может потребоваться итерационный метод для вычисления оценки симуляционного правдоподобия.

Дисперсию  оценки $\hat{\theta}_{MSM}$ легко получить. По построению симуляционные значения $u$ независимы между собой и независимы с начальными данными $y$, таким образом $\V[\hat{\theta}_{MSM}]=\V[\overline{y}]+\V[\overline{\overline{u}}]$. Тогда $\V[\overline{y}]=(\sigma^{2}_u+1)/N$. Поскольку $\overline{\overline{u}}$ среднее из $NS$ симуляций
$u$ и $\V[\overline{\overline{u}}]=\sigma^{2}_{u}/NS$, мы приходим к выводу, что

\begin{equation}
\V[\hat{\theta}_{MSM}]=\V[\overline{y}]+\V[\overline{\overline{u}}] = \dfrac{\sigma^{2}_u+1}{N}+\dfrac{\sigma^{2}_u}{NS}.
\end{equation}
Это выражение можно состоятельно оценить с помощью $\hat{\sigma}^{2}_u=(NS)^{-1}\sum^{N}_{i=1}\sum^{S}_{s=1}(u^{s}_i-\overline{\overline{u}})^2$.

Рассмотрим выборку $\lbrace{y_1,\ldots ,y_{100}}\rbrace$ размера $N=100$, сгенерированную с использованием модели (12.24) при $\theta=1$. В таблице 12.3 даны оценки симуляционных моментов при количестве симуляций стремящемся к бесконечности, $S \rightarrow \infty$. С ростом количества симуляций значение оценки симуляционных моментов сходится к оценке метода моментов, и происходит уменьшение стандартных ошибок.

\begin{table}[h]
\begin{center}
\caption{\label{tab:pred} Оценивание с помощью симуляционных моментов: пример}
\begin{tabular}{lccccc}
\hline 
\hline
{\bf{Число симуляций}} & $S = 1$ & $S = 10$ & $S = 100$ & $S = 1,000$ & $S = \infty (MM)$ \\ 
\hline
$MSM$-оценка параметра $\hat{\theta}$ & 1.0073 & 1.1096 & 1.2012 & 1.1887 & 1.1889 \\ 
Стандартная ошибка & (.2471) & (.1657) & (.1681) & (.1676) & (.1684) \\ 
\hline 
\hline
\end{tabular} 
\end{center}
\end{table}


\section{Косвенные оценки}

В этом разделе мы рассмотрим иной симуляционный подход, используемый в случае, когда исследователь хочет применить или оценить относительно простую модель, даже если процесс порождающий данные более сложный или его оценивание вызывает затруднения. Существует несколько вариантов и интерпретаций этого подхода; см. Гурьеру, Монфорт, и Рено (1993), Смит (1993), и Галлант и Таухен (1996). Рассматриваемый подход также получил название подход сопоставления моментов. Описание, представенное в этом разделе во многом совпадает с описанием в работе Гурьеру, Монфорт, и Рено (1993). 

Предположим, что параметрический процесс порождающие данные задан с помощью функции плотности $f(y;\theta),\theta{\e}R^{q}$, параметры которой трудно оценить. Допустим, что возможно специфицировать вспомогательную модель, в которой процесс порождающий данные задан плотностью $f^{a}(y;\beta), \beta{\e}R^{r}$, которую легко оценить с помощью метода квази-максимального (или иногда <<псевдо->>) правдоподобия. 
По причине идентифицируемости, обсуждаемой дальше, предположим, что размерность $\beta$ не меньше, чем размерность $\theta$, т.е. $r\geq q$. К примеру, вспомогательная модель может быть приближением функции правдоподобия исходной модели или может быть точным правдоподобием приближенной модели. 
Для заданной выборки, пусть $\hat{\beta}$ обозначает оценки квази-максимального правдоподобия. Тогда, согласно результатам Раздела 5.7, в общем случае $\hat{\beta}$ является несостоятельной оценкой параметра $\theta$, и, при некоторых предположениях о регулярности, эта оценка сходится по вероятности к так называемому псевдо-истинному значению, которое является функцией от $\theta$. 
Функция, которая связывает параметры вспомогательной модели с параметрами процесса порождающего данные называется связывающей функцией и обозначается $h(\theta)$. Аналитическая форма данной функции может быть известной или неизвестной. Таким образом, не всегда возможно рассчитать $\theta=h^{-1}(\beta)$ или $\hat{\theta}=h^{-1}(\hat{\beta})$.

Метод косвенной оценки может быть использован для улучшения оценок метода квази-максимального правдоподобия и получения оценок с меньшей асимптотическим смещением, чем у  $\hat{\beta}$. Идея состоит в том, чтобы использовать модель  с плотностью $f(y;\theta)$, чтобы случайным образом сгенерировать псевдо-наблюдения $y^{(s)}$ и применить вспомогательную модель с плотностью $f^{a}(y^{(s)};\beta)$, чтобы оценить $\hat{\beta}^{(s)}$, где $s$ обозначает $s$-тую симуляцию. Непрямая оценка является решением уравнения

\begin{equation}
\hat{\theta}=\arg \min_{\theta}(\hat{\beta}^{(s)}-\hat{\beta})'\Omega(\hat{\beta}^{s}-\hat{\beta}),
\end{equation}
где $\Omega$ --- это заданная симметричная положительно определенная матрица. Этот способ оценивания похож на метод минимального расстояния, рассмотренный в Разделе 6.7. То есть, последовательно генерируются псевдо-наблюдения и оценка параметров производится при помощи вспомогательной модели, с использованием псевдо-наблюдений. Итерации продолжается до тех пор, пока квадратичная форма (12.43) не примет минимальное значение. Важный момент состоит в том, что зерно (seed) генерирования псевдо-случайных значений $y^{(s)}$ остается неизменным, и источником изменчивости псевдо-наблюдений  является изменчивость значений $\hat{\beta}^{(s)}$. 

Перед тем как перейти к дальнейшему обсуждению, рассмотрим простой, конкретный пример с нелинейным процессом порождающим данные и линейной вспомогательной моделью. Мотивирован этот пример тем, что вспомогательная модель должна легко оцениваться, а процесс порождающий данные должен легко симулироваться.

Допустим, что процесс порождающий данные имеет вид:

\begin{equation}
y_i=\exp(x'_{i}\gamma)+u_i,
\end{equation}

\[
u_{i} \sim \mathcal{N}[0,\sigma^2].
\]

И вспомогательная модель задана следующим образом: 

\begin{equation}
y_i=x'_{i}\beta+\e_i,
\end{equation}

\[
\e_i\sim \mathcal{N}[0,\sigma^{2}_{\e}].
\]

Заметим, следующую интерпретацию:

$\dfrac{\partial{\E[y|x]}}{\partial{x}}=\beta$ (согласно вспомогательной модели),

$\dfrac{\partial{\ln{\E[y|x]}}}{\partial{x}}=\dfrac{\partial{\E[y|x]}}{\partial{x}}\times \dfrac{1}{\E[y|x]}=\gamma$ (согласно процессу порождающему данные).

Поэтому связывающая функция имеет вид $\gamma{\E[y|x]}=\beta$ или $\gamma=(\E[y|x])^{-1}\beta$. Заметим, что размерность $\beta$ равна размерности $\gamma$, т.е. $\dim[\beta]=\dim[\gamma]$.

При заданных значениях $(x_i,y_i,i=1,\ldots ,N)$, МНК-оценке $\hat{\beta}$, а также псевдо-случайных симуляциях размерности $N$, которые обозначены $u^{(0)}$, создадим $y^{(1)}_i(i=1,\ldots ,N)$ используя

\[
y^{(1)}_i=\exp(x'_{i}\hat{\beta})+u^{(0)}_i
\]
и получим обновлённую оценку $\hat{\beta}^{(1)}=(\sum{x_{i}x'_{i}})^{-1}\sum{x_{i}y^{(1)}_i}$, которая в дальнейшем используется для создания другого множества псевдо-наблюдений. Весь цикл симулирования повторяется, при фиксированных значениях $u^{(0)}$, до тех пор, пока $(\hat{\beta}^{(s)}-\hat{\beta})'\Omega(\hat{\beta}^{(s)}-\hat{\beta})$ не станет константой с ожидаемой точностью. В данном случае целесообразно выбрать $\Omega$ равной единичной матрице или $X'X$, выбор последнего варианта предполагает, что прогнозы из вспомогательной модели являются целью моделирования. Полученная в результате оценка параметра $\gamma$ является косвенной оценкой.

При других предпосылках $\dim{(\beta)}$ будет превышать $\dim{(\theta)}$ так, что  значение $\theta$ может не быть уникальным. Более того, при отсутствии аналитической формы связывающей функции, невозможно восстановить исходное значение параметра $\theta$, даже если размерности равны. В таком случае следует произвести оценку параметров вспомогательной модели, используя наилучшую косвенную оценку.

Для иллюстрации взаимосвязи между косвенной оценкой и оценкой, полученной методом сопоставления моментов, сделаем допущение, что $\Omega=X'X$; тогда $(\hat{\beta}^{(s)}-\hat{\beta})'X'X(\hat{\beta}^{(s)}-\hat{\beta})=(\hat{\beta}^{(s)}X-\hat{\beta}X)'(\hat{\beta}^{(s)}X-\hat{\beta}X)$, это означает, что косвенная оценка <<сопоставляет>> первый момент распределения. Для того, что вторые моменты также совпали, необходимо добавить параметры к вектору $\beta$, к примеру, параметр дисперсии. Таким образом, возможно сделать так, что значения первых начальных моментов будут совпадать.

При выполненных условиях регулярности, косвенный способ оценивания дает состоятельные и асимптотически нормальные оценки. Для дополнительной информации читатель может обратится к ранее упомянутым источникам.

\section{Вспомогательные оценки}

Как и в Разделе 12.3.2 рассмотрим расчет интеграла

\begin{equation}
I=\E[h(x)]=\int{h(x)g(x)dx},
\end{equation}
где для простоты $x$ чаще всего будет скаляром. Как и в Разделе 12.3 $x$ обозначает переменную интегрирования, в то время как в приложении переменная интегрирования обозначена часто за $u$, поскольку $x$ обозначает регрессор. 

Вспомогательная оценка это метод, позволяющий рассчитать $I$. Существует много способов сделать это, помимо прямого интегрирования с помощью Монте-Карло, приведенного в (12.14). В идеальном случае, вспомогательная оценка должна быть несмещенной, поскольку многие результаты Разделов 12.4 и 12.5 получены при использовании несмещенных оценок. Желательной является гладкость оценки, т.к. гладкость означает возможность применения итерационных градиентных методов. Однако, даже в этом идеальном случае время расчетов моделей, интересных с эмпирической точки зрения, может быть фантастически огромным. Далее рассмотрим несколько процедур, специально разработанных для ускорения процесса симулирования путем сокращения, для заданного количества симуляций, дисперсии симуляций по сравнению с базовыми методами, такими как интегрирование с помощью Монте-Карло. Более детально этот вопрос рассмотрен у Гевеке и Кина (2001).

\subsection{Частотные вспомогательный оценки}

Вначале рассмотрим пример частотной вспомогательной оценки, которая может быть применена к ряду дискретных моделей. Рассмотрение этого частного случая хорошо подчеркивает возможные трудности, которые могут возникнуть при симуляциях.

Предположим, что функция $h(x)$ является индикатором и принимает значение 1, если $x \in A$ и 0 в ином случае. Мы хотим подсчитать значение интеграла 
\[
I=\int{{\bf{1}}(x \in A)g(x)dx}.
\]

Применение прямого метода интегрирования с помощью Монте-Карло дает оценку

\[
\hat{I}_{FREQ}=\dfrac{1}{S}\sum^{S}_{s=1}{\bf{1}}(x^{s} \in A),
\]
где $x^s,s=1,\ldots ,S$ являются $S$ симуляциями функции $g(x)$. Этот метод является частотной вспомогательной оценкой поскольку оценка $I$ --- это частота, с которой $S$ симуляций $x^s$ попадают в  множество $A$. 

Основным возможным применением данного способа является мультиномиальная модель дискретного выбора, впервые упомянутая в Разделе 12.2.2. Именно она послужила толчком к исследованию симуляционных методов в экомнометрической литературе.  В модели с тремя альтернативами, вероятность выбора первой альтернативы, $p_1$, задана выражением (12.3) и равна интегралу по положительному ортанту двумерного нормального распределения. Значение частотной оценки $\hat{p}_1$ --- это просто доля симуляций $(u^{s}_1,u^{s}_2)$ двумерного нормального распределения у которых $u^{s}_1\geq 0$ и $u^{s}_2\geq 0$.

Применение частотных оценок имеет ряд ограничений. Во-первых, частотные оценки не являются ни дифференцируемыми, ни непрерывными по параметру $\theta$, который появляется в ${\bf{1}}(x \in A)$ и/или в $g(x)$. Малые изменения в значениях параметра $\theta$ приводят к одному и тому же числу симуляций, попадающих в положительный ортант. По этой причине МакФадден (1989) и Пэйкс и Поллард (1989) предложили более общую асимптотическую теорию, которая охватывает такие негладкие оценки. Однако на практике лучше всего  использовать альтернативные гладкие оценки, которые дифференцируемы по параметрам, так как это позволяет проводить расчёты с помощью градиентных методов.

Во-вторых, данный частотные вспомогательный оценки очень неэффективены, если очень малая часть $x \in A$. Например, для моделей дискретного выбора с $p_1=0.001$, даже если количество симуляций $S$ достигает 10,000 ошибки оценки $\hat{p}_1$ будут очень велики. Аналогичная проблема возникает в более общем случае, когда используется метод Монте-Карло (12.46) с непрерывной функцией $h(x)$, когда вероятность генерирования значений $x$ в области больших $h(x)$ низка.

В-третьих, применение данной вспомогательной оценки может быть затруднено на границах промежутка и, тогда в результате может получится, что $\hat{I}=0$ или $\hat{I}=1$, если согласно предпосылкам модели $0<I<1$ и это условие является необходимым для оценки модели.

\subsection{Сэмплирование по важности}

Сэмплирование по значимости (importance sampling) выражает интеграл (12.46) в следующем виде:

\begin{equation}
I=\int{\left(\dfrac{h(x)g(x)}{p(x)}\right)p(x)dx}
\end{equation}

\[
=\int{w(x)p(x)dx},
\]
где $p(x)$ функция плотности распределения построенная таким образом, что (а) легко сгенерировать случайную выборку из $p(x)$, (b) $p(x)$ имеет носитель совпадающий с  первоначальной областью интегрирования и (c) $w(x)=h(x)g(x)/p(x)$ легко оценить, ее значение ограничено и имеет конечную дисперсию. Далее используем оценку интеграла, рассчитанную при помощи прямого метода Монте-Карло на основе (12.47) вместо (12.46), и получим

\begin{equation}
\hat{I}_{IS}=\dfrac{1}{S}\sum^{S}_{s=1}w(x^{s}),
\end{equation}
где $x^s, s=1,\ldots ,S$ генерируются согласно плотности $p(x)$, а не $g(x)$. Термин сэмплирование по важности используется, потому что $w(x)$ определяет вес или <<важность>> различных точек в выборке. Сэмплирование по важности долгие годы применялось в литературе, посвященной байесовскому моделированию, и было введено в эконометрику Клоэком и ван Дейком (1978) в качестве метода оценивания апостериорных распределений. Этот вопрос рассмотрен далее в разделе 13.4.

Оценка сэмплирования по важности $\hat{I}_{IS}$ имеет дисперсию $S^{-1}\V_p[w(x)]$ при независимой выборки из $p(x)$.  Дисперсию достигает своего минимума, если $w(x)$ постоянна на всем промежутке интегрирования, так как в этом случае дисперсия $\V_p[w(x)] = 0$. Это можно сделать, если задать $w(x) = \E_g[h(x)]$,  так как в этом случае $p(x) = h(x)g(x)/\E_g[h(x)]$ --- это плотность, интеграл которой равен 1. К сожалению, эта оценка, которая является теоретически идеальной, не доступна на практике, так как $\E_g[h(x)]$ неизвестно. Однако это говорит о потенциальном преимуществе сэмплирования по важности, особенно в случае если $p(x)$ так выбрано, чтобы $w(x)$ было практически неизменным.

Даже если сэмплирование по важности приводит к увеличению дисперсии, у него могут быть другие положительные черты. Оно позволяет получить гладкие оценки, если $w(x)$ является гладкой по оцениваемым параметрам. Более того, сэмплирование по важности полезно, если тяжело генерировать выборку из $g(x)$, что может часто случаться, если $x$ --- это вектор коррелированных случайных переменных.

Для мультиномиальной дискретной пробит-модели широко распространенное сэмплирование по важности --- это GHK (Geweke-Hajivassiliou-McFadden) оценка, предложенная Гевеке (1992), Хаживассилиу и МакФадденон (1994), и Кином (1994). Она рекурсивно усекает многомерную функцию нормального распределения так, чтобы выборка генерировалась только на положительном ортанте. Преимущества этой оценки по сравнению с частотной оценкой состоят в том, что она гладкая, требует гораздо меньший размер выборки для альтернатив, которые могут быть выбраны с малой вероятностью, а также у неё, скорее всего, не будет проблем с граничными значениями.

\subsection{Понижение дисперсии при помощи антитетического ускорения}

В ранее рассмотренных методах предполагалось, что симуляции независимы друг от друга, с использованием методов детально рассматриваемых в Разделе 12.8, при использовании плотности  $g(x)$, или, если используется сэмплирование по важности, то $p(x)$. 

В методах понижения дисперсии используются зависимые симуляции, поскольку это может привести к сокращению дисперсии оценки. Основным примером является создание антитетической выборки, использующей отрицательно коррелированные симуляции. Этот способ рассмотрен в работе Рипли (1987, стр. 129-132), Гевеке (1988) и Хаживассилиу (2000), а также в работе Гевеке (1995), где также рассмотрены и другие способы понижения дисперсии.

Предположим, что необходимо оценить интеграл $I$ в (12.46), где $x$ имеет нулевое среднее и симметричную плотность  $g(x)$. Оценка интеграла с помощью простого метода Монте-Карло,  построенного на выборке из $2S$  независимо и одинаково распределенных значениях с плотностью $g(x)$, равна

\[
\hat{h}_{2S}(x)=\dfrac{1}{2S}\sum^{2S}_{s=1}h(x^s)
\]
и, при  независимости $2S$ симуляций, дисперсия равна 

\[
\V[\hat{h}_{2S}(x)]=\dfrac{1}{2S}\V[h(x)].
\]

При создании антитетической выборки альтернативная оценка, при расчете которой используются только $S$ независимо и одинаково распределенных симуляций,

\begin{equation}
\hat{h}_{A,S}(x)=\dfrac{1}{S}\sum^{S}_{s=1}\dfrac{1}{2}(h(x^s)+h(-x^s)),
\end{equation}
значение выражения равно среднему $h(x)$, оцениваемых в точках $x^s$ и $-x^{s}$. Пара $(x^s,-x^s)$ называется антитетической парой и дает несмещенную оценку $I$, поскольку $x$ симметрично распределен с нулевым средним. Если среднее равно $\mu$, тогда антитетическая пара равна $(x^s,2\mu-x^s)$. Если  количество независимых симуляций  для $x^s$  равно $S$ дисперсия $\hat{h}_{A,S}(x)$ равна 

\[
\V[\hat{h}_{A,S}(x)]=\dfrac{1}{S^2}\sum^{S}_{s=1}\dfrac{1}{4}(\V[h(x^s)]+2\Cov[h(x^s),h(-x^s)]+\V[h(-x^s)])=\dfrac{1}{2S}(\V[h(x)]+\Cov[h(x),h(-x)]).
\]

Таким образом, использование антитетической выборки даст более эффективные оценки, чем использование обычных, независимо и одинаково распределенных выборочных значений, если ковариация отрицательна, тогда значение вариации $\hat{h}_{A,S}(x)$ будет меньше, чем $\hat{h}_{2S}(x)$. Смена знака сгенерированного значения и его повторное использование --- это попытка получить отрицательную корреляцию при моделировании. Отрицательная корреляция будет появляться, если функция задана линейно или если отсутствует сильная нелинейность. Однако, в общем случае, нельзя утверждать, что будет выигрыш в  эффективности. К примеру, если $h(\cdot)$ симметрична относительно нуля, то $\Cov[h(x),h(-x)]=\V[h(x)]$.

Антитетическое сэмплирование может применяться так же для несимметричной плотности $g(x)$. Предположим, что симулированные значения $x$ могут быть получены методом обратного преобразования, рассмотренного далее в Разделе 12.8.2. Тогда возможно получить симулированные значения $u$, к примеру равномерно распределенные с параметрами $[0,1]$, произвести антитетическое преобразование $(1-u)$ и применить метод обратного преобразования для того, чтобы получить симуляции из выбранного распределения, так что $x_1=G^{-1}(u)$ и $x_2=G^{-1}(1-u)$, где $G(\cdot)$ известная  функция распределения $x$. Тогда $(x_1,x_2)$ формируют антитетическую пару и сокращение дисперсии наблюдается, если

\[
\Cov[h(G^{-1}(u)),h(G^{-1}(1-u))]=\Cov[f(u),f(1-u)]<0,
\] 
где $f(u)$ является сложной функцией $h(G^{-1}(u))$. Если $f(\cdot)$ монотонная функция, тогда дисперсия сокращается (Роберт и Казелла, 1999, стр. 112). Однако, свойство монотонности трудно проверить. Кроме того, утверждение о сокращении дисперсии справедливо только для метода обратного преобразования, в то время как на практике применяются другие методы формирования псевдо-случайных чисел (см. Раздел 12.8). Таким образом, трудно заранее понять, можно ли добиться роста эффективности в данной конкретной задаче.


Несмотря на то, что фантастический выигрыш в эффективности проявляется не во всех случаях, существенный выигрыш наблюдается во  многих случаях. Антитетическое сэмплирование также может применяться для ускорения сэмплирования по важности (Даниэлссон и Ричард, 1993)

Антитетическая выборка может использоваться и для многомерных распределений. Рассмотрим двумерную случайную величину $(x,y)$,  плотность которой симметрична относительно точки $(0,0)$. В этом случае сначала меняется знак для всех элементов по-отдельности, а затем попарно. Тогда антитетическая четверка состоит из $((x^s,y^s),(-x^s,y^s),(x^s,-y^s),(-x^s,-y^s))$. Для случайных величин размерности $m$ применяется аналогичная идея.

\subsection{Вычисления с использованием квази-случайной последовательности}

Второй метод сокращения дисперсии предполагает замену псевдо-случайных величин квази-случайными величинами, которые являются систематизированными случайными симуляциями, обеспечивающие лучший охват множества значений. Потенциальное ограничение этого подхода заключаются в том, что случайность требуется для использования закона больших чисел и центральной предельной теоремы, которые оправдывают применение симуляционных методов.

В квази-методе Монте-Карло вместо $S$ псевдо-случайных величин используются неслучайные значения принадлежащие области интегрирования. Основным примером являются последовательности Халтона, их обзор можно найти в книге Пресс и др. (1993) и впервые введенной в эконометрическую литературу Бхатом (2001) и Трейном (2003).

Последовательности Халтона имеют два желательных свойства. Во-первых, эти последовательности построены таким образом, чтобы достаточно равномерно покрывать область значений симулируемого  распределения. При использовании более равномерно распределенных симуляций для каждого отдельного наблюдения, значения симулированных вероятностей меняются меньше, чем значения, рассчитанные на основе случайных симуляций. Эти результаты схожи с детерминированной оценкой интеграла по заданной  сетке. 
Во-вторых, в последовательности Халтона новое наблюдение стремится заполнить пустые места, оставленные предыдущими наблюдениями. По этой причине оцененные вероятности отрицательно коррелируют по наблюдениям. Как и в случае антитетических пар случайных величин отрицательная корреляция уменьшает дисперсию оцениваемой функции. При подходящих условиях регулярности можно показать, что ошибка интегрирования при использовании квази-случайных последовательностей имеет порядок $N^{-1}$ по сравнению с псевдо-случайными последовательностями, где скорость сходимости равна $N^{-1/2}$ (Бхат, 2001).

Последовательность Халтона легко представить с помощью примера. Предположим, что симулируемая функция, зависит от одной случайной переменной. Стартовое значение является простым числом. Последовательность Халтона, в основе которой лежит просто число 2, строится следующим образом. Вначале единичный интервал $(0,1)$ делится на две части. Точка деления $1/2$ становится первым элементом последовательности Халтона. Далее каждая из частей делится на две части. Точки деления, $1/4$ и $3/4$ становятся двумя последующим элементами последовательности. Деление каждой из образовавшихся четырех частей на две части и дальнейшее продолжение процесса дает последовательность $\lbrace1/2,1/4,3/4,1/8,3/8,\ldots \rbrace$. Аналогично, последовательность, построенная на простом числе 3 выглядит как $\lbrace1/3,2/3,1/9,2/9,4/9,\ldots \rbrace$. Последовательности Халтона, строящиеся на составном числе, порождают разбиения единичного отрезка, похожее на разбиение, порождаемое последовательностями Халтона для делителей данного составного числа.

Длина последовательности определяется количеством наблюдений $N$ и количеством симуляций $S$. Принято отбрасывать первые элементы (около 20), поскольку первые элементы коррелированны для последовательностей Халтона, порождаемых разными простыми числами (для примера см. Трейн, 2003). Следовательно, сначала необходимо построить последовательности Халтона длиной $N\times S+20$ и отбросить первые двадцать элементов каждой последовательности. Далее, для каждого элемента каждой последовательности нужно рассчитать обратную функцию  распределения. Итоговые значения являются выборкой Халтона из заданного распределения.

Среди главных преимуществ квази-случайных чисел следует отметить, что квази-случайные числа по построению более равномерно покрывают область значений по сравнению с псевдо-случайными числами. Это можно увидеть на Рисунке 12.1. На этом рисунке, график 2  показывает симуляции двумерного нормального распределения, построенные с использованием последовательности Халтона. Другие графики показывают симуляции псевдо-случайных чисел для такого же распределения. Можно увидеть, что более равномерный охват выборочного пространства достигается в  случае последовательности Халтона.

Для более подробного изучения, рассмотрения примеров симуляционного моделирования с использованием последовательностей Халтона, а также чтобы увидеть  эффективность данного  подхода для одномерного или многомерного случаев, см. Трейн (2003, Глава 9). Метод работает хорошо для мультиномиальной логит-модели с нормально-распределенными случайными параметрами (Раздел 15.7).

\section{Методы генерации случайных величин}

Для рассмотренных ранее симуляций необходимы были способы генерирования случайных величин. В этом разделе описываются методы, используемые для генерирования случайных величин с плотностью, обозначаемой через $g(x)$ или $p(x)$ в Разделе 12.7 и $f(x)$ в этом разделе. Как правило достаточно сгенерировать равномерные или стандартные нормальные случайные величины, поскольку с их помощью можно получить многие другие распределения.

\vspace{2cm}

График 12.1 Сэмплирование по Халтону (график 2) в сравнении с псевдо-случайной выборкой.


Если случайная выборка используются для построения оценки с помощью симуляционных методов, тогда все генерации равномерного или стандартного нормального распределения должны быть сделаны перед вычислением любой оценки для предотвращения <<дрожания>>, проявляющегося в том, что могут не сходиться итерационные методы из-за создания новых симуляции при каждой итерации. Например, если $x\sim \mathcal{N}[\mu,\sigma^2]$ и оценки $\mu$ и $\sigma$ меняются при каждой итерации, тогда сделаем $NS$ начальных симуляций $z\sim \mathcal{N}[0,1]$ и при итерациях пересчитываем значения $x$, $x=\mu+\sigma{z}$, используя исходные симуляции $z$.

В этом разделе мы кратко обсуждаем некоторые стандартные методов генерирования случайных величин. Более углубленное и расширенное рассмотрение представлено во многих монографиях и обзорах, в том числе в работах Брэдли, Фокса и Шрейджа (1983), Дагпунара (1988), Деврой (1986) и Рипли (1987).


Перед тем как перейти к рассмотрению методов, отметим, что термин генератор случайных чисел является оксюмороном. Более точное определение --- псевдо-случайные числа. Главной особенностью этих генераторов является то, что они используют детерминистические способы для создания длинных цепочек чисел, которые имитируют свойства случайной выборки из целевого распределения. Целевое распределение будет зависеть от конкретной ситуации, однако в соответствии с контекстом этой книги равномерное, нормальное, экспоненциальное, гамма, логистическое и пуассоновское распределения являются основными. Последовательность начинается со стартовой точки или зерна (seed). После генерации конечного, но достаточно большого количества значений цикл повторяется вновь. Это означает, что компьютерный алгоритм создаст такие же значения при таком же стартовом значении зерна. Хорошим генератором случайных чисел является тот, который позволяет создать длинную цепочку чисел без циклических повторений и какой-либо внутренней зависимости. Ключевым критерием выбора генераторов является близость свойств симулированного распределения с целевым распределением при умеренных вычислительных затратах.

\subsection{Генератор псевдослучайных равномерно-распределенных чисел}

Псевдо-случайные равномерно распределенные числа создаются при помощи детерминированной последовательности, которая имитирует статистические свойства последовательности равномерно распределенных случайных чисел. Хороший генератор имеет продолжительный период, распределение близкое к равномерному, а сами значения независимы. Важно иметь  хороший равномерный генератор, поскольку псевдо-случайные числа для практически любого распределения могут быть получены путем преобразования равномерно распределенных псевдо-случайных чисел  (Брэдли и др., 1983, стр. 24).

Стандартный генератор описывается уравнением

\[
X_j=(kX_{j-1}+c) \mod{m},
\]
где операция $a \mod b$ означает остаток от деления $a$ на $b$. Это дает последовательность целых чисел от $0$ до $m$, а равномерно распределенная случайная величина получается по формуле $R_j=X_j/m$ (Рипли, 1987,  стр. 20). Значение $X_0$ называется зерном, и необходимо для инициализации генератора.  Получаемая  последовательность является детерминистической, что позволяет её реплицировать, поскольку при одинаковом  значении зерна получаются одни и те же последовательности. Период цикла зависит от $X_0$, $k$ и $c$. Если расчеты производились на основе 32-разрядной целочисленной арифметики, тогда максимальная длина периода равна $2^{31} \simeq 2.1\times 10^9$. Тем не менее, легко можно выбрать неудачные  значения $X_0,k$ и $c$, при которых длина периода ниже чем $2^{31} \simeq 2.1\times 10^9$. Возможные проблемы обсуждаются в книге Пресс и др. (1993). 

\subsection{Неравномерные случайные величины}

Случайные величины, имеющие разное распределение, в том числе нормальное, как правило получены из симуляций равномерно распределенных случайных чисел. К основным методам относятся: (1) обратное преобразование, (2) преобразование, (3) метод принятия или отбрасывания (4) смешивание или комбинирование.

\begin{center}
Обратное преобразование
\end{center}

Обозначим через $F(x)$ функцию распределения непрерывной случайной величины $x$,

\[
F(x)=\Pr[X\leq x]
\]

При заданных значениях равномерно распределенной случайной величины $r$, $0 \leq r \leq 1$, обратное преобразование
\[
x=F^{-1}(r)
\]
дает единственное значение $x$ поскольку $F$ непрерывная и монотонно возрастающая.

Например, функция распределения показательного распределения с единичной интенсивностью равна $1-e^{-x}$. Решая $r=1-e^{-x}$ относительно $x$  получаем $x=-\ln{(1-r)}$. Если случайная выборка из равномерного распределения $[0,1]$ равна 0.64, тогда $x=-\ln{(1-0.64)}=1.0217$. На Рисунке 12.2 изображен график функции распределения $X$ и графически показано как работает метод обратного преобразования. Вначале случайным образом выбирается точка на вертикальной оси на уровне $r$, а затем --- соответствующее ей  значение на горизонтальной оси так.  

Применение этого метода не вызывает затруднений, если $F(\cdot)$ задана явно и $x$ является непрерывной случайной величиной. Даже если нет аналитической формы для $F(\cdot)$ метод иногда возможно применить, хотя количество расчетов при этом увеличивается, поскольку обратные к  стандартным функциям распределения часто реализованы в виде готовых функций в статистических пакетах.

\vspace{2cm}

График 12.2. Метод обратного преобразования для построения выборки из экспоненциального  распределения с единичной интенсивностью. Равномерная величина равная 0.64 (т.е. $F(x) = 1- \exp(-x) = 0.64$), и, следовательно, $x = 1.02$

Метод может применяться для дискретных случайных переменных с функцией распределения, заданной ступенчато. К примеру, если $x$ принимает целые значения, тогда значение $r=0.312$, взятое из равномерного распределения приводит к тому, что $x=j$, где $j$ выбирается так, что $F(j-1)<0.312$ и $F(j)\geq 0.312$.

Общепринятым методом генерации нормально распределенных случайных величин является метод Бокса-Мюллера. В методе Бокса-Мюллера используется способ обратного преобразования, который применяется для пары независимо и равномерно распределенных величин. А именно, если $r_1$ и $r_2$ независимо и равномерно распределены, тогда $x_1=\sqrt{-2\ln{r_1}}\cos(2\pi{r_2})$ и $x_2=\sqrt{-2ln{r_1}}\sin(2\pi{r_2})$ и имеют стандартное нормальное распределение и независимы, $\mathcal{N}(0,1)$.

\begin{center}
Преобразование
\end{center}

Иногда требуемую плотность распределения возможно получить при помощи некоторого преобразования. 

Метод преобразования является действенным способом генерирования распределений, построенных на основе нормального распределения. Среди примеров преобразований отметим возведение в квадрат стандартно нормально распределенной случайной величины для построения случайной величины с центральным хи-квадрат распределением, суммирование $r$ квадратов независимых стандартных нормально распределенных случайных величин, для получения хи-квадрат распределения с $r$ степенями свободы,  а также расчет среднего значения квадрата независимых хи-квадрат распределенных величин для построения случайных величин с $F$-распределением. Метод преобразования применяется не только для распределений связанных с нормальным. 

\begin{center}
Метод принятия-отбрасывания
\end{center}

Предположим, что необходимо сгенерировать величины с плотностью $f(x)$, и это достаточно трудно сделать, однако существует другая плотность $g(x)$, которая покрывает $f(x)$, т.е. выполняется неравенство $f(x)\leq kg(x)$ для всех значений $x$ для некоторой конечной константы $k$. Это отражено на Рисунке 12.3, где тонкая линия изображает огибающую $kg(x)$.

\vspace{2cm}



График 12.3. Метод принятия-отбрасывания генерирует значения с плотностью $g(x)$, где $kg(x)$ покрывает целевую функцию плотности $f(x)$
%Accept-reject method draws from density $g(x)$ where $kg(x)$ envelopes the desired density $f(x)$.

В основе метода принятия-отбрасывания используется плотность $g(x)$ вместо $f(x)$. Значение $x=r$ принимается, если

\[
r\leq \dfrac{f(x)}{kg(x)},
\]
где $r$, значение равномерно распределенной случайной величины. Если условие не выполняется, тогда значение не принимается и тогда необходимо делать новые симуляции до тех пор, пока условие не будет выполняться. Применение метода зависит от простоты получения значений с плотностью $g(x)$, а не с плотностью $f(x)$. В среднем исходное  значение будет принято с вероятностью $1/k$, при больших значениях $k$ необходимо будет сделать много симуляций. 

Для иллюстрации метода допустим, что $Y$ обозначает случайную величину, сгенерированную методом принятия-отбрасывания, $X$ задает случайную величину с плотностью $g(x)$ и $U$ обозначает равномерную случайную величину. Тогда $Y$ имеет функцию распределения

\[
\Pr[Y\leq y]=Pr[X\leq y|U\leq f(x)/kg(x)]
\]

\[
=\dfrac{\Pr[X\leq y, U\leq f(x)/kg(x)]}{\Pr[U\leq f(x)/kg(x)]}
\]

\[
=\dfrac{\int^{y}_{-\infty}\int^{f(x)/kg(x)}_{0}dug(x)dx}{\int^{\infty}_{-\infty}\int^{f(x)/kg(x)}_{0}dug(x)dx}
\]

\[
=\dfrac{\int^{y}_{-\infty}[f(x)/kg(x)]g(x)dx}{\int^{\infty}_{-\infty}[f(x)/kg(x)]g(x)dx}
\]

\[
=\dfrac{\int^{y}_{-\infty}[f(x)/k]dx}{\int^{\infty}_{-\infty}[f(x)/k]dx}
\]

\[
\int^{y}_{-\infty}f(x)dx,
\]
которая соответствует плотности $f(x)$, как и ожидалось.

\begin{center}
Составное распределение
\end{center}



Иногда плотность $f(x)$ может быть выражена через смесь распределений или составное распределение

\[
f(x)=\int{g(x|\e)h(\e)d\e}.
\]
Тогда значения $f(x)$ могут быть получены в два шага, сначала необходимо сгенирировать $\e$ из плотности $h(\e)$, а затем значения $x$ из условной плотности распределения $g(x|\e)$.

В качестве примера рассмотрим получение значений отрицательного биномиального распределения со средним $\lambda$ и дисперсией $\lambda(1+\alpha\lambda)$, где оба параметра, $\lambda$ и $\alpha$ заданные константы. Можно использовать тот факт, что отрицательное биномиальное распределение может быть рассмотрено как смесь распределений Пуассона и гамма (см. Главу 20). Вначале получим значения $\e$ из гамма-распределения со средним $I$ и дисперсией $\alpha$ через преобразование экспоненциального распределения. Далее рассчитываются значения $\lambda\e$ при известных, из предыдущего пункта, значениях $\e$.

Если $h(\e)$ дискретно заданная величина с вероятностями значений $p_j$ отличными от нуля в $C$ точках, $j=1,\ldots ,C$, тогда интегрирование заменяется суммированием. Таким образом,

\[
f(x)=\sum^{C}_{j=1}p_{j}g(x|\e=\e_{j}).
\]
При этом, для получения выборки размера $S$ с плотностью $f(x)$, сгенерируем $Sp_j$ значений из условной плотности $g(x|\e=\e_j)$ и построим выборку размером $S$ путем объединения выборок.

\begin{center}
Некоторые стандартные генераторы
\end{center}

Таблица в Приложении B описывает процесс генерации псевдо-случайных чисел для некоторых стандартных непрерывных и дискретных случаев. В основе лежит предположение, что $r,r_1,r_2,\ldots $ независимо равномерно распределенные случайные значения $R,R_1,R_2,\ldots $ с параметрами $[0,1]$. Следует отметить, что существуют другие методы создания случайных переменных, перечислим один или два из них.

\subsection{Многомерное распределение}

Получение значений многомерного распределения сложнее, чем одномерного. Например, методы обратного преобразования и преобразования могут быть неприменимы. Для многомерных распределений возможно использовать метод смеси и комбинирования распределений, поскольку среди многомерных распределений часто встречаются смеси распределений.

Среди общепринятых методов можно выделить алгоритм Гиббса и иные алгоритмы Монте-Карло по схеме марковской цепи. Эти методы будут рассмотрены позже в Разделе 13.5, поскольку они широко применимы при байесовском анализе, в котором используются сложные многомерные распределения. Как будет объяснено далее, при использовании алгоритма Гиббса может возникнуть корреляция между выборочными значениями, что может привести к понижению эффективности симуляционного моделирования.

Ограничимся рассмотрением многомерного нормального распределения. Значения могут быть получены путем преобразования значений, имеющих одномерное стандартное нормальное распределение. Предположим, что необходимо создать $q$-мерное нормальное распределение, так что $x\sim \mathcal{N}(0,\Sigma)$. Это возможно с помощью преобразования, использующего разложение Холецкого для  положительно определенная матрица $\Sigma$ 

\[
\Sigma=LL', 
\]
где $L$ нижнетреугольная матрица. Например, для $q=2$ разложение Холецкого можно представить как

\[
\begin{bmatrix} \sigma_{11} & \sigma_{12} \\ \sigma_{21} & \sigma_{22} \end{bmatrix} = 
\begin{bmatrix} l_{11} & 0 \\ l_{21} & l_{22} \end{bmatrix}
\begin{bmatrix} l_{11} & l_{21} \\ 0 & l_{22} \end{bmatrix},
\]
которое дает три уравнения $l^{2}_{11}=\sigma_{11},l_{11}l_{21}=\sigma_{12}$ и $l^{2}_{21}+l^{2}_{22}=\sigma_{22}$, в результатом решения получим значения $l_{11},l_{21}$ и $l_{22}$. Для заданного $q$-мерного вектора $\e$, элементы которого стандартно нормально распределены, легко проверить, что из $\e \sim \mathcal{N}(0,I)$ следует $x=L\e$, а линейная комбинация нормально распределенных величин имеет распределение с параметрами $\mathcal{N}(0,\sum)$. В частности, $\E[L\e]=0$ и $\V[L\e]=\E[L\e\e'L']=LL'=\sum$. В основе этого метода лежит свойство, что линейная комбинация нормально распределенных величин является нормально распределенной величиной. Это свойство не выполняется для величин, имеющих распределение отличное от нормального.

\section{Библиографические заметки}

Пресс и другие (1993) приводят хорошее введение в численное и Монте-Карло интегрирование и указывают дальнейшие ссылки, включая некоторые, которые есть в этой главе.

Литература по эконометрике, посвященная оцениванию с помощью симуляций, уделяет особое внимание пробит-модели. Однако методы имеют более широкое применение и могут быть легко и успешно применены в других моделях, которые легче оценить, чем  мультиномиальный пробит. Лерман и Мански (1981) использовали симуляционные частоты для оценивания вероятностей и выяснили, что необходима большая выборка. МакФадден (1989) ввел метод симуляционных моментов и показал, что этот метод является состоятельным и асимптотически нормальным. Пэйкс и Поллард (1989) привели довольно подробное описание асимптотической теории и для метода симуляционных моментов, и для симуляционного правдоподобия. Написанная доступным языком работа Стерна (1997) --- отличная отправная точка. Гурьеру и Монфорт (1996) приводят подробное описание основных методов. Другую литературу на данную тему хорошо изучать в контексте моделей, которые будут рассмотрены с последующих главах. В частности, Хаживассилиу и Рууд (1994) уделяют особое внимание усеченным моделям с нормальным распределением, включая мультиномиальный пробит. Трейн (2003) рассматривает модели дискретного выбора, включая логит со случайными параметрами. 


\begin{center}
Упражнения
\end{center}


\begin{enumerate}
\item [$12 --- 1$] Для оценки интеграла $I=\int{t(x)g(x)dx}$ методом Монте-Карло используется сумма $\hat{I}=N^{-1}\sum{t(x_i)g(x_i)/p(x_i)}$, где $x_i$ значения, сгенерированные с помощью сэмплирования по важности с плотностью $p(x)$. Покажите, что предел по вероятности $\plim \hat{I}=I$.

\item [$12 --- 2$]  Для $f(\theta)=|\sum|^{-1/2}[1+\dfrac{1}{\nu}(\theta-\mu)^{'}\sum^{-1}(\theta-\mu)]^{-(\nu+d)/2}$, рассмотрим интеграл размерности $d$ $\int_{R^{d}}f(\theta)d\theta$. Подынтегральная функция является основой многомерного $t$-распределения, таким образом правильным ответом является обратное к нормирующей постоянной. 
\begin{enumerate}
\item Оцените этот интеграл как среднее по методу Монте-Карло $S^{-1}\sum^{S}_{s=1}f(\theta^{(s)})/h(\theta^{(s)})$, $\theta^{(s)}\sim h(\theta)$, где плотность важности $h(\theta)$ является многомерным $t$-распределением с тем же центром и масштабирующим множителем как и функция $f(\theta)$, но отличается количеством степеней свободы.
\item Оцените стабильность полученного среднего меняя количество степеней свободы $h(\theta)$. Также оцените стабильность среднего увеличив несоответствие между $f(\theta)$ и $h(\theta)$, меняя центр и коэффициент масштаба $h(\theta)$.
\end{enumerate}

\item [$12 --- 3$] Для оценки метода симуляционных моментов, рассмотренной в Разделе 12.5.3 предположите, что вспомогательная оценка является частотной.
\begin{enumerate}
\item Покажите, что $\V_{y,u}[\hat{m}(\theta_0)]=(1+1/S)\V_{y}[m(\theta_0)]$.
\item Далее покажите, что  использования частотной вспомогательной оценки приводит к увеличению дисперсии оценки методом моментом в $(1+(1/S))$ раз.
\item Насколько будет высока потеря эффективности для стандартных ошибок, если $S=10$?
\end{enumerate}

\item [$12 --- 4$]  Обратимся к примеру, рассмотренному в Разделе 12.5.6, рассчитайте оценку $\hat{\alpha}$, которая является решением уравнения $\sum^{N}_{i=1}[y_i-\dfrac{1}{S}\sum^{S}_{s=1}(\alpha+u^{S}_i)]=0$. Получите аналитическое выражение для $\alpha$ оценки и ее дисперсии.

\item [$12 --- 5$] 
\begin{enumerate}
\item Напишите алгоритм для построения псевдо-случайной выборки из трехмерного  нормального распределения $\mathcal{N}[0,\sum]$ c $\sigma_{jj}=1, j=1,2.3$ и ковариациями $\sigma_{12}=\sigma_{13}=\sigma_{23}=0.5$. Постройте выборку из 1,000 реализаций и сравните  оценки среднего значения и дисперсий с теоретическими.
\item Повторите пункт (а), но вместо трехмерного нормального распределения используйте $t$-распределение Стьюдента с пятью степенями свободы.
\end{enumerate}

\item [$12 --- 6$] Напишите функцию для генерирования одномерного усеченного нормального распределения $\tau\mathcal{N}_{[a,b]}[\mu,\sigma^2]$ с применением метода обратного преобразования, рассмотренного в Разделе 12.8.2. Здесь $[a,b]$ нижняя и верхняя точки усечения. Используйте значения $\mu=1$, $\sigma^2=4$ и $a=3$, $b=4$.

\item [$12 --- 7$] Рассмотрим модель бинарной логит регрессии (см. Раздел 14.3).
\begin{enumerate}
\item Запишите логарифмическую функцию правдоподобия.
\item Предположим, что свободный член задан случайно и его значение получается из соответствующего распределения с конечным средним и дисперсией. Как вы можете обосновать  использование ненаблюдаемой гетерогенности в этом случае? Если логит-модель составлена на основе случайной  модели полезности с экстремальным распределением ошибок, как случайный характер свободного члена может повлиять на интерпретацию или расчет результатов? [см. Ревелт и Трейн, 1998.]
\item Предложите подходящее распределение для свободного члена; перепишите функцию правдоподобия с учетом ненаблюдаемой гетерогенности. Далее запишите условную функцию правдоподобия при фиксированной ненаблюдаемой гетерогенности.
\item Опишите пошагово процедуру оценивания модели с использованием симуляционного  правдоподобия. Детально объясните как рассчитать матрицу дисперсий неизвестных параметров. Как вы будете определять количество необходимых симуляций?
\item Рассмотрите возможность применения метода симуляционных моментов как альтернативу оценки симуляционного правдоподобия для логит-модели со случайными параметрами. Запишите условия для моментов при заданной ненаблюдаемой гетерогенности. Далее опишите процедуру расчета оценки симуляционных моментов для данной модели.
\end{enumerate}


\item [$12 --- 8$]
Некоторые статистические пакеты позволяют построить как пуассоновское, так и гамма- распределение псевдослучайных чисел. Также известно, что отрицательное биномиальное распределение можно построить как смесь значений пуассоновского и гамма-распределений (см. Раздел 20.4).
\begin{enumerate}
\item Запишите процедуру получения чисел, имеющих отрицательное биномиальное распределение методом смеси. 
\item Используйте выбранный вами метод для построения выборки, состоящей из 10,000 значений, которые имеют пуассоновское распределение со средним 0.25.
\item Постройте соответствующую выборку из гамма распределения со средним 1 и дисперсией $\alpha$, где $\alpha$ задана так, чтобы получить величины с отрицательным биномиальным распределением и дисперсией 0.3125.
\end{enumerate}
\end{enumerate}


