




\appendix

%%% ссылки: def:A1, th:A12 etc



\chapter{Асимптотическая теория}

\section{Введение}

В этом приложении мы рассмотрим поведение \textbf{последовательности случайных величин} $b_N$ при $N$, стремящемся к бесконечности.

В приложениях индекс $N$ --- это размер выборки, а последовательность $b_N$ --- это оценка, например, $\hat{\beta}$ или $\hat{\theta}$, или один из элементов оценки, например, $N^{-1}\sum_i x_i^2$ или $N^{-1}\sum_i x_i u_i$ в случае МНК с одной объясняющей переменной и без константы, или тестовая статистика.

Для теории оценивания существенно важными являются два аспекта поведения \textbf{последовательности} $b_N$ при $N\to \infty$. Во-первых, мы рассматриваем \textbf{сходимость по вероятности} последовательности $b_N$ к пределу $b$, константе или случайной величине, близкой к $b_N$ в вероятностном смысле, который мы уточним. 
Во-вторых, если предел $b$ --- это случайная величина, то мы изучаем \textbf{предельное распределение}, при этом может потребоваться масштабирование исходной последовательности.

Обычно оценки являются функциями от \textbf{средних арифметических} или \textbf{сумм}. В таком случае свойства оценки проще всего получить, используя результаты о среднем арифметическом, в частности, \textbf{закон больших чисел} и \textbf{центральные предельные теоремы}. Мы используем обозначение $\bar{X}_N=N^{-1}\sum_i X_i$, где $X_i$ --- это произвольные усредняемые случайные величины. Важно отличать это обозначение от обозначения $\mathbf{x}_i$, используемого для вектора объясняющей переменной. Например, для МНК с одним регрессором без константы мы будем применять закон больших чисел к среднему от величин $X_i=x_i^2$ и центральную предельную теорему к среднему от величин $X_i=x_i u_i$.

Таблица A.1. охватывает все определения и теоремы, упоминаемые в этом приложении. Они формулируются без доказательств, но с некоторыми комментариями. Основное внимание уделено асимптотически нормальным оценкам, которые возникают чаще всего при работе с пространственными данными. Дополнительные результаты нужны в случае непараметрического оценивания, параметрического оценивания, если множество возможных значений данных зависит от параметров, и для анализа временных рядов при наличии единичного корня. 

\begin{table}[h]
\caption{\label{tab:asydef} Асимптотическая теория: определения и теоремы}
\begin{tabular}{cclc}
\hline 
\hline
Определение & Теорема & Название & Уравнение \\ 
\hline 
A.1 &  & Сходимость по вероятности & (A.1) \\ 
A.2 &   & Состоятельность & (A.2) \\ 
 & A.3 & Теорема Слуцкого & (A.3) \\ 
A.4 &  & Сходимость в среднеквадратичном & (A.4) \\ 
 & A.5 & Неравенство Чебышева & (A.5) \\ 
A.6 &  & Сходимость почти наверное & (A.6) \\ 
A.7 &  & Закон больших чисел & (A.7) \\ 
 & A.8 & Усиленный закон больших чисел &  \\ 
 & A.9 & Закон больших чисел Маркова &  \\ 
A.10 &  & Сходимость по распределению & (A.9) \\ 
 & A.11 & Теорема о непрерывном отображении & (A.10) \\ 
  & A.12 & Теорема о преобразованиях &  (A.11) \\ 
A.13 &  & Центральная предельная теорема & (A.13)  \\ 
 & A.14 & ЦПТ Линберга-Леви & \\
 & A.15 & ЦПТ Ляпунова & \\
 & A.16 & Теорема Крамера-Вольда & \\
 & A.17 & Теорема о нормальности предела произведения & (A.15) \\
A.18 & & Асимптотическое распределение & (A.16) \\
A.19 & & Асимптотическая дисперсия & (A.17) \\
A.20 & & Оценка асимптотической дисперсии & (A.18) \\
A.21 & & Асимптотическая эффективность & (A.19) \\
A.22 & & Стохастический порядок малости & \\
\hline
\hline
\end{tabular} 
\end{table}

Первое ключевое понятие, сходимость по вероятности, представлено в разделе A.2. Законы больших чисел представлены в разделе A.3. Другое ключевое понятие, сходимость по распределению, обсуждается в разделе A.4. Сходимость к нормальному распределению с использованием центральных предельных теорем представлена в разделе A.5. Дальнейшие результаты и терминология для предельных многомерных нормальных распределений представлены в разделе A.6. Стохастический порядок малости, часто используемое обозначение в асимптотической теории, представлен в разделе A.7. В разделе A.8. представлены некоторые полезные свойства математического ожидания.


\section{Сходимость по вероятности}

С силу случайности выборки даже при бесконечном её размере мы никогда не можем быть уверены, что последовательность $b_N$ окажется ближе небольшого наперёд заданного расстояния от своего предела. В роли последовательности $b_N$ часто выступает последовательность оценок $\hat{\theta}$, зачастую чтобы подчеркнуть, что это не одна оценка, а именно последовательность, используют обозначение $\hat{\theta}_N$. Однако мы можем быть почти уверены. Разные точные формулировки этой почти уверенности соответствуют разным типам сходимости последовательности случайных величин. Один из наиболее часто используемых типов --- это сходимость по вероятности.

\subsection{Сходимость по вероятности}

Напомним, что неслучайная последовательность действительных чисел $\{a_N\}$ сходится к числу $a$, если для любого $\e>0$ существует число $N^*=N^*(\e)$, такое что, для всех $N>N^*$ выполнено условие
\[
|a_N-a|<\e
\]
Например, если $a_N=2+3/N$, то предел последовательности равен $a=2$ так как $|a_N-a|=|2+3/N-2|=|3/N|<\e$ для всех $N>N^*=3/\e$.

Когда мы имеем последовательность случайных величин, мы не можем быть уверены в том, что оказались на расстоянии ближе чем на $\e$ от предела в силу случайности. Вместо это мы требуем, чтобы вероятность оказаться на расстоянии ближе чем на $\e$ от предела была сколь угодно близка к единице. Таким образом мы требуем, чтобы для любого $\e > 0$
\[
\lim_{N\to\infty} \P[|b_N-b|<\e]=1
\]

\begin{definition}[Сходимость по вероятности] Последовательность случайных величин $\{b_N\}$ \textbf{сходится по вероятности} к числу $b$, если для любого $\e>0$ и $\delta>0$, существует $N^*=N^*(\e,\delta)$, такое что для любых $N>N^*$ выполнено условие
\label{def:A1}
\begin{equation}
\P[|b_N-b|<\e]>1-\delta
\end{equation}
\end{definition}

Мы используем обозначение $\plim b_N=b$, где \verb|plim| расшифровывается как \textbf{probability limit}, т.е. предел по вероятности, также используется обозначение $b_N \overset{p}{\to}b$.

Заметим, что величина $b$ может быть константой или случайной величиной. Сходимость действительных чисел является частным случаем сходимости по вероятности.

Определение \ref{def:A1} подходит для последовательностей скалярных случайных величин. Обобщение на случай \textbf{векторных случайных величин}, таких как векторных оценок параметров, является несложным. Мы можем либо применить определение к каждому элементу вектора $\mathbf{b}_N$, либо заменить выражение $|b_N-b|$ скаляром $(\mathbf{b}_N-\mathbf{b})'(\mathbf{b}_N-\mathbf{b})=(b_{1N}-b_1)^2+\ldots+(b_{KN}-b_K)^2$ или его квадратным корнем $||\mathbf{b}_N-\mathbf{b}||$. 

Когда последовательность $\{\mathbf{b}_N\}$ является последовательностью оценок параметра $\hat{\mathbf{\theta}}$, имеется следующий аналог несмещённости для большого размера выборки.

\begin{definition}[Состоятельность]
Оценка $\hat{\mathbf{\theta}}$ является \textbf{состоятельной} оценкой для параметра $\mathbf{\theta}_0$ если 
\begin{equation}
\plim \hat{\mathbf{\theta}} = \mathbf{\theta}_0
\end{equation}
\end{definition}

Индекс 0 у $\mathbf{\theta}$ объясняется в разделе 5.2.3. Заметим, что из несмещённости не следует состоятельность. Несмещённость означает только, что ожидаемое значение $\hat{\mathbf{\theta}}$ равно $\mathbf{\theta}_0$, и допускает разброс вокруг $\mathbf{\theta}_0$, который необязательно исчезает, когда размер выборки стремится к бесконечности. Также состоятельная оценка не обязана быть несмещённой. Например, прибавление $1/N$ к несмещённой и состоятельной оценке превратит её в смещённую, но состоятельную.

Хотя последовательность вектора случайных величин $\{\mathbf{b}_N\}$ может сходится к случайному вектору $\mathbf{b}$, во многих эконометрических приложениях $\{\mathbf{b}_N\}$ сходится к вектору констант. Например, мы хотели бы, чтобы оценка неизвестного параметра, сходилась бы к самому параметру. Стоит обратить внимание, что некоторые из следующих результатов верны, только если предельное значение $\mathbf{b}$ является константой.

\begin{theorem}[Теорема Слуцкого]
\label{th:A3}
Пусть $\mathbf{b}_N$ --- конечномерный вектор случайных величин и $g(\cdot)$ --- действительная функция, непрерывная в точке $\mathbf{b}$. Тогда
\begin{equation}
\mathbf{b}_N\overset{p}{\to}\mathbf{b} \Rightarrow g(\mathbf{b}_N)\overset{p}{\to}g(\mathbf{b})
\end{equation}
\end{theorem}


Доказательство приводится в работе Амэмии (1985, стр. 79). Рууд (2000) формулирует похожую теорему (см. также Рао, 1973, стр. 124), в которой предел $\mathbf{b}$ может быть случайной величиной, при этом функция $g(\cdot)$ должна быть везде непрерывной. Заметим, что некоторые авторы называют теоремой Слуцкого теорему \ref{th:A12} ниже.

Теорема \ref{th:A3}  --- это одна из главный причин, по которой большинство результатов в эконометрике формулируются асимптотически, а не для конечных выборок. Утверждение теоремы является очень удобным свойством, которое не является верным для математических ожиданий. Например, из равенства $\plim$ $(b_{1N},b_{2N})=(b_1,b_2)$ следует, что $\plim$ $(b_{1N}b_{2N})=b_1b_2$, в то время как в общем случае $\E[b_{1N}b_{2N}]$ не равно $\E[b_{1}]\E[b_{2}]$.



\subsection{Другие виды сходимости}

Часто бывает легко определить наличие другого вида сходимости, из которой будет следовать сходимость по вероятности. Эти виды сходимости приведены для полноты изложения. Законы больших чисел, изложенные в следующем разделе, используются гораздо чаще.

\begin{definition}[Сходимость в среднем квадратичном] Последовательность случайных величин $\{b_N\}$  \textbf{сходится в среднем квадратичном} к случайной величине $b$, если 
\begin{equation}
\lim_{N\to\infty} \E[(b_N-b)^2] = 0
\end{equation}
\end{definition}

Мы используем обозначение $b_N \overset{m}{\to}b$. Сходимость в среднем квадратичном полезна тем, что из $b_N\overset{m}{\to} b$ следует сходимость по вероятности $b_N\overset{p}{\to}b$ (см. Рао, 1973, стр. 110), кроме того, её обычно легче доказать. При этом требуется существование дисперсии величин $b_N$. Если $\E[b_N]=b$, тогда остается только доказать, что дисперсия $b_N$ стремится к нулю при $N\to\infty$. Если величины $b_N$ являются смещенными оценками для $b$, тогда мы требуем, чтобы сумма дисперсии и возведенного в квадрат смещения стремилась к нулю.

Другой результат, используемый при доказательстве сходимости по вероятности, --- это неравенство Чебышева.

\begin{theorem}[Неравенство Чебышева]
\label{th:A5}
Для любой случайной величины $Z$ со средним $\mu$ и с дисперсией $\sigma^2$, для любого $k > 0$,
\begin{equation}
\P[(Z-\mu)^2>k]\leq \sigma^2/k
\end{equation}
\end{theorem}

Доказательство можно найти в Рао (1973, стр. 95). В обобщенном неравенстве Чебышева величина $(Z-\mu)^2$ из теоремы \ref{th:A5} заменена на произвольную неотрицательную функцию $g(Z)$, и оно приобретает вид $\P[g(Z)>k]\leq \E[g(Z)]/k$ для любых $k>0$, см. работу Амэмии (1985, стр. 87).

Теорема \ref{th:A5} может быть использована для доказательства сходимости по вероятности, при этом $Z$ заменяется на $b_N$. Для  теоремы требуются математическое ожидание и дисперсия $b_N$, которые легко можно получить для оценок, рассчитываемых с помощью среднего арифметического независимых случайных величин. Впрочем, в этом случае можно воспользоваться более простым способом --- напрямую применить закон больших чисел к среднему и получить предел по вероятности.

Концептуально более сложное понятие сходимости --- сходимость почти наверное.

\begin{definition}[Сходимость почти наверное] Последовательность случайных величин $\{b_N\}$ \textbf{сходится почти наверное } к $b$, если
\begin{equation}
\P[\lim_{N\to\infty} b_N = b] = 1
\end{equation}
\end{definition}
Сходимость почти наверное обозначается $b_N \overset{as}{\to} b$. Из сходимости почти наверное следует сходимость по вероятности (см. Рао, 1973, стр. 111). Сходимость по вероятности допускает более вольное поведение $b_N$, чем сходимость почти наверное.

Сходимость почти наверное также называется \textbf{сильной состоятельностью} в отличие от сходимости по вероятности, называемой \textbf{слабой состоятельностью}. Сходимость по вероятности легче для понимания и достаточна для большинства эконометрических приложений.



\section{Законы больших чисел}

Законы больших чисел --- это теоремы о сходимости по вероятности или о сходимости почти наверное для частного случая, когда последовательность оценок $\{b_N\}$ является последовательностью выборочных средних, т.е. $b_N=\bar{X}_N$, где

\begin{equation}
\label{eq:A7}
\bar{X}_N=\frac{1}{N}\sum_{i=1}^N X_i
\end{equation}

Здесь $X_i$ обозначает произвольную случайную величину, это обозначение может использоваться не только для регрессора.

С помощью закона больших чисел легче доказывать сходимость по вероятности, чем используя $(\delta,\e)$-язык определения \ref{def:A1} или чем используя другие виды сходимости.

\begin{definition}[Закон больших чисел]  \textbf{Слабый закон больших чисел} (ЗБЧ) накладывает условия на отдельные величины $X_i$ в выражении $\bar{X}_N$, при которых
\begin{equation}
\label{eq:A8}
(\bar{X}_N - \E[X_N]) \overset{p}{\to} 0
\end{equation}
\textbf{Усиленный закон больших чисел} подразумевает сходимость почти наверное.
\end{definition}

Бывает полезно представлять, что ЗБЧ означает сходимость $\bar{X}_N$ к своему математическому ожиданию. Строго говоря, ЗБЧ означает лишь более слабое условие, что $\bar{X}_N$ сходится к \textit{предельному значению своего математического ожидания}, т.к. из \ref{eq:A8}  следует, что

\[
\plim \bar{X}_N = \lim \E[\bar{X}_N]
\]

Если у $X_i$ одинаковое математическое ожидание $\mu$, то ЗБЧ означает, что $\plim \bar{X}_N = \mu$.

Две наиболее популярные формулировки закона больших чисел таковы:

\begin{theorem}[ЗБЧ Колмогорова] 
\label{th:A8}
Пусть $\{X_i\}$ независимы и одинаково распределены. Если $\E[X_i]=\mu$ и $\E[|X_i|]<\infty$, то $(\bar{X}_N - \E[X_N]) \overset{as}{\to} 0$.
\end{theorem}

\begin{theorem}[ЗБЧ Маркова] 
\label{th:A9}
Пусть $\{X_i\}$ независимы и необязательно одинаково распределены с $\E[X_i]=\mu_i$  и $V[X_i]=\sigma^2_i$. Если для некоторого $\delta>0$ выполнено условие $\sum_{i=1}^{\infty} (\E[|X_i-\mu_i|^{1+\delta}]/i^{1+\delta}) < \infty$, то $(\bar{X}_N - \E[X_N]) \overset{as}{\to} 0$.
\end{theorem}

Формулировку данных теорем можно найти в книге Уайта (2001a, стр. 32 и стр. 35), доказательство --- в работе Рао (1973, стр. 114-116). Оба закона относятся к сходимости почти наверное, из которой следует сходимость по вероятности. Рао (1973) называет теорему \ref{th:A8} вторым ЗБЧ Колмогорова и приводит теорему \ref{th:A9} для частного случая $\delta=1$, называя её первым ЗБЧ Колмогорова.

ЗБЧ Колмогорова допускает даже бесконечную дисперсию $X_i$ за счёт требования одинаковой распределённости. Заключение теоремы, поэтому, можно упростить до $\bar{X}_N \overset{as}{\to} \mu$, где $\mu=E[X]$. Существует слабая версия этого закона, называемая теоремой Хинчина, утверждающая, что для последовательности независимых одинаково распределённых $\{X_i\}$, у которых существует $\E[X]$, средние $\bar{X}_N$ сходятся по вероятности. Формулировки Хинчина достаточно для большинства эконометрических приложений.

ЗБЧ Маркова не требует одинаковой распределённости, но требует существования момента с порядком выше первого. Естественный выбор $\delta$ --- это $\delta=1$. В этом случае требуется существование дисперсии и дополнительное условие $\sum_{i=1}^{\infty} (\sigma^2_i/i^2) < \infty$. Дисперсии могут меняться и даже расти с $i$ при условии, что они растут не слишком быстро, т.е. сумма $\sum_{i=1}^{\infty} (\sigma^2_i/i^2)$ остаётся конечной. Например, дополнительное условие выполнено, если $\sigma^2_i=\sigma^2$, т.к. $\sum_{i=1}^{\infty} 1/i^2$ сходится, и не выполнено, если $\sigma^2_i=i\sigma^2$, т.к. $\sum_{i=1}^{\infty} 1/i$ расходится.

Во многих микроэконометрических задачах, включая регрессии со \textit{стратифицированной выборкой} или с \textit{фиксированными регрессорами}, нужна более сложная версия ЗБЧ --- версия Маркова.

ЗБЧ удобны тем, что накладывают условия на отдельные величины $X_i$, а не на последовательность средних $\bar{X}_N$. Именно с помощью ЗБЧ эконометристы чаще всего доказывают сходимость по вероятности. Связано это с тем, что большинство оценок и тестовых статистик являются функциями от средних арифметических исходных данных или ненаблюдаемых величин.

\section{Сходимость по распределению}

При $N\to\infty$ распределение состоятельной оценки $\hat{\theta}$ становится \textit{вырожденным} и сосредотачивается в точке $\theta_0$. Чтобы получить \textit{невырожденное} распределение при $N\to\infty$ необходимо \textit{отмасштабировать} оценку $\hat{\theta}$. Часто в качестве масштабирующего множителя подходит $\sqrt{N}$, в этом случае мы рассматриваем последовательность случайных величин $b_N=\sqrt{N}(\hat{\theta}-\theta_0)$.

В общем случаем $N$-ая случайная величина в последовательности $b_N$ имеет чрезвычайно сложную функцию распределения $F_N$. Как и любая последовательность функций, последовательность $F_N$ функций распределения может сходится к предельной функции. Здесь подразумевается сходимость в естественном смысле.

\begin{definition}[Сходимость по распределению] 
\label{def:A10}
Последовательность случайных величин $\{b_N\}$ \textbf{сходится по распределению} к случайной величине $b$ если
\begin{equation}
\label{eq:A9}
\lim_{N\to\infty} F_N = F
\end{equation}
в точках непрерывности функции $F$. Здесь $F_N$ --- функция распределения величины $b_N$, $F$ --- функция распределения величины $b$, сходимость --- поточечная.
\end{definition}

Мы используем обозначение $\b_N \overset{d}{\to}b$, а функцию $F$ мы называем \textbf{предельным распределением} последовательности $\{b_N\}$.

Из сходимости по вероятности следует сходимость по распределению, т.е. из $\b_N \overset{p}{\to}b$ следует $\b_N \overset{d}{\to}b$ (см. Рао, 1973, стр. 122).

В общем случае обратное неверно. Например, пусть $b_N=X_N$, $N$-ая копия независимых и одинаково распределённых величин $X \sim \mathcal{N}[\mu,\sigma^2]$. В этом случаем $\b_N \overset{d}{\to}b\sim \mathcal{N}[\mu,\sigma^2]$, но дисперсия $(b_N-b)$ не уменьшается с $N\to \infty$, а значит $b_N$ не сходится по вероятности к $b$.

В частном случаем, когда $b$ --- константа, тем не менее, из $\b_N \overset{d}{\to}b$ следует $\b_N \overset{p}{\to}b$ (см. Рао, 1973, стр. 120). В этом случае предельное распределение является вырожденным, сосредоточенным в точке $b$.

Чтобы обобщить предельное распределение на случай \textbf{векторных случайных величин}, просто определим $F_N$ и $F$ соответственно как функции распределения векторов $\mathbf{b}_N$ и $\mathbf{b}$.

\begin{theorem}[Теорема о непрерывном отображении]
\label{th:A11}
Пусть $\mathbf{b}_N$ --- последовательность конечномерных векторных случайных величин и $g(\cdot)$ --- непрерывная вещественная функция. Тогда
\begin{equation}
\mathbf{b}_N \overset{d}{\to} \mathbf{b} \Rightarrow g(\mathbf{b}_N) \overset{d}{\to} g(\mathbf{b})
\end{equation}
\end{theorem}

Доказательство можно найти в Рао (1973, стр. 124). Теорема \ref{th:A11} --- это аналог теоремы \ref{th:A3} для случая сходимости по распределению.

Следующая теорема описывает последствия умножения, сложения и деления последовательности с пределом по распределению на последовательность, сходящуюся по вероятности к константе.

\begin{theorem}[Теорема о преобразованиях]
\label{th:A12}
Если $a_N \overset{d}{\to} a$ и $b_N \overset{p}{\to} b$, где $a$ --- случайная величина, а $b$ --- константа, то

\begin{enumerate}
\item $a_N+b_N \overset{d}{\to} a+ b$ 
\item $a_Nb_N \overset{d}{\to} a b$ 
\item $a_N/b_N \overset{d}{\to} a/ b$ если $\P[b=0]=0$
\end{enumerate}
\end{theorem}

Доказательство можно найти в Рао (1973, стр. 122). Теорему \ref{th:A12} также называют \textit{теоремой Крамера}. Она также называется теоремой Слуцкого. Мы называем теоремой Слуцкого теорему \ref{th:A3}.

Теорема \ref{th:A12} очень полезна тем, что позволяет найти отдельно предельное распределение последовательности $a_N$ и предел по вероятности последовательности $b_N$, вместо того, чтобы исследовать совместное поведение пары $a_N$ и $b_N$. Из-за своей важности результат с умножением последовательностей даже имеет специальное название \textit{правило произведения}.

\section{Центральная предельная теорема}

Центральные предельные теоремы --- это теоремы \textit{о сходимости по распределению} для последовательности $\{b_N\}$  \textit{выборочных средних}. Центральная предельная теорема --- это простой способ получить предельное распределение последовательности $\{b_N\}$, гораздо более простой, чем прямое использование формулы \ref{eq:A9}.

Из ЗБЧ следует, что выборочное среднее сходится к константе $\lim \E[\bar{X}_N]$, т.е. к вырожденному распределению. Поэтому мы отмасштабируем величину $(\bar{X}_N-\E[\bar{X}_N])$ на её стандартное отклонение, чтобы построить величину с единичной дисперсией, которая могла бы сходиться к невырожденному распределению.

\begin{theorem}[Центральная предельная теорема]
Пусть 
\begin{equation}
Z_N=\frac{\bar{X}_N-\E[\bar{X}_N]}{\sqrt{\V[\bar{X}_N]}}
\end{equation}
где $\bar{X}_N$ --- выборочное среднее. \textbf{Центральная предельная теорема} (ЦПТ) формулирует условия на отдельные слагаемые $X_i$ в $\bar{X}_N$ при которых
\begin{equation}
Z_N \overset{d}{\to} \mathcal{N} [0,1]
\end{equation}
т.е. при которых $Z_N$ сходится по распределению к стандартному нормальному.
\end{theorem}

По построению у величины $Z_N$ ожидание равно $0$, а дисперсия равна $1$, поэтому остаётся доказать только нормальность. Формальные доказательства ЦПТ используют характеристическую функцию, обобщение производящей функции моментов $Z_N$. При этом доказывается что с $N\to \infty$ производящие функции сходятся к производящей функции для стандартной нормальной случайной величины.

Заметим, что если $\bar{X}_N$ удовлетворяет условиям ЦПТ, то и $h(N)\bar{X}_N$ также удовлетворяет условиям ЦПТ, например, для $h(N)=\sqrt{N}$, так как

\[
Z_N=\frac{h(N)\bar{X}_N-\E[h(N)\bar{X}_N]}{\sqrt{\V[h(N)\bar{X}_N]}}
\]

Во многих приложениях удобно применять центральную предельную теорему к нормализованным $\sqrt{N}\bar{X}_N=N^{-1/2}\sum_{i=1}^{N} X_i$, т.к. $\V[\sqrt{N}\bar{X}_N]$ конечна.

Примеры центральных теорем включают следующие:

\begin{theorem}[ЦПТ Линдеберга-Леви]
\label{th:A14}
Если величины $\{X_i\}$ независимы и одинаково распределены с $\E[X_i]=\mu$ и $\V[X_i]=\sigma^2$, то $Z_N \overset{d}{\to} \mathcal{N}[0,1]$.
\end{theorem}

Доказательство можно найти в Рао (1973, стр. 127).

Эту версию ЦПТ можно найти в большинстве вводных учебников по статистике и она полезна в случае независимых и одинаково распределённых слагаемых. В этом случае выражение для $Z_N$ можно упростить до
\[
Z_N=\frac{\bar{X}_N-\mu}{\sigma/\sqrt{N}}.
\]

Заметим, что в случае независимых и одинаково распределённых случайных величин существования $\mu$ достаточно, чтобы $\bar{X}_N \overset{p}{\to} \mu$, однако чтобы получить предельное нормальное распределение, требуется дополнительная предпосылка о существовании $\sigma^2$.

В таких приложениях как, например, МНК с фиксированными регрессорами, предпосылка о независимости и одинаковой распределённости не подходит. В этом случае можно применить ЦПТ к независимым и неодинаково распределённым $\{X_i\}$, при этом требуются дополнительные предпосылки.

\begin{theorem}[ЦПТ Ляпунова]
\label{th:A15}
Пусть $\{X_i\}$ независимы с $\E[X_i]=\mu_i$ и $\V[X_i]=\sigma^2_i$. Если для некоторого $\delta>0$ выполнено условие 
\[
\lim_{N\to\infty} \frac{\sum_{i=1}^N \E[|X_i-\mu_i|^{2+\delta}]}{\left( \sum_{i=1}^N \sigma_i^2 \right)^{(2+\delta)/2}} = 0
\]
то $Z_N \overset{d}{\to} \mathcal{N}[0,1]$.
\end{theorem}

Данный вариант ЦПТ Ляпунова доказан в работе Уайта (2001a, стр. 119). Рао (1973, стр. 128) рассматривает частный случай $\delta=1$.

Основным дополнительным требованием ЦПТ Ляпунова является существование абсолютного момента порядка большего, чем два. Следует отметить также и другие дополнительные предположения по сравнению со случаем одинаково распределённых случайных величин. Для неодинаково распределённых $X_i$ 

\[
Z_N=\frac{\sum_{i=1}^N X_i - \sum_{i=1}^N \mu_i}{\sqrt{\sum_{i=1}^N \sigma^2_i}}
\]

Теоремы \ref{th:A14} и \ref{th:A15} являются частными случаями более общей ЦПТ Линдеберга-Феллера (см. Рао, 1973, стр. 128). У ЦПТ Линдеберга-Феллера есть дополнительная предпосылка, которую трудно проверять.

В большинстве микроэконометрических приложений таких, как \textit{стратифицированные выборки} или \textit{фиксированные регрессоры}, используется более сложная версия ЦПТ --- версия Ляпунова.

\section{Многомерное нормальное предельное распределение}

В этом разделе мы сосредоточимся на распространённых в микроэконометрике оценках с многомерным нормальным предельным распределением.

\subsection{Многомерное нормальное предельное распределение}

Рассмотрённые ранее ЦПТ относились к скалярным последовательностям случайных величин. Они могут быть обобщены на случай векторных случайных величин с помощью следующего утверждения:

\begin{theorem}[Теорема Крамера-Вольда]
Пусть $\{\mathbf{b}_N\}$ --- последовательность случайных векторов размера $k\times 1$. Если последовательность $\mathbf{\lambda}'\mathbf{b}_N$ сходится к нормальному распределению для любого вектора констант $\mathbf{\lambda}$ размера $k\times 1$, то последовательность $\mathbf{b}_N$ сходится к многомерному нормальному распределению.
\end{theorem}

Рао (1973, стр. 128) приводит более общий результат, неограниченный нормальным распределением.

Достоинство данного результата в том, что если $\mathbf{b}_N$ --- это вектор средних арифметических, то $\mathbf{\lambda}'\mathbf{b}_N=\lambda_1 b_{1N}+\ldots + \lambda_k b_{kN}$ будет скаляром и к нему будет применима скалярная ЦПТ из предыдущего раздела. Это приведёт к тому, что

\[
\frac{\mathbf{\lambda}'\mathbf{b}_N-\mathbf{\lambda}'\mathbf{\mu}_N}
{\sqrt{\mathbf{\lambda}'\mathbf{\V}_N \mathbf{\lambda}}} \overset{d}{\to} \mathcal{N}[0,1],
\]
где $\mathbf{\mu}_N=\E[\mathbf{b}_N]$ и $\mathbf{\V}_N=\V[\mathbf{b}_N]$. В этом случае мы получаем, что

\begin{equation}
\label{eq:A14}
\mathbf{\V}^{-1/2}(\mathbf{b}_N-\mathbf{\mu}_N)\overset{d}{\to}
\mathcal{N}[\mathbf{0},\mathbf{I}].	
\end{equation}

Этот результат объясняется дальше в подразделе A.6.3.

\subsection{Линейное преобразование}

Микроэконометрические оценки часто могут быть представлены в виде $\sqrt{N}(\hat{\mathbf{\theta}}_N-\mathbf{\theta}_0)=\mathbf{H}_N\mathbf{a}_N$, где $\plim \mathbf{H}_N$ существует и $\mathbf{a}_N$ имеет предельное нормальное распределение. Распределение этого произведения, или линейного преобразования для $\mathbf{a}_N$, может быть получено с помощью части два теоремы \ref{th:A12} (теоремы о преобразовании). Мы переформулируем это утверждение в том виде, в котором оно часто встречается:

\begin{theorem}[Теорема о нормальности предела произведения]
\label{th:A17}
Если вектор $\mathbf{a}_N \overset{d}{\to} \mathcal{N}[\mathbf{\mu},\mathbf{A}]$ и матрица $\mathbf{H}_N\overset{p}{\to} \mathbf{H}$, где $\mathbf{H}$ положительно определена, то
\begin{equation}
\label{eq:A15}
\mathbf{H}_N\mathbf{a}_N \overset{d}{\to} \mathcal{N}
[\mathbf{H}\mathbf{\mu},\mathbf{H}\mathbf{A}\mathbf{H}'].
\end{equation}
\end{theorem}

Теорема \ref{th:A17} может быть непосредственно применена к оценке. Например, МНК оценка

\[
\sqrt{N}(\hat{\mathbf{\beta}}-\mathbf{\beta}_0)=
\left(
\frac{1}{N}\mathbf{X}'\mathbf{X}
\right)^{-1}
\frac{1}{\sqrt{N}}\mathbf{X}'\mathbf{u}
\]
рассматривается как произведение $\mathbf{H}_N=(N^{-1}\mathbf{X}'\mathbf{X})^{-1}$ и $\mathbf{a}_N=N^{-1/2}\mathbf{X}'\mathbf{u}$. Поэтому мы ищем предел по вероятности для $\mathbf{H}_N$ и предельное распределение $\mathbf{a}_N$.

Теорема \ref{th:A17} может быть использована для оправдания \textit{замены} ковариационной матрицы предельного распределения на состоятельную оценку без замены предельного распределения. Если мы доказали, что 

\[
\sqrt{N}(\hat{\mathbf{\theta}}-\mathbf{\theta}_0) \overset{d}{\to}
\mathcal{N}[\mathbf{0},\mathbf{B}],
\]
то из теоремы \ref{th:A17} следует, что
\[
\mathbf{B}_N^{-1/2}\sqrt{N}(\hat{\mathbf{\theta}}-\mathbf{\theta}_0) \overset{d}{\to}
\mathcal{N}[\mathbf{0},\mathbf{I}]
\]
для любой положительно определенной состоятельной оценки $\mathbf{B}_N$ матрицы $\mathbf{B}$.


\subsection{Предельная ковариационная матрица} % (fold)

Собственно ЦПТ позволяет сформулировать довольно запутанный результат \ref{eq:A14}. Домножив на $\bV_N^{1/2}$ и применив теорему \ref{th:A17}, мы получим более удобную формулировку:

\[
\bb_N-\bmu_N \dto \cN[\mathbf{0},\bV],
\]
где $\bV=\plim \bV_N$ и мы предполагаем, что $\bb_N$ и $\bV_N$ правильным образом отмасштабированы, т.е. $\bV$ существует и положительно определена.

Разные авторы по-разному определяют \textbf{предельную ковариационную матрицу} $\bV$. 

Общее определение --- просто

\[
\bV = \plim \bV_N.
\]

Это наиболее общий способ представить данный результат, именно в этом виде он используется в данной книге. В случае фиксированных регрессоров результат упрощается до $\bV = \lim \bV_N$.

В микроэконометрических приложениях матрица $\bV_N$ часто оказывается средним арифметическим некоторых матриц, скажем,

\[
\bV_N=\frac{1}{N}\sum_{i=1}^{N} \bS_i,
\]
где $\bS_i$ --- это квадратные матрицы, зависящие от параметров и данных, относящихся к $i$-му наблюдению. При независимости по $i$, как правило, можно применить закон больших чисел и получить, что $\bV_N-\E[\bV_N]\pto 0$. Тогда оказывается, что

\[
\bV = \lim \E[\bV_N] = \lim \frac{1}{N} \sumton \E[\bS_i].
\]

Выражения такого вида использует Амэмия (1985).

Если $\bS_i$ независимы и одинаково распределены, то $\E[\bS_i]=\E[\bS]$ одинаково для всех наблюдений. Поэтому простая случайная выборка приводит к простому выражению 

\[
\bV = \E[\bS],
\]
этим видом, например, пользуются Ньюи и МакФадден (1994) и Вулдридж (2002).

Например, рассмотрим оценку МНК с гомоскедастичной ошибкой. Здесь $\sqrt{N}(\mathbf{\hat{\beta}}-\mathbf{\beta}_0) \dto \cN [\mathbf{0},\sigma^2 \mathbf{M}^{-1}_{\mathbf{XX}}]$. Матрицу $\mxx=\plim N^{-1} \sum_i \mathbf{x}_i\mathbf{x}_i'$ можно представить в виде $\mxx = \lim N^{-1} \sum_i \E[\mathbf{x}_i\mathbf{x}_i']$, если применим закон больших чисел, а $\mxx=\E[\bx\bx']$ при простой случайной выборке.

Матрица $\bV$ может принимать сложные формы, например, она может принять сэндвич форму $\bA\bB\bA'$. Тогда указанные идеи применяются к каждой компоненте. Например, $\bB = \plim \bB_N$ может быть представлен в виде $\bB = \lim \E[\bB_N]$ или в виде $\bB=\E[\bS]$ при случайной выборке, если $\bB=N^{-1}\sum_i \bS_i$.

\subsection{Асимптотическое распределение и дисперсия}

При выводе предельного распределения оценки мы работаем с последовательностью $\b_N=\sqrt{N}(\hat{\theta}-\theta_0)$, чтобы обеспечить ненулевую дисперсию $b_N$ при $N\to\infty$. Если предельное распределение $b_N$ оказывается нормальным, то многие авторы говорят, что оценка $b_N$ асимптотически нормальна, и называют предел ковариационной матрицы \textbf{асимптотической ковариационной матрицей} $b_N$.

Иногда бывает удобно выразить результат в терминах распределения и ковариационной матрицы самой оценки $\hat{\mathbf{\theta}}$.

\begin{definition}[Асимптотическое распределение $\hat{\btheta}$]
\label{def:A18}
Если 
\begin{equation}
\label{eq:A16}
\sqrt{N}(\hat{\btheta}-\btheta_0)\dto \cN[\mathbf{0},\bB],	
\end{equation}
то мы говорим, что \textit{при большой выборке} оценка $\hat{\btheta}$ \textbf{асимптотически нормально распределена}, и обозначаем это
\begin{equation}
\label{eq:A17}
	\hat{\btheta} \sim \cN [\btheta_0,N^{-1}\bB]
\end{equation}
где слова <<при большой выборке>> означают, что $N$ достаточно велико, чтобы \ref{eq:A16} было хорошим приближением, но не настолько велико, что дисперсия в \ref{eq:A17} занулилась.
\end{definition}

Формула \ref{eq:A17} следует из \ref{eq:A16}, так как деление случайной величины на $\sqrt{N}$ приводит к делению дисперсии на $N$.

Удобно неявно подразумевать асимптотическую нормальность и использовать следующую терминологию:

\begin{definition}[Асимптотическая ковариационная матрица $\hat{\btheta}$]
\label{def:A19}
Если \ref{eq:A16} выполнено, мы говорим, что \textbf{асимптотическая ковариационная матрица} оценки $\hbtheta$ это:
\begin{equation}
	\label{eq:A18}
	\V[\hbtheta]=N^{-1}\bB
\end{equation}	
\end{definition}

\begin{definition}[Оцененная асимптотическая ковариационная матрица $\hat{\btheta}$]
\label{def:A20}
Если \ref{eq:A16} выполнено, мы говорим, что \textbf{оценённая асимптотическая ковариационная матрица} оценки $\hbtheta$ это:
\begin{equation}
	\label{eq:A19}
	\hat{\V}[\hbtheta]=N^{-1}\hat{\bB},
\end{equation}	
где $\hat{\bB}$ --- это состоятельная оценка матрицы $\bB$.
\end{definition}

Некоторые авторы используют обозначения $\mathrm{Avar}[\hbtheta]$ и $\widehat{\mathrm{Avar}}[\hbtheta]$ в определениях \ref{def:A19} и \ref{def:A20}, чтобы избежать потенциальной путаницы с дисперсией $\V[\cdot]$. В данной книге очень малое количество оценок имеют явное выражение для дисперсии в конечных выборках, поэтому $\V[\hbtheta]$ обозначает асимптотическую ковариационную матрицу оценки.


Пример к определениям \ref{def:A18}-\ref{def:A20}. Если $\{X_i\}$ независимы и одинаково распределены $[\mu, \sigma^2]$, то из ЦПТ Линдеберга-Леви следует, что $\sqrt{N}(\bar{X}_N-\mu)/\sigma \dto \cN [ 0,1]$, или, по другому говоря, $\sqrt{N}\bar{X}_N \dto \cN [\mu,\sigma^2]$. Мы говорим, что асимптотически $\bar{X}_N \sim \cN[\mu,\sigma^2/N]$, асимптотическая дисперсия $\bar{X}_N$ равна $\sigma^2/N$, оценка асимптотической дисперсии $\bar{X}_N$ равна $s^2/N$, где $s^2$  --- это состоятельная оценка для $\sigma^2$. В качестве $s^2$ подойдет, например, $s^2=\sum_i (X_i - \bar{X}_N)^2/(N-1)$.

\subsection{Асимптотическая эффективность}

Для конечной выборки по неравенству Крамера-Рао нижняя граница для ковариационной матрицы несмещённой оценки равна $-(\E[\partial^2 \ln L_N/\partial \btheta\btheta' |_{\btheta_0}])^{-1}$. Этот результат можно обобщить на случай асимптотически нормальных оценок.

\begin{definition}[Асимптотическая эффективность]
\label{def:A21}
	Состоятельная асимптотически нормальная оценка $\hbtheta$ параметра $\btheta$ называется \textbf{асимптотически эффективной}, если её асимптотическая ковариационная матрица совпадает с нижней границей Крамера-Рао. 
\end{definition}

\section{Стохастический порядок малости}

Для описания скорости сходимости удобно использовать обозначения $(O,o)$, О-большое и о-малое.

Последовательность неслучайных чисел $a_N$ --- это $O(g(N))$, если $\lim (a_N/g(N))$ конечен и ненулевой, и $o(g(N))$, если $\lim (a_N/g(N))$ нулевой. Другими словами, последовательность $a_N$ --- это $O(g(N))$, если она того же порядка малости, что и функция $g(N)$, и $o(g(N))$, если она более высокого порядка малости, чем $g(N)$. Например, последовательность $(3/N)+(5/N)^2$ --- это $O(1/N)$ или $O(N^{-1})$, т.к. при больших $N$ она пропорциональна $N^{-1}$. Рассматриваемая последовательность будет $o(N^{-1/2})$, но больше, чем $o(N^{-1})$.

Эти обозначения можно обобщить до \textbf{стохастического порядка малости} последовательности случайных величин. Мы получаем обозначения $(O_p,o_p)$.

\begin{definition}[Стохастический порядок малости]
\label{def:A22}
	Последовательность случайных величин $b_N$ является $O_p(g(N))$ если
	\[
	0<\plim \frac{b_N}{g(N)}<\infty
	\]
	и является $o_p(g(N))$ если 
	\[
	\plim \frac{b_N}{g(N)}=0.
	\]
\end{definition}

Чаще всего $g(N)=N^{-c}$ для некоторой константы $c\geq 0$. Состоятельная оценка $\hat{\theta}$ параметра $\theta_0$ может быть записана в виде $\hat{\theta}=\theta_0+o_p(1)$, т.к. она равна $\theta_0$ плюс слагаемое, сходящееся к нулю по вероятности. Оценка $\hat{\theta}$, которая также является \textit{корень из $N$-состоятельной}, может быть записана в виде $\hat{\theta}=\theta_0+O_p(N^{-1/2})$, т.к. в этом случае $N^{1/2}(\hat{\theta}-\theta_0)=O_p(1)$.


\section{Прочие результаты}

Этот раздел содержит ключевые результаты об условном математическом ожидании, верные для конечных выборок. А также теоремы о возможности перемены порядка математического ожидания и преобразования.

\begin{theorem}[Закон повторного ожидания]
Если  $X$ и $Y$ --- случайные величины, то:
\[
\E[Y]=\E_X[\E_{Y|X}[Y|X]],
\]
где $\E[\cdot]$ --- безусловное математическое ожидание $Y$, $\E_X[\cdot]$ --- безусловное математическое ожидание по отношению к частной функции распределения $X$, и $\E_{Y|X}[\cdot|X]$ --- условное математическое ожидание $Y$ при известном $X$.	
 \end{theorem} 

Этот результат означает, что, взяв сначала условное ожидание $Y$ при известном $X$, а затем взяв ожидание по $X$, мы получим безусловное математическое ожидание $Y$. См. Рао (1973, стр. 97) для доказательства. Например, если $\E[u|\bx]=0$, то $\E[u]=\E_{\bx}[\E[u|\bx]]=\E_{\bx}[0]=0$.

\begin{theorem}[Разложение дисперсии]
Если  $X$ и $Y$ --- случайные величины, то:
\[
\V[Y]=\E_X[\V_{Y|X}[Y|X]]+\V_X[\E_{Y|X}[Y|X]],
\]
где $\V[Y]$ --- безусловная дисперсия $Y$, $\E_X[\cdot]$ --- безусловное математическое ожидание по отношению к частному функции распределения $X$, $\V_{Y|X}[Y|X]$ обозначает условную дисперсию $Y$ при известном $X$, $\V_X[\cdot]$ обозначает дисперсию по отношению к безусловному распределению $X$, и $\E_{Y|X}[\cdot|X]$ --- условное математическое ожидание $Y$ при известном $X$.	
\end{theorem}

Словами, безусловная дисперсия $Y$ равна сумме (1) ожидаемого значения (по $X$) условной дисперсии и (2) дисперсии (по $X$) условного математического ожидания. Простой способ запомнить это состоит в том, чтобы увидеть, что безусловная дисперсия равна $\E\V$ плюс $\V\E$. Доказательство можно найти в Рао (1973, стр. 97).

\begin{theorem}[Неравенство Йенсена]
Если у случайной величины $Z$ существует ожидание $\E[Z]$ и $g(\cdot)$ --- \textbf{выпуклая функция}, то
\[
g(\E[Z]) \leq \E[g(Z)].
\]
Если, наоборот, функция $g(\cdot)$ является \textbf{вогнутой}, то
\[
g(\E[Z]) \geq \E[g(Z)].
\]
\end{theorem}
Результат доказывается в Рао (1973, стр. 58) и очень полезен для нелинейных моделей. Он подчёркивает разницу между поведением среднего индивида и средним поведением. Например, предположим, что адекватна экспоненциальная модель с $\E[y|\bx]=\exp(\bx'\mathbf{\beta})$. Экспоненциальная функция вогнута, поэтому из неравенства Йенсена следует, что $\exp(\E[\bx'\bbeta])\geq \E[\exp(\bx'\bbeta]$. Условное среднее для индивида со средними характеристиками, равными $\bx=\E[x]$, превосходит безусловное среднее $\E[y]=\E[\E[y|\bx]]=\E[\exp(\bx'\bbeta)]$.

\section{Библиографические заметки}

Классический источник доказательств --- Рао (1973, стр. 108-130), который мы цитируем, где возможно. Многие результаты взяты из работ Амэмии (1985, глава 3) и Уайта (2001a).

Учебники магистерского уровня такие, как Грин (2003), приводят обзор ключевых результатов. Более продвинутые книги Дэвидсона и МакКиннона (1993), Хендри (1995), Рууда (2000) и Вулдриджа (2002) излагают результаты на таком же уровне, как в этой книге, или более подробно. Дэвидсон (1994) излагает длинный курс стохастической теории для эконометристов. Как уже отмечалось, терминология может отличаться в разных источниках, особенно это касается теорем Слуцкого и Крамера.


\chapter{Псевдо-случайные величины}

В этом приложении мы приводим функции плотности или вероятности и два первых момента наиболее распространённых одномерных распределений. Также мы предъявляем алгоритмы для генерации псевдо-случайных выборок из этих распределений.

\begin{table}[h]
\caption{\label{tab:density} Функции плотности непрерывных случайных величин и их моменты}
\begin{tabular}{cp{6cm}p{4cm}c}
\hline 
\hline
Случайная величина & Ф. плотности $f(x)$ & Среднее, дисперсия & Ограничения\\ 
\hline 
Равномерная, $\mathcal{U}[a;b]$ & $1/(b-a)$ & $\frac{a+b}{2}$, $\frac{(a-b)^2}{12}$ & $b>a$ \\ 
Нормальная, $\mathcal{N}[\mu,\sigma^2]$ & $\frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ & $\mu$, $\sigma^2$ & $\sigma^2>0$ \\ 
Экспоненциальная, $\mathcal{E}[\lambda]$ & $\lambda e^{-\lambda x}$ & $1/\lambda$, $1/\lambda^2$ & $\lambda>0$ \\ 
Гамма, $\mathcal{G}[a,b]$ & $\frac{1}{\Gamma(a)b^a}x^{a-1}e^{-x/b}$ & $ab$, $ab^2$ & $a,b>0$ \\ 
Бета, $\mathcal{B}[a,b]$ & $\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}x^{a-1}(1-x)^{b-1}$ & $\frac{a}{a+b}$, $\frac{ab}{(a+b)^2(a+b+1)}$ & $a,b>0$ \\ 
Логистическая, $\mathcal{L}[a,b]$ & $e^{-\frac{x-a}{b}}/[b(1+\exp(-\frac{x-a}{b}))^2]$ & $a$, $(b\pi)^2/3$ & $b>0, a \in \mathbb{R}$ \\ 
Хи-квадрат, $\chi^2(n)$ & $\frac{x^{n/2-1}\exp(-x/2)}{\Gamma(n/2)2^{n/2}}$ & $n$, $2n$ & \\ 
t, $t(v)$ & $\frac{\Gamma((v+1)/2)}{\Gamma(v/2)\sqrt{v\pi}}(1+x^2/v)^{-(v+1)/2}$ & $0$, $\frac{v}{v-2}$ при $v>2$ & $v\in\mathbb{N}$ \\ 
F, $F(w,v)$ & $\frac{\Gamma((v+w)/2)(v/w)^{v/2}}{\Gamma(v/2)\Gamma(w/2)}\times$

$x^{w/2-1}(x+v/w)^{-(v+w)/2}$ & $\frac{v}{v-2}$ при $v>2$  

$\frac{2v^2(v+w-2)}{w(v-4)(v-2)^2}$ при $v>4$ & $v,w\in\mathbb{N}$\\
\hline
\hline
\end{tabular} 
\end{table}

\begin{table}[h]
\caption{\label{tab:algo} Алгоритмы генерации непрерывных случайных величин}
\begin{tabular}{p{5cm}p{2cm}p{9cm}}
\hline 
\hline
Случайная величина & Диапазон 

значений & Алгоритм генерации \\
\hline
Равномерная, $\mathcal{U}[a;b]$ & $x \in [a;b]$ & Сгенерить $r$ из $\mathcal{U}[0;1]$ 

Присвоить $x=a+(b-a)r$ \\
Нормальная, $\mathcal{N}[\mu,\sigma^2]$ & $ x_1,x_2 \in \mathbb{R}$ &  Сгенерить $r_1$, $r_2$ из $\mathcal{U}[0;1]$ 

Присвоить:

\hspace{0.5cm} $x_1=\mu+\sigma\sqrt{-2\ln r_1}\cos(2\pi r_2)$ 

\hspace{0.5cm} $x_2=\mu+\sigma\sqrt{-2\ln r_1}\sin(2\pi r_2)$ \\ 
Экспоненциальная, $\mathcal{E}[\lambda]$ & $x \geq 0$  & Сгенерить $r$ из $\mathcal{U}[0;1]$ 

Присвоить $x=-\frac{\ln r}{\lambda}$ \\
Гамма, $\mathcal{G}[a,b]$ & $x \geq 0$ & Способ i (если $a \in \mathbb{N}$):

Сгенерить $y_1$, $y_2$, \ldots, $y_n$ из $\mathcal{E}[\lambda]$ 

Присвоить $x=\sum_{i=1}^a y_i$

Способ ii (если $a \notin \mathbb{N}$):

Представить $a$ в виде $a=m+q$, где $m\in \mathbb{N}$, $0<q<1$

Сгенерить $y_1$ из $\mathcal{B}[q,1-q]$

Сгенерить $y_2$ из $\mathcal{E}[1]$

Сгенерить $r_1$, $r_2$, \ldots, $r_n$ из $\mathcal{U}[0;1]$

Присвоить $x=-\frac{1}{\lambda}[\sum_{i=1}^m \ln r_i - y_1y_2]$ \\
Бета, $\mathcal{B}[a,b]$ & $x \in [0;1] $ & Способ i ($a,b \in \mathbb{N}$): 

Присвоить произвольное $k$

Сгенерить $y_1$ из $\mathcal{G}[k,a]$

Сгенерить $y_2$ из $\mathcal{G}[k,b]$

Присвоить $x=y_1/(y_1+y_2)$

Способ ii ($a \notin \mathbb{N}$ или $b \notin \mathbb{N}$): 

Присвоить $r_1=1$ и $r_2=1$

Повторять пока $(r_1^{1/a}+r_2^{1/b}) > 1$:

\hspace{0.5cm} Сгенерить $r_1$, $r_2$ из $\mathcal{U}[0;1]$

Присвоить $x=r_1^{1/a}/(r_1^{1/a}+r_2^{1/b})$ \\

Логистическая, $\mathcal{L}[a,b]$ & $x\in \mathbb{R}$ & Сгенерить $r$ из $\mathcal{U}[0;1]$ 

Присвоить $x=a+b\ln \frac{r}{1-r}$ \\ 
Хи-квадрат, $\chi^2(n)$ & $x\geq 0$ & Сгенерить $y_1$, $y_2$, \ldots, $y_n$ из $\mathcal{N}[0;1]$

Присвоить $x=\sum_{i=1}^n y_i$\\ 
t, $t(v)$ & $x\in \mathbb{R}$ & Сгенерить $y_1$ из $\mathcal{N}[0;1]$

Сгенерить $y_2$ из $\chi^2(v)$

Присвоить $x=y_1/\sqrt{y_2/v}$ \\ 
F, $F(w,v)$ & $x \geq 0$ & Сгенерить $y_1$ из $\chi^2(w)$

Сгенерить $y_2$ из $\chi^2(v)$

Присвоить $x=(y_1/w)/(y_2/v)$ \\
\hline
\hline 
\end{tabular}
\end{table}


\begin{table}[h]
\caption{\label{tab:density2}  Функции плотности непрерывных случайных величин и их моменты}
\begin{tabular}{p{5cm}ccp{3cm}}
\hline 
\hline
Случайная величина & Вероятность $f(x)$ & Среднее, дисперсия & Ограничения\\ 
\hline 
Биномиальная, $Bi[n,p]$ & $\binom{n}{x}p^x(1-p)^{n-x}$ & $np$, $np(1-p)$ & $n\in \mathbb{N}$, $p\in[0;1]$ \\
Пуассоновская, $\mathcal{P}[\lambda]$ & $e^{-\lambda}\lambda^x/x!$ & $\lambda$, $\lambda$ & $\lambda>0$ \\
Отрицательная биномиальная, $NB[n,p]$ & $\binom{n+x-1}{x}p^n(1-p)^x$ & $n(1-p)/p$, $n(1-p)/p^2$ & $0<p<1$, 

$n>1$\\
\hline
\hline
\end{tabular} 
\end{table}


\begin{table}[h]
\caption{\label{tab:algod} Алгоритмы генерации дискретных случайных величин}
\begin{tabular}{p{5cm}p{4cm}p{7cm}}
\hline
\hline 
Случайная величина & Диапазон значений & Алгоритм генерации \\
\hline
Биномиальная, $Bi[n,p]$ & $x=0,1,\ldots,n$ & Присвоить $x = 0$

Повторить $n$ раз:

\hspace{0.5cm}Сгенерить $r$ равномерно на $[0;1]$ 

\hspace{0.5cm}Если $r\leq p$, то присвоить $x = x+1$

Вывести $x$ \\

Пуассоновская, $\mathcal{P}[\lambda]$ & $x=0,1,\ldots$ & Присвоить $x = 0$ и $t = 0$

Повторять пока $t<\lambda$:

\hspace{0.5cm}Сгенерить экспоненциальную $y$  

\hspace{0.5cm}Присвоить $t=t+y$ и $x=x+1$

Вывести $x$ \\
Отрицательная биномиальная, $NB[n,p]$ & $x=0,1,\ldots$ & Сгенерить $\lambda$ из $\mathcal{G}(n,\frac{1-p}{p})$

Сгенерить $x$ из $\mathcal{P}(\lambda)$ 

Вывести $x$ \\
\hline
\hline
\end{tabular}
\end{table}


